

insert  into `ambari_component_layout`(`id`,`service_code`,`host_group`,`component_code`,`is_ha`,`state`,`created_by`,`created_time`,`updated_by`,`updated_time`) values (12,'AMBARI','AMBARI','AMBARI-SERVER',1,'VALID','system','2022-12-08 13:29:33','system','2022-12-08 13:29:33'),(13,'AMBARI','AMBARI','AMBARI-AGENT',1,'VALID','system','2022-12-08 13:29:33','system','2022-12-08 13:29:33'),(23,'HDFS','MASTER1','NAMENODE',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(25,'HDFS','MASTER1','HDFS_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(27,'HDFS','CORE','DATANODE',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(29,'ZOOKEEPER','MASTER1','ZOOKEEPER_SERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(30,'ZOOKEEPER','MASTER1','ZOOKEEPER_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(31,'YARN','MASTER1','RESOURCEMANAGER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(33,'YARN','MASTER1','YARN_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(34,'YARN','CORE','NODEMANAGER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(35,'YARN','TASK','NODEMANAGER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(36,'MAPREDUCE2','MASTER1','HISTORYSERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(37,'MAPREDUCE2','MASTER1','MAPREDUCE2_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(38,'HIVE','MASTER1','HIVE_METASTORE',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(39,'HIVE','TASK','HIVE_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(40,'HIVE','MASTER1','HIVE_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(41,'HBASE','MASTER1','HBASE_MASTER',0,'INVALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(42,'HBASE','MASTER1','HBASE_CLIENT',0,'INVALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(43,'HBASE','CORE','HBASE_REGIONSERVER',0,'INVALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(44,'SPARK3','MASTER1','SPARK3_THRIFTSERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(45,'SPARK3','MASTER1','SPARK3_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(46,'SPARK3','CORE','SPARK3_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(47,'TEZ','MASTER1','TEZ_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(49,'HDFS','AMBARI','JOURNALNODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(50,'HDFS','AMBARI','HDFS_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(51,'YARN','AMBARI','YARN_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(52,'ZOOKEEPER','AMBARI','ZOOKEEPER_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(53,'ZOOKEEPER','AMBARI','ZOOKEEPER_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(54,'MAPREDUCE2','AMBARI','HISTORYSERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(55,'MAPREDUCE2','AMBARI','MAPREDUCE2_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(56,'HIVE','AMBARI','HIVE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(57,'HBASE','AMBARI','HBASE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(58,'SPARK3','AMBARI','SPARK3_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(59,'TEZ','AMBARI','TEZ_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(60,'SQOOP','AMBARI','SQOOP',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(61,'HDFS','MASTER1','NAMENODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(62,'HDFS','MASTER1','ZKFC',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(63,'HDFS','MASTER1','JOURNALNODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(64,'YARN','MASTER1','RESOURCEMANAGER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(65,'YARN','MASTER1','APP_TIMELINE_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(66,'ZOOKEEPER','MASTER1','ZOOKEEPER_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(67,'HIVE','MASTER1','HIVE_METASTORE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(68,'HIVE','MASTER1','HIVE_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(69,'HBASE','MASTER1','HBASE_MASTER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(70,'SPARK3','MASTER1','SPARK3_THRIFTSERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(71,'HDFS','MASTER2','NAMENODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(72,'HDFS','MASTER2','ZKFC',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(73,'HDFS','MASTER2','JOURNALNODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(74,'YARN','MASTER2','RESOURCEMANAGER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(75,'ZOOKEEPER','MASTER2','ZOOKEEPER_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(76,'HIVE','MASTER2','HIVE_SERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(77,'HBASE','MASTER2','HBASE_MASTER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(78,'SPARK3','MASTER2','SPARK3_THRIFTSERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(79,'HDFS','CORE','DATANODE',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(80,'YARN','CORE','NODEMANAGER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(81,'HBASE','CORE','HBASE_REGIONSERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(82,'ZOOKEEPER','TASK','ZOOKEEPER_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(83,'YARN','TASK','NODEMANAGER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(84,'HBASE','TASK','HBASE_REGIONSERVER',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(85,'HIVE','CORE','HIVE_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(86,'SPARK3','MASTER1','SPARK3_JOBHISTORYSERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(87,'YARN','MASTER1','APP_TIMELINE_SERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(88,'HDFS','MASTER1','SECONDARY_NAMENODE',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(89,'ZOOKEEPER','CORE','ZOOKEEPER_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(90,'ZOOKEEPER','TASK','ZOOKEEPER_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(91,'MAPREDUCE2','TASK','MAPREDUCE2_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(92,'MAPREDUCE2','CORE','MAPREDUCE2_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(93,'HIVE','MASTER1','HIVE_SERVER',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(94,'SPARK3','TASK','SPARK3_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(95,'SQOOP','TASK','SQOOP',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(96,'SQOOP','CORE','SQOOP',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(97,'SQOOP','MASTER1','SQOOP',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(885,'SPARK3','MASTER1','SPARK3_JOBHISTORYSERVER',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(886,'ZOOKEEPER','MASTER1','ZOOKEEPER_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(887,'HDFS','MASTER1','HDFS_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(888,'YARN','MASTER1','YARN_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(889,'MAPREDUCE2','MASTER1','MAPREDUCE2_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(890,'HIVE','MASTER1','HIVE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(891,'HBASE','MASTER1','HBASE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(892,'SPARK3','MASTER1','SPARK3_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(893,'TEZ','MASTER1','TEZ_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(894,'ZOOKEEPER','MASTER2','ZOOKEEPER_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(895,'HDFS','MASTER2','HDFS_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(896,'YARN','MASTER2','YARN_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(897,'MAPREDUCE2','MASTER2','MAPREDUCE2_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(898,'HIVE','MASTER2','HIVE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(899,'HBASE','MASTER2','HBASE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(900,'SPARK3','MASTER2','SPARK3_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(901,'TEZ','MASTER2','TEZ_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(902,'HDFS','TASK','HDFS_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(903,'YARN','TASK','YARN_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(904,'MAPREDUCE2','TASK','MAPREDUCE2_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(905,'HIVE','TASK','HIVE_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(906,'HBASE','TASK','HBASE_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(907,'SPARK3','TASK','SPARK3_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(908,'TEZ','TASK','TEZ_CLIENT',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(912,'SQOOP','MASTER1','SQOOP',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(913,'SQOOP','MASTER2','SQOOP',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(914,'SQOOP','CORE','SQOOP',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(915,'HDFS','CORE','HDFS_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(916,'YARN','CORE','YARN_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(917,'ZOOKEEPER','CORE','ZOOKEEPER_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(918,'HIVE','CORE','HIVE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(919,'HBASE','CORE','HBASE_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(920,'SPARK3','CORE','SPARK3_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(921,'TEZ','CORE','TEZ_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(922,'MAPREDUCE2','CORE','MAPREDUCE2_CLIENT',1,'VALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(923,'SQOOP','TASK','SQOOP',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47'),(924,'HDFS','CORE','HDFS_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(925,'YARN','CORE','YARN_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(926,'HBASE','CORE','HBASE_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(927,'TEZ','CORE','TEZ_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(928,'HDFS','TASK','ZOOKEEPER_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(929,'YARN','TASK','YARN_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(930,'HBASE','TASK','HBASE_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(931,'TEZ','TASK','TEZ_CLIENT',0,'VALID','system','2022-12-08 14:01:25','system','2022-12-08 14:01:25'),(932,'HIVE','MASTER2','HIVE_METASTORE',1,'INVALID','system','2022-12-10 03:53:47','system','2022-12-10 03:53:47');


insert  into `ambari_config_item`(`id`,`stack_code`,`service_code`,`component_code`,`config_type_code`,`key`,`value`,`is_content_prop`,`is_dynamic`,`dynamic_type`,`item_type`,`state`,`created_by`,`created_time`,`updated_by`,`updated_time`) values (9,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.hostname','%HOSTGROUP::MASTER1%',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(10,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.zk-address','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(11,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.log.server.web-service.url','http://%HOSTGROUP::MASTER1%:8188/ws/v1/applicationhistory',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(12,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.webapp.address','%HOSTGROUP::MASTER1%:8088',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(13,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.address','%HOSTGROUP::MASTER1%:10200',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(14,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.admin.address','%HOSTGROUP::MASTER1%:8141',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(15,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.resource-tracker.address','%HOSTGROUP::MASTER1%:8025',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(16,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.scheduler.address','%HOSTGROUP::MASTER1%:8030',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(17,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.address','%HOSTGROUP::MASTER1%:8050',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(18,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.nodemanager.local-dirs','/data/disk0/hadoop/yarn/local',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(19,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.leveldb-timeline-store.path','/hadoop/yarn/timeline',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(20,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.leveldb-state-store.path','/hadoop/yarn/timeline',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(21,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.nodemanager.log-dirs','/data/disk0/hadoop/yarn/log',0,0,NULL,'NON_HA','VALID','sysstem','2022-12-11 04:39:00','system','2022-12-11 04:39:00'),(22,'SDP-1.0','STACK','NULL','cluster-env','agent_mounts_ignore_list','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:03','system','2022-12-11 06:52:03'),(23,'SDP-1.0','STACK','NULL','cluster-env','alerts_repeat_tolerance','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:16','system','2022-12-11 06:52:17'),(24,'SDP-1.0','STACK','NULL','cluster-env','enable_external_ranger','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:26','system','2022-12-11 06:52:26'),(25,'SDP-1.0','STACK','NULL','cluster-env','fetch_nonlocal_groups','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:27','system','2022-12-11 06:52:27'),(26,'SDP-1.0','STACK','NULL','cluster-env','hide_yarn_memory_widget','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:27','system','2022-12-11 06:52:27'),(27,'SDP-1.0','STACK','NULL','cluster-env','ignore_bad_mounts','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:27','system','2022-12-11 06:52:27'),(28,'SDP-1.0','STACK','NULL','cluster-env','ignore_groupsusers_create','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:28','system','2022-12-11 06:52:28'),(29,'SDP-1.0','STACK','NULL','cluster-env','kerberos_domain','EXAMPLE.COM',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:28','system','2022-12-11 06:52:28'),(30,'SDP-1.0','STACK','NULL','cluster-env','manage_dirs_on_root','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:29','system','2022-12-11 06:52:29'),(31,'SDP-1.0','STACK','NULL','cluster-env','managed_hdfs_resource_property_names','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:29','system','2022-12-11 06:52:29'),(32,'SDP-1.0','STACK','NULL','cluster-env','namenode_rolling_restart_safemode_exit_timeout','3600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:29','system','2022-12-11 06:52:29'),(33,'SDP-1.0','STACK','NULL','cluster-env','namenode_rolling_restart_timeout','4200',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:30','system','2022-12-11 06:52:30'),(34,'SDP-1.0','STACK','NULL','cluster-env','one_dir_per_partition','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:30','system','2022-12-11 06:52:30'),(35,'SDP-1.0','STACK','NULL','cluster-env','override_uid','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:31','system','2022-12-11 06:52:31'),(36,'SDP-1.0','STACK','NULL','cluster-env','recovery_enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:31','system','2022-12-11 06:52:31'),(37,'SDP-1.0','STACK','NULL','cluster-env','recovery_lifetime_max_count','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:31','system','2022-12-11 06:52:31'),(38,'SDP-1.0','STACK','NULL','cluster-env','recovery_max_count','6',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:32','system','2022-12-11 06:52:32'),(39,'SDP-1.0','STACK','NULL','cluster-env','recovery_retry_interval','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:32','system','2022-12-11 06:52:32'),(40,'SDP-1.0','STACK','NULL','cluster-env','recovery_type','AUTO_START',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:33','system','2022-12-11 06:52:33'),(41,'SDP-1.0','STACK','NULL','cluster-env','recovery_window_in_minutes','60',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:33','system','2022-12-11 06:52:33'),(42,'SDP-1.0','STACK','NULL','cluster-env','repo_suse_rhel_template','[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:33','system','2022-12-11 06:52:33'),(44,'SDP-1.0','STACK','NULL','cluster-env','security_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:34','system','2022-12-11 06:52:34'),(45,'SDP-1.0','STACK','NULL','cluster-env','smokeuser','ambari-qa',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:35','system','2022-12-11 06:52:35'),(46,'SDP-1.0','STACK','NULL','cluster-env','smokeuser_keytab','/etc/security/keytabs/smokeuser.headless.keytab',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:35','system','2022-12-11 06:52:35'),(47,'SDP-1.0','STACK','NULL','cluster-env','stack_features','{\n  \"SDP\": {\n    \"stack_features\": [\n      {\n        \"name\": \"snappy\",\n        \"description\": \"Snappy compressor/decompressor support\",\n        \"min_version\": \"2.0.0.0\",\n        \"max_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"lzo\",\n        \"description\": \"LZO libraries support\",\n        \"min_version\": \"2.2.1.0\"\n      },\n      {\n        \"name\": \"express_upgrade\",\n        \"description\": \"Express upgrade support\",\n        \"min_version\": \"2.1.0.0\"\n      },\n      {\n        \"name\": \"rolling_upgrade\",\n        \"description\": \"Rolling upgrade support\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"config_versioning\",\n        \"description\": \"Configurable versions support\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"datanode_non_root\",\n        \"description\": \"DataNode running as non-root support (AMBARI-7615)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"tez_for_spark\",\n        \"description\": \"Tez dependency for Spark\",\n        \"min_version\": \"2.2.0.0\",\n        \"max_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"timeline_state_store\",\n        \"description\": \"Yarn application timeline-service supports state store property (AMBARI-11442)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"copy_tarball_to_hdfs\",\n        \"description\": \"Copy tarball to HDFS support (AMBARI-12113)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"spark_thriftserver\",\n        \"description\": \"Spark Thrift Server\",\n        \"min_version\": \"2.3.2.0\"\n      },\n      {\n        \"name\": \"hive_metastore_upgrade_schema\",\n        \"description\": \"Hive metastore upgrade schema support (AMBARI-11176)\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"hive_server_interactive\",\n        \"description\": \"Hive server interactive support (AMBARI-15573)\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"hive_purge_table\",\n        \"description\": \"Hive purge table support (AMBARI-12260)\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"hive_server2_kerberized_env\",\n        \"description\": \"Hive server2 working on kerberized environment (AMBARI-13749)\",\n        \"min_version\": \"2.2.3.0\",\n        \"max_version\": \"2.2.5.0\"\n      },\n      {\n        \"name\": \"hive_env_heapsize\",\n        \"description\": \"Hive heapsize property defined in hive-env (AMBARI-12801)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"hive_metastore_site_support\",\n        \"description\": \"Hive Metastore site support\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"hbase_home_directory\",\n        \"description\": \"Hbase home directory in HDFS needed for HBASE backup\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"spark_java_opts_support\",\n        \"description\": \"Allow Spark to generate java-opts file\",\n        \"min_version\": \"2.2.0.0\",\n        \"max_version\": \"2.4.0.0\"\n      },\n      {\n        \"name\": \"zkfc_version_advertised\",\n        \"description\": \"ZKFC advertise version\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"toolkit_config_update\",\n        \"description\": \"Support separate input and output for toolkit configuration\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"nifi_encrypt_config\",\n        \"description\": \"Encrypt sensitive properties written to nifi property file\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"tls_toolkit_san\",\n        \"description\": \"Support subject alternative name flag\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"admin_toolkit_support\",\n        \"description\": \"Supports the nifi admin toolkit\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"nifi_jaas_conf_create\",\n        \"description\": \"Create NIFI jaas configuration when kerberos is enabled\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"registry_remove_rootpath\",\n        \"description\": \"Registry remove root path setting\",\n        \"min_version\": \"2.6.3.0\"\n      },\n      {\n        \"name\": \"nifi_encrypted_authorizers_config\",\n        \"description\": \"Support encrypted authorizers.xml configuration for version 3.1 onwards\",\n        \"min_version\": \"2.6.5.0\"\n      },\n      {\n        \"name\": \"multiple_env_sh_files_support\",\n        \"description\": \"This feature is supported by RANGER and RANGER_KMS service to remove multiple env sh files during upgrade to stack 3.0\",\n        \"max_version\": \"2.6.99.99\"\n      },\n      {\n        \"name\": \"registry_allowed_resources_support\",\n        \"description\": \"Registry allowed resources\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_rewriteuri_filter_support\",\n        \"description\": \"Registry RewriteUri servlet filter\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_support_schema_migrate\",\n        \"description\": \"Support schema migrate in registry for version 3.1 onwards\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_support_db_user_creation\",\n        \"description\": \"Supports registry\'s database and user creation on the fly\",\n        \"min_version\": \"3.0.0.0\"\n      }\n    ]\n  }\n}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:35','system','2022-12-11 06:52:35'),(48,'SDP-1.0','STACK','NULL','cluster-env','stack_name','SDP',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:36','system','2022-12-11 06:52:36'),(49,'SDP-1.0','STACK','NULL','cluster-env','stack_packages','{\n  \"SDP\": {\n    \"stack-select\": {\n      \"HBASE\": {\n        \"HBASE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-client\",\n          \"INSTALL\": [\n            \"hbase-client\"\n          ],\n          \"PATCH\": [\n            \"hbase-client\"\n          ],\n          \"STANDARD\": [\n            \"hbase-client\",\n            \"phoenix-client\",\n            \"hadoop-client\"\n          ]\n        },\n        \"HBASE_MASTER\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-master\",\n          \"INSTALL\": [\n            \"hbase-master\"\n          ],\n          \"PATCH\": [\n            \"hbase-master\"\n          ],\n          \"STANDARD\": [\n            \"hbase-master\"\n          ]\n        },\n        \"HBASE_REGIONSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-regionserver\",\n          \"INSTALL\": [\n            \"hbase-regionserver\"\n          ],\n          \"PATCH\": [\n            \"hbase-regionserver\"\n          ],\n          \"STANDARD\": [\n            \"hbase-regionserver\"\n          ]\n        },\n        \"PHOENIX_QUERY_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"phoenix-server\",\n          \"INSTALL\": [\n            \"phoenix-server\"\n          ],\n          \"PATCH\": [\n            \"phoenix-server\"\n          ],\n          \"STANDARD\": [\n            \"phoenix-server\"\n          ]\n        }\n      },\n      \"HDFS\": {\n        \"DATANODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-datanode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-datanode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-datanode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-datanode\"\n          ]\n        },\n        \"HDFS_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-client\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        },\n        \"NAMENODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-namenode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-namenode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-namenode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-namenode\"\n          ]\n        },\n        \"NFS_GATEWAY\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-nfs3\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-nfs3\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-nfs3\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-nfs3\"\n          ]\n        },\n        \"JOURNALNODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-journalnode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-journalnode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-journalnode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-journalnode\"\n          ]\n        },\n        \"SECONDARY_NAMENODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-secondarynamenode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ]\n        },\n        \"ZKFC\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-zkfc\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-zkfc\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-zkfc\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-zkfc\"\n          ]\n        }\n      },\n      \"HIVE\": {\n        \"HIVE_METASTORE\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-metastore\",\n          \"INSTALL\": [\n            \"hive-metastore\"\n          ],\n          \"PATCH\": [\n            \"hive-metastore\"\n          ],\n          \"STANDARD\": [\n            \"hive-metastore\"\n          ]\n        },\n        \"HIVE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-server2\",\n          \"INSTALL\": [\n            \"hive-server2\"\n          ],\n          \"PATCH\": [\n            \"hive-server2\"\n          ],\n          \"STANDARD\": [\n            \"hive-server2\"\n          ]\n        },\n        \"HIVE_SERVER_INTERACTIVE\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-server2-hive\",\n          \"INSTALL\": [\n            \"hive-server2-hive\"\n          ],\n          \"PATCH\": [\n            \"hive-server2-hive\"\n          ],\n          \"STANDARD\": [\n            \"hive-server2-hive\"\n          ]\n        },\n        \"HIVE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-client\",\n          \"INSTALL\": [\n            \"hive-client\"\n          ],\n          \"PATCH\": [\n            \"hive-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"MAPREDUCE2\": {\n        \"HISTORYSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-mapreduce-historyserver\",\n          \"INSTALL\": [\n            \"hadoop-mapreduce-historyserver\"\n          ],\n          \"PATCH\": [\n            \"hadoop-mapreduce-historyserver\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-mapreduce-historyserver\"\n          ]\n        },\n        \"MAPREDUCE2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-mapreduce-client\",\n          \"INSTALL\": [\n            \"hadoop-mapreduce-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-mapreduce-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"OOZIE\": {\n        \"OOZIE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"oozie-client\",\n          \"INSTALL\": [\n            \"oozie-client\"\n          ],\n          \"PATCH\": [\n            \"oozie-client\"\n          ],\n          \"STANDARD\": [\n            \"oozie-client\"\n          ]\n        },\n        \"OOZIE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"oozie-server\",\n          \"INSTALL\": [\n            \"oozie-client\",\n            \"oozie-server\"\n          ],\n          \"PATCH\": [\n            \"oozie-server\",\n            \"oozie-client\"\n          ],\n          \"STANDARD\": [\n            \"oozie-client\",\n            \"oozie-server\"\n          ]\n        }\n      },\n      \"SPARK3\": {\n        \"LIVY2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"livy2-client\",\n          \"INSTALL\": [\n            \"livy2-client\"\n          ],\n          \"PATCH\": [\n            \"livy2-client\"\n          ],\n          \"STANDARD\": [\n            \"livy2-client\"\n          ]\n        },\n        \"SPARK2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-client\",\n          \"INSTALL\": [\n            \"spark3-client\"\n          ],\n          \"PATCH\": [\n            \"spark3-client\",\n            \"hive_warehouse_connector\"\n          ],\n          \"STANDARD\": [\n            \"spark3-client\",\n            \"livy2-client\",\n            \"hive_warehouse_connector\"\n          ]\n        },\n        \"SPARK2_JOBHISTORYSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-historyserver\",\n          \"INSTALL\": [\n            \"spark3-historyserver\"\n          ],\n          \"PATCH\": [\n            \"spark3-historyserver\"\n          ],\n          \"STANDARD\": [\n            \"spark3-historyserver\"\n          ]\n        },\n        \"SPARK2_THRIFTSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-thriftserver\",\n          \"INSTALL\": [\n            \"spark3-thriftserver\"\n          ],\n          \"PATCH\": [\n            \"spark3-thriftserver\"\n          ],\n          \"STANDARD\": [\n            \"spark3-thriftserver\"\n          ]\n        }\n      },\n      \"TEZ\": {\n        \"TEZ_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"tez-client\",\n          \"INSTALL\": [\n            \"tez-client\"\n          ],\n          \"PATCH\": [\n            \"tez-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"YARN\": {\n        \"APP_TIMELINE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-timelineserver\",\n          \"INSTALL\": [\n            \"hadoop-yarn-timelineserver\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-timelineserver\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-timelineserver\"\n          ]\n        },\n        \"TIMELINE_READER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-timelinereader\",\n          \"INSTALL\": [\n            \"hadoop-yarn-timelinereader\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-timelinereader\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-timelinereader\"\n          ]\n        },\n        \"NODEMANAGER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-nodemanager\",\n          \"INSTALL\": [\n            \"hadoop-yarn-nodemanager\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-nodemanager\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-nodemanager\"\n          ]\n        },\n        \"RESOURCEMANAGER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-resourcemanager\",\n          \"INSTALL\": [\n            \"hadoop-yarn-resourcemanager\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-resourcemanager\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-resourcemanager\"\n          ]\n        },\n        \"YARN_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-client\",\n          \"INSTALL\": [\n            \"hadoop-yarn-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"ZOOKEEPER\": {\n        \"ZOOKEEPER_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"zookeeper-client\",\n          \"INSTALL\": [\n            \"zookeeper-client\"\n          ],\n          \"PATCH\": [\n            \"zookeeper-client\"\n          ],\n          \"STANDARD\": [\n            \"zookeeper-client\"\n          ]\n        },\n        \"ZOOKEEPER_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"zookeeper-server\",\n          \"INSTALL\": [\n            \"zookeeper-server\"\n          ],\n          \"PATCH\": [\n            \"zookeeper-server\"\n          ],\n          \"STANDARD\": [\n            \"zookeeper-server\"\n          ]\n        }\n      }\n    },\n    \"conf-select\": {\n      \"hadoop\": [\n        {\n          \"conf_dir\": \"/etc/hadoop/conf\",\n          \"current_dir\": \"{0}/current/hadoop-client/conf\",\n          \"component\": \"hadoop-client\"\n        }\n      ],\n      \"hbase\": [\n        {\n          \"conf_dir\": \"/etc/hbase/conf\",\n          \"current_dir\": \"{0}/current/hbase-client/conf\",\n          \"component\": \"hbase-client\"\n        }\n      ],\n      \"hive\": [\n        {\n          \"conf_dir\": \"/etc/hive/conf\",\n          \"current_dir\": \"{0}/current/hive-client/conf\",\n          \"component\": \"hive-client\"\n        }\n      ],\n      \"hive2\": [\n        {\n          \"conf_dir\": \"/etc/hive2/conf\",\n          \"current_dir\": \"{0}/current/hive-server2-hive/conf\",\n          \"component\": \"hive-server2-hive\"\n        }\n      ],\n      \"hive-hcatalog\": [\n        {\n          \"conf_dir\": \"/etc/hive-webhcat/conf\",\n          \"prefix\": \"/etc/hive-webhcat\",\n          \"current_dir\": \"{0}/current/hive-webhcat/etc/webhcat\",\n          \"component\": \"hive-webhcat\"\n        },\n        {\n          \"conf_dir\": \"/etc/hive-hcatalog/conf\",\n          \"prefix\": \"/etc/hive-hcatalog\",\n          \"current_dir\": \"{0}/current/hive-webhcat/etc/hcatalog\",\n          \"component\": \"hive-webhcat\"\n        }\n      ],\n      \"spark3\": [\n        {\n          \"conf_dir\": \"/etc/spark3/conf\",\n          \"current_dir\": \"{0}/current/spark3-client/conf\",\n          \"component\": \"spark3-client\"\n        }\n      ],\n      \"sqoop\": [\n        {\n          \"conf_dir\": \"/etc/sqoop/conf\",\n          \"current_dir\": \"{0}/current/sqoop-client/conf\",\n          \"component\": \"sqoop-client\"\n        }\n      ],\n      \"tez\": [\n        {\n          \"conf_dir\": \"/etc/tez/conf\",\n          \"current_dir\": \"{0}/current/tez-client/conf\",\n          \"component\": \"tez-client\"\n        }\n      ],\n      \"zookeeper\": [\n        {\n          \"conf_dir\": \"/etc/zookeeper/conf\",\n          \"current_dir\": \"{0}/current/zookeeper-client/conf\",\n          \"component\": \"zookeeper-client\"\n        }\n      ]\n    },\n    \"conf-select-patching\": {\n      \"HBASE\": {\n        \"packages\": [\"hbase\"]\n      },\n      \"HDFS\": {\n        \"packages\": []\n      },\n      \"HIVE\": {\n        \"packages\": [\"hive\", \"hive-hcatalog\", \"hive2\", \"tez_hive2\"]\n      },\n      \"MAPREDUCE2\": {\n        \"packages\": []\n      },\n      \"SPARK3\": {\n        \"packages\": [\"spark3\", \"livy2\"]\n      },\n      \"SQOOP\": {\n        \"packages\": [\"sqoop\"]\n      },\n      \"TEZ\": {\n        \"packages\": [\"tez\"]\n      },\n      \"YARN\": {\n        \"packages\": []\n      },\n      \"ZOOKEEPER\": {\n        \"packages\": [\"zookeeper\"]\n      }\n    },\n    \"upgrade-dependencies\" : {\n      \"HIVE\": [\"TEZ\", \"MAPREDUCE2\", \"SQOOP\"],\n      \"TEZ\": [\"HIVE\"],\n      \"MAPREDUCE2\": [\"HIVE\"]\n    }\n  }\n}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:36','system','2022-12-11 06:52:36'),(50,'SDP-1.0','STACK','NULL','cluster-env','stack_root','{\"SDP\":\"/usr/sdp\"}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:37','system','2022-12-11 06:52:37'),(51,'SDP-1.0','STACK','NULL','cluster-env','stack_tools','{\n  \"SDP\": {\n    \"stack_selector\": [\n      \"sdp-select\",\n      \"/usr/bin/sdp-select\",\n      \"sdp-select\"\n    ],\n    \"conf_selector\": [\n      \"conf-select\",\n      \"/usr/bin/conf-select\",\n      \"conf-select\"\n    ]\n  }\n}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:37','system','2022-12-11 06:52:37'),(52,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_fast_jar_hdfs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:37','system','2022-12-11 06:52:37'),(53,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_oozie_share_lib_to_hdfs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:38','system','2022-12-11 06:52:38'),(54,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_tarballs_hdfs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:38','system','2022-12-11 06:52:38'),(55,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_create_users_and_groups','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:39','system','2022-12-11 06:52:39'),(56,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_hive_schema_create','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:39','system','2022-12-11 06:52:39'),(57,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_lzo_package_operations','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:39','system','2022-12-11 06:52:39'),(58,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_oozie_schema_create','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:40','system','2022-12-11 06:52:40'),(59,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_setup_jce','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:40','system','2022-12-11 06:52:40'),(60,'SDP-1.0','STACK','NULL','cluster-env','user_group','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:41','system','2022-12-11 06:52:41'),(61,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hdfs.groups','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:41','system','2022-12-11 06:52:41'),(62,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hdfs.hosts','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:41','system','2022-12-11 06:52:41'),(63,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hive.groups','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:42','system','2022-12-11 06:52:42'),(64,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.root.groups','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:42','system','2022-12-11 06:52:42'),(65,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.root.hosts','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:43','system','2022-12-11 06:52:43'),(66,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hive.hosts','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:43','system','2022-12-11 06:52:43'),(69,'SDP-1.0','HDFS','NULL','core-site','fs.defaultFS','hdfs://%HOSTGROUP::MASTER1%:8020',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:44','system','2022-12-11 06:52:44'),(70,'SDP-1.0','HDFS','NULL','core-site','fs.gs.application.name.suffix',' (GPN:Hortonworks; version 1.0) SDP/{{version}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:45','system','2022-12-11 06:52:45'),(71,'SDP-1.0','HDFS','NULL','core-site','fs.gs.path.encoding','uri-path',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:45','system','2022-12-11 06:52:45'),(72,'SDP-1.0','HDFS','NULL','core-site','fs.gs.working.dir','/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:45','system','2022-12-11 06:52:45'),(73,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.fast.upload','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:46','system','2022-12-11 06:52:46'),(74,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.fast.upload.buffer','disk',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:46','system','2022-12-11 06:52:46'),(75,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.multipart.size','67108864',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:46','system','2022-12-11 06:52:46'),(76,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.user.agent.prefix','User-Agent: APN/1.0 Hortonworks/1.0 SDP/{{version}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:47','system','2022-12-11 06:52:47'),(77,'SDP-1.0','HDFS','NULL','core-site','fs.trash.interval','360',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:47','system','2022-12-11 06:52:47'),(78,'SDP-1.0','HDFS','NULL','core-site','ha.failover-controller.active-standby-elector.zk.op.retries','120',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:48','system','2022-12-11 06:52:48'),(79,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.authentication.simple.anonymous.allowed','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:48','system','2022-12-11 06:52:48'),(80,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-headers','X-Requested-With,Content-Type,Accept,Origin,WWW-Authenticate,Accept-Encoding,Transfer-Encoding',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:48','system','2022-12-11 06:52:48'),(81,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-methods','GET,PUT,POST,OPTIONS,HEAD,DELETE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:49','system','2022-12-11 06:52:49'),(82,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-origins','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:49','system','2022-12-11 06:52:49'),(83,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.max-age','1800',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:50','system','2022-12-11 06:52:50'),(84,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.filter.initializers','org.apache.hadoop.security.AuthenticationFilterInitializer,org.apache.hadoop.security.HttpCrossOriginFilterInitializer',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:50','system','2022-12-11 06:52:50'),(85,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.auth_to_local','DEFAULT',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:50','system','2022-12-11 06:52:50'),(86,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.authentication','simple',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:51','system','2022-12-11 06:52:51'),(87,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.authorization','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:51','system','2022-12-11 06:52:51'),(88,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.instrumentation.requires.admin','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:52','system','2022-12-11 06:52:52'),(89,'SDP-1.0','HDFS','NULL','core-site','io.compression.codecs','org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:52','system','2022-12-11 06:52:52'),(90,'SDP-1.0','HDFS','NULL','core-site','io.file.buffer.size','131072',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:52','system','2022-12-11 06:52:52'),(91,'SDP-1.0','HDFS','NULL','core-site','io.serializations','org.apache.hadoop.io.serializer.WritableSerialization',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:53','system','2022-12-11 06:52:53'),(92,'SDP-1.0','HDFS','NULL','core-site','ipc.client.connect.max.retries','50',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:53','system','2022-12-11 06:52:53'),(93,'SDP-1.0','HDFS','NULL','core-site','ipc.client.connection.maxidletime','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:54','system','2022-12-11 06:52:54'),(94,'SDP-1.0','HDFS','NULL','core-site','ipc.client.idlethreshold','8000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:54','system','2022-12-11 06:52:54'),(95,'SDP-1.0','HDFS','NULL','core-site','ipc.server.tcpnodelay','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:54','system','2022-12-11 06:52:54'),(96,'SDP-1.0','HDFS','NULL','core-site','mapreduce.jobtracker.webinterface.trusted','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:55','system','2022-12-11 06:52:55'),(97,'SDP-1.0','HDFS','NULL','core-site','net.topology.script.file.name','/etc/hadoop/conf/topology_script.py',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:55','system','2022-12-11 06:52:55'),(98,'SDP-1.0','HDFS','NULL','hadoop-env','content','\n      # Set Hadoop-specific environment variables here.\n\n      # The only required environment variable is JAVA_HOME.  All others are\n      # optional.  When running a distributed configuration it is best to\n      # set JAVA_HOME in this file, so that it is correctly defined on\n      # remote nodes.\n\n      # The java implementation to use.  Required.\n      export JAVA_HOME={{java_home}}\n      export HADOOP_HOME_WARN_SUPPRESS=1\n\n      # Hadoop home directory\n      export HADOOP_HOME=${HADOOP_HOME:-/usr/sdp/current/hadoop}\n\n      # Hadoop Configuration Directory\n\n      {# this is different for SDP1 #}\n      # Path to jsvc required by secure SDP 2.0 datanode\n      export JSVC_HOME={{jsvc_path}}\n\n\n      # The maximum amount of heap to use, in MB. Default is 1000.\n      export HADOOP_HEAPSIZE=\"{{hadoop_heapsize}}\"\n\n      export HADOOP_NAMENODE_INIT_HEAPSIZE=\"-Xms{{namenode_heapsize}}\"\n\n      # Extra Java runtime options.  Empty by default.\n      export HADOOP_OPTS=\"-Djava.net.preferIPv4Stack=true ${HADOOP_OPTS}\"\n\n      USER=\"$(whoami)\"\n\n      # Command specific options appended to HADOOP_OPTS when specified\n      HADOOP_JOBTRACKER_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{jtnode_opt_newsize}} -XX:MaxNewSize={{jtnode_opt_maxnewsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xmx{{jtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dmapred.audit.logger=INFO,MRAUDIT -Dhadoop.mapreduce.jobsummary.logger=INFO,JSA ${HADOOP_JOBTRACKER_OPTS}\"\n\n      HADOOP_TASKTRACKER_OPTS=\"-server -Xmx{{ttnode_heapsize}} -Dhadoop.security.logger=ERROR,console -Dmapred.audit.logger=ERROR,console ${HADOOP_TASKTRACKER_OPTS}\"\n\n      {% if java_version < 8 %}\n      SHARED_HDFS_NAMENODE_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{namenode_opt_newsize}} -XX:MaxNewSize={{namenode_opt_maxnewsize}} -XX:PermSize={{namenode_opt_permsize}} -XX:MaxPermSize={{namenode_opt_maxpermsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms{{namenode_heapsize}} -Xmx{{namenode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT\"\n      export HDFS_NAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-name-node\\\" -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 ${HDFS_NAMENODE_OPTS}\"\n      export HDFS_DATANODE_OPTS=\"-server -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-data-node\\\" -XX:ErrorFile=/var/log/hadoop/$USER/hs_err_pid%p.log -XX:NewSize=200m -XX:MaxNewSize=200m -XX:PermSize=128m -XX:MaxPermSize=256m -Xloggc:/var/log/hadoop/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xms{{dtnode_heapsize}} -Xmx{{dtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT ${HDFS_DATANODE_OPTS} -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly\"\n\n      export HDFS_SECONDARYNAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-secondary-name-node\\\" ${HDFS_SECONDARYNAMENODE_OPTS}\"\n\n      # The following applies to multiple commands (fs, dfs, fsck, distcp etc)\n      export HADOOP_CLIENT_OPTS=\"-Xmx${HADOOP_HEAPSIZE}m -XX:MaxPermSize=512m $HADOOP_CLIENT_OPTS\"\n\n      {% else %}\n      SHARED_HDFS_NAMENODE_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{namenode_opt_newsize}} -XX:MaxNewSize={{namenode_opt_maxnewsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms{{namenode_heapsize}} -Xmx{{namenode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT\"\n      export HDFS_NAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-name-node\\\" -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 ${HDFS_NAMENODE_OPTS}\"\n      export HDFS_DATANODE_OPTS=\"-server -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-data-node\\\" -XX:ErrorFile=/var/log/hadoop/$USER/hs_err_pid%p.log -XX:NewSize=200m -XX:MaxNewSize=200m -Xloggc:/var/log/hadoop/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xms{{dtnode_heapsize}} -Xmx{{dtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT ${HDFS_DATANODE_OPTS} -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly\"\n\n      export HDFS_SECONDARYNAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-secondary-name-node\\\" ${HDFS_SECONDARYNAMENODE_OPTS}\"\n\n      # The following applies to multiple commands (fs, dfs, fsck, distcp etc)\n      export HADOOP_CLIENT_OPTS=\"-Xmx${HADOOP_HEAPSIZE}m $HADOOP_CLIENT_OPTS\"\n      {% endif %}\n\n      {% if security_enabled %}\n      export HDFS_NAMENODE_OPTS=\"$HDFS_NAMENODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_nn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HDFS_SECONDARYNAMENODE_OPTS=\"$HDFS_SECONDARYNAMENODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_nn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HDFS_DATANODE_OPTS=\"$HDFS_DATANODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_dn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HADOOP_JOURNALNODE_OPTS=\"$HADOOP_JOURNALNODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_jn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      {% endif %}\n\n      HDFS_NFS3_OPTS=\"-Xmx{{nfsgateway_heapsize}}m -Dhadoop.security.logger=ERROR,DRFAS ${HDFS_NFS3_OPTS}\"\n      HADOOP_BALANCER_OPTS=\"-server -Xmx{{hadoop_heapsize}}m ${HADOOP_BALANCER_OPTS}\"\n\n\n      # On secure datanodes, user to run the datanode as after dropping privileges\n      export HDFS_DATANODE_SECURE_USER=${HDFS_DATANODE_SECURE_USER:-{{hadoop_secure_dn_user}}}\n\n      # Extra ssh options.  Empty by default.\n      export HADOOP_SSH_OPTS=\"-o ConnectTimeout=5 -o SendEnv=HADOOP_CONF_DIR\"\n\n      # Where log files are stored.  $HADOOP_HOME/logs by default.\n      export HADOOP_LOG_DIR={{hdfs_log_dir_prefix}}/$USER\n\n      # Where log files are stored in the secure data environment.\n      export HADOOP_SECURE_LOG_DIR=${HADOOP_SECURE_LOG_DIR:-{{hdfs_log_dir_prefix}}/$HDFS_DATANODE_SECURE_USER}\n\n      # File naming remote slave hosts.  $HADOOP_HOME/conf/slaves by default.\n      # export HADOOP_WORKERS=${HADOOP_HOME}/conf/slaves\n\n      # host:path where hadoop code should be rsync\'d from.  Unset by default.\n      # export HADOOP_MASTER=master:/home/$USER/src/hadoop\n\n      # Seconds to sleep between slave commands.  Unset by default.  This\n      # can be useful in large clusters, where, e.g., slave rsyncs can\n      # otherwise arrive faster than the master can service them.\n      # export HADOOP_WORKER_SLEEP=0.1\n\n      # The directory where pid files are stored. /tmp by default.\n      export HADOOP_PID_DIR={{hadoop_pid_dir_prefix}}/$USER\n      export HADOOP_SECURE_PID_DIR=${HADOOP_SECURE_PID_DIR:-{{hadoop_pid_dir_prefix}}/$HDFS_DATANODE_SECURE_USER}\n\n      YARN_RESOURCEMANAGER_OPTS=\"-Dyarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY\"\n\n      # A string representing this instance of hadoop. $USER by default.\n      export HADOOP_IDENT_STRING=$USER\n\n      # The scheduling priority for daemon processes.  See \'man nice\'.\n\n      # export HADOOP_NICENESS=10\n\n      # Add database libraries\n      JAVA_JDBC_LIBS=\"\"\n      if [ -d \"/usr/share/java\" ]; then\n      for jarFile in `ls /usr/share/java | grep -E \"(mysql|ojdbc|postgresql|sqljdbc)\" 2>/dev/null`\n      do\n      JAVA_JDBC_LIBS=${JAVA_JDBC_LIBS}:$jarFile\n      done\n      fi\n\n      # Add libraries to the hadoop classpath - some may not need a colon as they already include it\n      export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}${JAVA_JDBC_LIBS}\n\n      # Setting path to hdfs command line\n      export HADOOP_LIBEXEC_DIR=/usr/sdp/current/hadoop/libexec\n\n      # Mostly required for hadoop 2.0\n      export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:/usr/sdp/current/hadoop/lib/native/Linux-{{architecture}}-64\n\n      {% if zk_principal_user is defined %}\n      HADOOP_OPTS=\"-Dzookeeper.sasl.client.username={{zk_principal_user}} $HADOOP_OPTS\"\n      {% endif %}\n\n      export HADOOP_OPTS=\"-Dsdp.version=$SDP_VERSION $HADOOP_OPTS\"\n\n\n      # Fix temporary bug, when ulimit from conf files is not picked up, without full relogin.\n      # Makes sense to fix only when runing DN as root\n      if [ \"$command\" == \"datanode\" ] && [ \"$EUID\" -eq 0 ] && [ -n \"$HDFS_DATANODE_SECURE_USER\" ]; then\n      {% if is_datanode_max_locked_memory_set %}\n      ulimit -l {{datanode_max_locked_memory}}\n      {% endif %}\n      ulimit -n {{hdfs_user_nofile_limit}}\n      fi\n      # Enable ACLs on zookeper znodes if required\n      {% if hadoop_zkfc_opts is defined %}\n      export HDFS_ZKFC_OPTS=\"{{hadoop_zkfc_opts}} $HDFS_ZKFC_OPTS\"\n      {% endif %}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:55','system','2022-12-11 06:52:55'),(99,'SDP-1.0','HDFS','NULL','hadoop-env','dtnode_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:56','system','2022-12-11 06:52:56'),(100,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:56','system','2022-12-11 06:52:56'),(101,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_pid_dir_prefix','/var/run/hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:57','system','2022-12-11 06:52:57'),(102,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_root_logger','INFO,RFA',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:57','system','2022-12-11 06:52:57'),(103,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_log_dir_prefix','/var/log/hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:57','system','2022-12-11 06:52:57'),(104,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_principal_name','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:58','system','2022-12-11 06:52:58'),(105,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_tmp_dir','/tmp',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:58','system','2022-12-11 06:52:58'),(106,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_keytab','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:59','system','2022-12-11 06:52:59'),(107,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_nofile_limit','128000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:59','system','2022-12-11 06:52:59'),(108,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_nproc_limit','65536',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:52:59','system','2022-12-11 06:52:59'),(109,'SDP-1.0','HDFS','NULL','hadoop-env','keyserver_host',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:00','system','2022-12-11 06:53:00'),(110,'SDP-1.0','HDFS','NULL','hadoop-env','keyserver_port','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:00','system','2022-12-11 06:53:00'),(111,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_backup_dir','/tmp/upgrades',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:01','system','2022-12-11 06:53:01'),(112,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:01','system','2022-12-11 06:53:01'),(113,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_maxnewsize','128',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:01','system','2022-12-11 06:53:01'),(114,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_maxpermsize','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:02','system','2022-12-11 06:53:02'),(115,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_newsize','128',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:02','system','2022-12-11 06:53:02'),(116,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_permsize','128',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:03','system','2022-12-11 06:53:03'),(117,'SDP-1.0','HDFS','NULL','hadoop-env','nfsgateway_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:03','system','2022-12-11 06:53:03'),(118,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user','hdfs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:03','system','2022-12-11 06:53:03'),(119,'SDP-1.0','HDFS','NULL','hadoop-env','proxyuser_group','users',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:04','system','2022-12-11 06:53:04'),(120,'SDP-1.0','HDFS','NULL','hadoop-policy','security.admin.operations.protocol.acl','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:04','system','2022-12-11 06:53:04'),(121,'SDP-1.0','HDFS','NULL','hadoop-policy','security.client.datanode.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:05','system','2022-12-11 06:53:05'),(122,'SDP-1.0','HDFS','NULL','hadoop-policy','security.client.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:05','system','2022-12-11 06:53:05'),(123,'SDP-1.0','HDFS','NULL','hadoop-policy','security.datanode.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:06','system','2022-12-11 06:53:06'),(124,'SDP-1.0','HDFS','NULL','hadoop-policy','security.inter.datanode.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:06','system','2022-12-11 06:53:06'),(125,'SDP-1.0','HDFS','NULL','hadoop-policy','security.inter.tracker.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:06','system','2022-12-11 06:53:06'),(126,'SDP-1.0','HDFS','NULL','hadoop-policy','security.job.client.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:07','system','2022-12-11 06:53:07'),(127,'SDP-1.0','HDFS','NULL','hadoop-policy','security.job.task.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:07','system','2022-12-11 06:53:07'),(128,'SDP-1.0','HDFS','NULL','hadoop-policy','security.namenode.protocol.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:07','system','2022-12-11 06:53:07'),(129,'SDP-1.0','HDFS','NULL','hadoop-policy','security.refresh.policy.protocol.acl','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:08','system','2022-12-11 06:53:08'),(130,'SDP-1.0','HDFS','NULL','hadoop-policy','security.refresh.usertogroups.mappings.protocol.acl','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:08','system','2022-12-11 06:53:08'),(131,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_log_max_backup_size','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:09','system','2022-12-11 06:53:09'),(132,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_log_number_of_backup_files','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:09','system','2022-12-11 06:53:09'),(133,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_security_log_max_backup_size','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:10','system','2022-12-11 06:53:10'),(134,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_security_log_number_of_backup_files','20',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:10','system','2022-12-11 06:53:10'),(135,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.block.access.token.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:10','system','2022-12-11 06:53:10'),(136,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.blockreport.initialDelay','120',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:11','system','2022-12-11 06:53:11'),(137,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.blocksize','134217728',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:11','system','2022-12-11 06:53:11'),(138,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.datanode-restart.timeout','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:12','system','2022-12-11 06:53:12'),(139,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.read.shortcircuit','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:12','system','2022-12-11 06:53:12'),(140,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.read.shortcircuit.streams.cache.size','4096',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:12','system','2022-12-11 06:53:12'),(141,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.retry.policy.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:13','system','2022-12-11 06:53:13'),(142,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.cluster.administrators',' hdfs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:13','system','2022-12-11 06:53:13'),(143,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.content-summary.limit','5000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:14','system','2022-12-11 06:53:14'),(144,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.address','0.0.0.0:50010',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:14','system','2022-12-11 06:53:14'),(145,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.balance.bandwidthPerSec','6250000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:14','system','2022-12-11 06:53:14'),(146,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.data.dir','/data/disk0/hadoop/hdfs/data',0,1,'MULTI_DISK','NON_HA','VALID','system','2022-12-11 06:53:15','system','2022-12-11 06:53:15'),(147,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.data.dir.perm','750',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:15','system','2022-12-11 06:53:15'),(148,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.du.reserved','135137647104',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:15','system','2022-12-11 06:53:15'),(149,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.failed.volumes.tolerated','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:16','system','2022-12-11 06:53:16'),(150,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.http.address','0.0.0.0:50075',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:16','system','2022-12-11 06:53:16'),(151,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.https.address','0.0.0.0:50475',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:17','system','2022-12-11 06:53:17'),(152,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.ipc.address','0.0.0.0:8010',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:17','system','2022-12-11 06:53:17'),(153,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.max.transfer.threads','16384',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:17','system','2022-12-11 06:53:17'),(154,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.domain.socket.path','/var/lib/hadoop-hdfs/dn_socket',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:18','system','2022-12-11 06:53:18'),(155,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.encrypt.data.transfer.cipher.suites','AES/CTR/NoPadding',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:18','system','2022-12-11 06:53:18'),(156,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.heartbeat.interval','3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:19','system','2022-12-11 06:53:19'),(157,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.hosts.exclude','/etc/hadoop/conf/dfs.exclude',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:19','system','2022-12-11 06:53:19'),(158,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.http.policy','HTTP_ONLY',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:19','system','2022-12-11 06:53:19'),(159,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.https.port','50470',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:20','system','2022-12-11 06:53:20'),(160,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.edits.dir','/hadoop/hdfs/journalnode',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:20','system','2022-12-11 06:53:20'),(161,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.http-address','0.0.0.0:8480',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:21','system','2022-12-11 06:53:21'),(162,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.https-address','0.0.0.0:8481',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:21','system','2022-12-11 06:53:21'),(163,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.accesstime.precision','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:22','system','2022-12-11 06:53:22'),(164,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.acls.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:22','system','2022-12-11 06:53:22'),(165,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.audit.log.async','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:22','system','2022-12-11 06:53:22'),(166,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.avoid.read.stale.datanode','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:23','system','2022-12-11 06:53:23'),(167,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.avoid.write.stale.datanode','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:23','system','2022-12-11 06:53:23'),(168,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.dir','/hadoop/hdfs/namesecondary',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:24','system','2022-12-11 06:53:24'),(169,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.edits.dir','${dfs.namenode.checkpoint.dir}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:24','system','2022-12-11 06:53:24'),(170,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.period','21600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:25','system','2022-12-11 06:53:25'),(171,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.txns','1000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:25','system','2022-12-11 06:53:25'),(172,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.fslock.fair','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:25','system','2022-12-11 06:53:25'),(173,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.handler.count','400',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:26','system','2022-12-11 06:53:26'),(174,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.http-address','%HOSTGROUP::MASTER1%:50070',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:26','system','2022-12-11 06:53:26'),(175,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.https-address','%HOSTGROUP::MASTER1%:50470',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:27','system','2022-12-11 06:53:27'),(176,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.name.dir','/data/disk0/hadoop/hdfs/namenode',0,0,'','NON_HA','VALID','system','2022-12-11 06:53:27','system','2022-12-11 06:53:27'),(177,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.name.dir.restore','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:27','system','2022-12-11 06:53:27'),(178,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.rpc-address','%HOSTGROUP::MASTER1%:8020',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:28','system','2022-12-11 06:53:28'),(179,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.safemode.threshold-pct','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:28','system','2022-12-11 06:53:28'),(180,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.secondary.http-address','%HOSTGROUP::MASTER1%:50090',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:29','system','2022-12-11 06:53:29'),(181,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.stale.datanode.interval','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:29','system','2022-12-11 06:53:29'),(182,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.startup.delay.block.deletion.sec','3600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:30','system','2022-12-11 06:53:30'),(183,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.write.stale.datanode.ratio','1.0f',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:30','system','2022-12-11 06:53:30'),(184,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.permissions.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:31','system','2022-12-11 06:53:31'),(185,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.replication','3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:31','system','2022-12-11 06:53:31'),(186,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.replication.max','50',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:31','system','2022-12-11 06:53:31'),(187,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.webhdfs.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:32','system','2022-12-11 06:53:32'),(188,'SDP-1.0','HDFS','NULL','hdfs-site','fs.permissions.umask-mode','022',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:32','system','2022-12-11 06:53:32'),(189,'SDP-1.0','HDFS','NULL','hdfs-site','hadoop.caller.context.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:33','system','2022-12-11 06:53:33'),(190,'SDP-1.0','HDFS','NULL','hdfs-site','manage.include.files','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:33','system','2022-12-11 06:53:33'),(191,'SDP-1.0','HDFS','NULL','hdfs-site','nfs.exports.allowed.hosts','* rw',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:34','system','2022-12-11 06:53:34'),(192,'SDP-1.0','HDFS','NULL','hdfs-site','nfs.file.dump.dir','/tmp/.hdfs-nfs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:34','system','2022-12-11 06:53:34'),(193,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.permissions.superusergroup','hdfs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:34','system','2022-12-11 06:53:34'),(194,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','ranger.plugin.hdfs.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:35','system','2022-12-11 06:53:35'),(195,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:35','system','2022-12-11 06:53:35'),(196,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hadoop/hdfs/audit/hdfs/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:36','system','2022-12-11 06:53:36'),(197,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:36','system','2022-12-11 06:53:36'),(198,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:36','system','2022-12-11 06:53:36'),(199,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hadoop/hdfs/audit/solr/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:37','system','2022-12-11 06:53:37'),(200,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:37','system','2022-12-11 06:53:37'),(201,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:38','system','2022-12-11 06:53:38'),(202,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.is.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:38','system','2022-12-11 06:53:38'),(203,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:38','system','2022-12-11 06:53:38'),(204,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','REPOSITORY_CONFIG_PASSWORD','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:39','system','2022-12-11 06:53:39'),(205,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','REPOSITORY_CONFIG_USERNAME','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:39','system','2022-12-11 06:53:39'),(206,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','common.name.for.certificate','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:40','system','2022-12-11 06:53:40'),(207,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:40','system','2022-12-11 06:53:40'),(208,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:40','system','2022-12-11 06:53:40'),(209,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_ranger_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:41','system','2022-12-11 06:53:41'),(210,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_ranger_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:41','system','2022-12-11 06:53:41'),(211,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','hadoop.rpc.protection','authentication',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:42','system','2022-12-11 06:53:42'),(212,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','policy_user','ambari-qa',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:42','system','2022-12-11 06:53:42'),(213,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','ranger-hdfs-plugin-enabled','No',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:42','system','2022-12-11 06:53:42'),(214,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:43','system','2022-12-11 06:53:43'),(215,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:43','system','2022-12-11 06:53:43'),(216,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:44','system','2022-12-11 06:53:44'),(217,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:44','system','2022-12-11 06:53:44'),(218,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:44','system','2022-12-11 06:53:44'),(219,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:45','system','2022-12-11 06:53:45'),(220,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:45','system','2022-12-11 06:53:45'),(221,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.pollIntervalMs','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:45','system','2022-12-11 06:53:45'),(222,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.rest.ssl.config.file','/etc/hadoop/conf/ranger-policymgr-ssl.xml',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:46','system','2022-12-11 06:53:46'),(223,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:46','system','2022-12-11 06:53:46'),(224,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:47','system','2022-12-11 06:53:47'),(225,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.service.name','{{repo_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:47','system','2022-12-11 06:53:47'),(226,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','xasecure.add-hadoop-authorization','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:47','system','2022-12-11 06:53:47'),(234,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.keypassword','bigdata',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:51','system','2022-12-11 06:53:51'),(235,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.location','/etc/security/serverKeys/keystore.jks',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:51','system','2022-12-11 06:53:51'),(236,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.password','bigdata',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:51','system','2022-12-11 06:53:51'),(237,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.type','jks',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:52','system','2022-12-11 06:53:52'),(238,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.location','/etc/security/serverKeys/all.jks',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:52','system','2022-12-11 06:53:52'),(239,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.password','bigdata',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:53','system','2022-12-11 06:53:53'),(240,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.reload.interval','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:53','system','2022-12-11 06:53:53'),(241,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.type','jks',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:53','system','2022-12-11 06:53:53'),(242,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.default.minimum-user-limit-percent','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:54','system','2022-12-11 06:53:54'),(243,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:53:54','system','2022-12-11 06:53:54'),(244,'SDP-1.0','HDFS','NULL','hadoop-metrics2.properties','content','\n{% if has_ganglia_server %}\n*.period=60\n\n*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31\n*.sink.ganglia.period=10\n\n# default for supportsparse is false\n*.sink.ganglia.supportsparse=true\n\n.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both\n.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHeapUsedM=40\n\n# Hook up to the server\nnamenode.sink.ganglia.servers={{ganglia_server_host}}:8661\ndatanode.sink.ganglia.servers={{ganglia_server_host}}:8659\njobtracker.sink.ganglia.servers={{ganglia_server_host}}:8662\ntasktracker.sink.ganglia.servers={{ganglia_server_host}}:8658\nmaptask.sink.ganglia.servers={{ganglia_server_host}}:8660\nreducetask.sink.ganglia.servers={{ganglia_server_host}}:8660\nresourcemanager.sink.ganglia.servers={{ganglia_server_host}}:8664\nnodemanager.sink.ganglia.servers={{ganglia_server_host}}:8657\nhistoryserver.sink.ganglia.servers={{ganglia_server_host}}:8666\njournalnode.sink.ganglia.servers={{ganglia_server_host}}:8654\nnimbus.sink.ganglia.servers={{ganglia_server_host}}:8649\nsupervisor.sink.ganglia.servers={{ganglia_server_host}}:8650\n\nresourcemanager.sink.ganglia.tagsForPrefix.yarn=Queue\n\n{% endif %}\n\n{% if has_metric_collector %}\n\n*.period={{metrics_collection_period}}\n*.sink.timeline.plugin.urls=file:///usr/lib/ambari-metrics-hadoop-sink/ambari-metrics-hadoop-sink.jar\n*.sink.timeline.class=org.apache.hadoop.metrics2.sink.timeline.HadoopTimelineMetricsSink\n*.sink.timeline.period={{metrics_collection_period}}\n*.sink.timeline.sendInterval={{metrics_report_interval}}000\n*.sink.timeline.slave.host.name={{hostname}}\n*.sink.timeline.zookeeper.quorum={{zookeeper_quorum}}\n*.sink.timeline.protocol={{metric_collector_protocol}}\n*.sink.timeline.port={{metric_collector_port}}\n*.sink.timeline.instanceId = {{cluster_name}}\n*.sink.timeline.set.instanceId = {{set_instanceId}}\n*.sink.timeline.host_in_memory_aggregation = {{host_in_memory_aggregation}}\n*.sink.timeline.host_in_memory_aggregation_port = {{host_in_memory_aggregation_port}}\n{% if is_aggregation_https_enabled %}\n*.sink.timeline.host_in_memory_aggregation_protocol = {{host_in_memory_aggregation_protocol}}\n{% endif %}\n\n# HTTPS properties\n*.sink.timeline.truststore.path = {{metric_truststore_path}}\n*.sink.timeline.truststore.type = {{metric_truststore_type}}\n*.sink.timeline.truststore.password = {{metric_truststore_password}}\n\ndatanode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nnamenode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nresourcemanager.sink.timeline.collector.hosts={{ams_collector_hosts}}\nnodemanager.sink.timeline.collector.hosts={{ams_collector_hosts}}\njobhistoryserver.sink.timeline.collector.hosts={{ams_collector_hosts}}\njournalnode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nmaptask.sink.timeline.collector.hosts={{ams_collector_hosts}}\nreducetask.sink.timeline.collector.hosts={{ams_collector_hosts}}\napplicationhistoryserver.sink.timeline.collector.hosts={{ams_collector_hosts}}\n\nresourcemanager.sink.timeline.tagsForPrefix.yarn=Queue\n\n{% if is_nn_client_port_configured %}\n# Namenode rpc ports customization\nnamenode.sink.timeline.metric.rpc.client.port={{nn_rpc_client_port}}\n{% endif %}\n{% if is_nn_dn_port_configured %}\nnamenode.sink.timeline.metric.rpc.datanode.port={{nn_rpc_dn_port}}\n{% endif %}\n{% if is_nn_healthcheck_port_configured %}\nnamenode.sink.timeline.metric.rpc.healthcheck.port={{nn_rpc_healthcheck_port}}\n{% endif %}\n\n{% endif %}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:56:45','system','2022-12-11 06:56:45'),(245,'SDP-1.0','HDFS','NULL','hdfs-log4j','content','\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#  http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\n\n# Define some default values that can be overridden by system properties\n# To change daemon root logger use hadoop_root_logger in hadoop-env\nhadoop.root.logger=INFO,console\nhadoop.log.dir=.\nhadoop.log.file=hadoop.log\n\n\n# Define the root logger to the system property \\\"hadoop.root.logger\\\".\nlog4j.rootLogger=${hadoop.root.logger}, EventCounter\n\n# Logging Threshold\nlog4j.threshhold=ALL\n\n#\n# Daily Rolling File Appender\n#\n\nlog4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFA.File=${hadoop.log.dir}/${hadoop.log.file}\n\n# Rollver at midnight\nlog4j.appender.DRFA.DatePattern=\'.\'yyyy-MM-dd-HH\n\n# 30-day backup\n#log4j.appender.DRFA.MaxBackupIndex=30\nlog4j.appender.DRFA.layout=org.apache.log4j.PatternLayout\n\n# Pattern format: Date LogLevel LoggerName LogMessage\nlog4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\n# Debugging Pattern format\n#log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n\n\n\n#\n# console\n# Add \\\"console\\\" to rootlogger above if you want to use this\n#\n\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n\n\n#\n# TaskLog Appender\n#\n\n#Default values\nhadoop.tasklog.taskid=null\nhadoop.tasklog.iscleanup=false\nhadoop.tasklog.noKeepSplits=4\nhadoop.tasklog.totalLogFileSize=100\nhadoop.tasklog.purgeLogSplits=true\nhadoop.tasklog.logsRetainHours=12\n\nlog4j.appender.TLA=org.apache.hadoop.mapred.TaskLogAppender\nlog4j.appender.TLA.taskId=${hadoop.tasklog.taskid}\nlog4j.appender.TLA.isCleanup=${hadoop.tasklog.iscleanup}\nlog4j.appender.TLA.totalLogFileSize=${hadoop.tasklog.totalLogFileSize}\n\nlog4j.appender.TLA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.TLA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\n\n#\n#Security audit appender\n#\nhadoop.security.logger=INFO,console\nhadoop.security.log.maxfilesize={{hadoop_security_log_max_backup_size}}MB\nhadoop.security.log.maxbackupindex={{hadoop_security_log_number_of_backup_files}}\nlog4j.category.SecurityLogger=${hadoop.security.logger}\nhadoop.security.log.file=SecurityAuth.audit\nlog4j.additivity.SecurityLogger=false\nlog4j.appender.DRFAS=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFAS.File=${hadoop.log.dir}/${hadoop.security.log.file}\nlog4j.appender.DRFAS.layout=org.apache.log4j.PatternLayout\nlog4j.appender.DRFAS.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\nlog4j.appender.DRFAS.DatePattern=\'.\'yyyy-MM-dd-HH\n\nlog4j.appender.RFAS=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RFAS.File=${hadoop.log.dir}/${hadoop.security.log.file}\nlog4j.appender.RFAS.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RFAS.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\nlog4j.appender.RFAS.MaxFileSize=${hadoop.security.log.maxfilesize}\nlog4j.appender.RFAS.MaxBackupIndex=${hadoop.security.log.maxbackupindex}\n\n#\n# hdfs audit logging\n#\nhdfs.audit.logger=INFO,console\nlog4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=${hdfs.audit.logger}\nlog4j.additivity.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=false\nlog4j.appender.DRFAAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFAAUDIT.File=${hadoop.log.dir}/hdfs-audit.log\nlog4j.appender.DRFAAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.DRFAAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.DRFAAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n#\n# NameNode metrics logging.\n# The default is to retain two namenode-metrics.log files up to 64MB each.\n#\nnamenode.metrics.logger=INFO,NullAppender\nlog4j.logger.NameNodeMetricsLog=${namenode.metrics.logger}\nlog4j.additivity.NameNodeMetricsLog=false\nlog4j.appender.NNMETRICSRFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.NNMETRICSRFA.File=${hadoop.log.dir}/namenode-metrics.log\nlog4j.appender.NNMETRICSRFA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.NNMETRICSRFA.layout.ConversionPattern=%d{ISO8601} %m%n\nlog4j.appender.NNMETRICSRFA.MaxBackupIndex=1\nlog4j.appender.NNMETRICSRFA.MaxFileSize=64MB\n\n#\n# mapred audit logging\n#\nmapred.audit.logger=INFO,console\nlog4j.logger.org.apache.hadoop.mapred.AuditLogger=${mapred.audit.logger}\nlog4j.additivity.org.apache.hadoop.mapred.AuditLogger=false\nlog4j.appender.MRAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.MRAUDIT.File=${hadoop.log.dir}/mapred-audit.log\nlog4j.appender.MRAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.MRAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.MRAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n#\n# Rolling File Appender\n#\n\nlog4j.appender.RFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RFA.File=${hadoop.log.dir}/${hadoop.log.file}\nlog4j.appender.RFA.DatePattern=\'.\'yyyy-MM-dd-HH\n# Logfile size and and 30-day backups\nlog4j.appender.RFA.MaxFileSize={{hadoop_log_max_backup_size}}MB\nlog4j.appender.RFA.MaxBackupIndex={{hadoop_log_number_of_backup_files}}\n\nlog4j.appender.RFA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} - %m%n\nlog4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n\n\n\n# Custom Logging levels\n\nhadoop.metrics.log.level=INFO\n#log4j.logger.org.apache.hadoop.mapred.JobTracker=DEBUG\n#log4j.logger.org.apache.hadoop.mapred.TaskTracker=DEBUG\n#log4j.logger.org.apache.hadoop.fs.FSNamesystem=DEBUG\nlog4j.logger.org.apache.hadoop.metrics2=${hadoop.metrics.log.level}\n\n# Jets3t library\nlog4j.logger.org.jets3t.service.impl.rest.httpclient.RestS3Service=ERROR\n\n#\n# Null Appender\n# Trap security logger on the hadoop client side\n#\nlog4j.appender.NullAppender=org.apache.log4j.varia.NullAppender\n\n#\n# Event Counter Appender\n# Sends counts of logging messages at different severity levels to Hadoop Metrics.\n#\nlog4j.appender.EventCounter=org.apache.hadoop.log.metrics.EventCounter\n\n# Removes \\\"deprecated\\\" messages\nlog4j.logger.org.apache.hadoop.conf.Configuration.deprecation=WARN\n\n#\n# HDFS block state change log from block manager\n#\n# Uncomment the following to suppress normal block state change\n# messages from BlockManager in NameNode.\n#log4j.logger.BlockStateChange=WARN\n\n# Adding logging for 3rd party library\nlog4j.logger.org.apache.commons.beanutils=WARN',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:56:48','system','2022-12-11 06:56:48'),(246,'SDP-1.0','HDFS','NULL','viewfs-mount-table','content',' ',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:09','system','2022-12-11 06:57:09'),(247,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.accessible-node-labels','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:10','system','2022-12-11 06:57:10'),(248,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.capacity','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:10','system','2022-12-11 06:57:10'),(249,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.maximum-am-resource-percent','0.2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:10','system','2022-12-11 06:57:10'),(250,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.maximum-applications','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:11','system','2022-12-11 06:57:11'),(251,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.user-limit-factor','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:11','system','2022-12-11 06:57:11'),(252,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.node-locality-delay','40',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:11','system','2022-12-11 06:57:11'),(253,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.acl_submit_applications','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:12','system','2022-12-11 06:57:12'),(254,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.acl_submit_applications','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:12','system','2022-12-11 06:57:12'),(255,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.state','RUNNING',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:13','system','2022-12-11 06:57:13'),(256,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.capacity','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:13','system','2022-12-11 06:57:13'),(257,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.acl_administer_queue','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:13','system','2022-12-11 06:57:13'),(258,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.maximum-capacity','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:14','system','2022-12-11 06:57:14'),(259,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.queues','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:14','system','2022-12-11 06:57:14'),(260,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.maximum-threads','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:15','system','2022-12-11 06:57:15'),(261,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.acl_administer_jobs','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:15','system','2022-12-11 06:57:15'),(262,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.scheduling-interval-ms','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:15','system','2022-12-11 06:57:15'),(263,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.resource-calculator','org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:16','system','2022-12-11 06:57:16'),(264,'SDP-1.0','YARN','NULL','container-executor','cgroup_root','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:16','system','2022-12-11 06:57:16'),(265,'SDP-1.0','YARN','NULL','container-executor','content','{#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#}\n\n#/*\n# * Licensed to the Apache Software Foundation (ASF) under one\n# * or more contributor license agreements.  See the NOTICE file\n# * distributed with this work for additional information\n# * regarding copyright ownership.  The ASF licenses this file\n# * to you under the Apache License, Version 2.0 (the\n# * \"License\"); you may not use this file except in compliance\n# * with the License.  You may obtain a copy of the License at\n# *\n# *     http://www.apache.org/licenses/LICENSE-2.0\n# *\n# * Unless required by applicable law or agreed to in writing, software\n# * distributed under the License is distributed on an \"AS IS\" BASIS,\n# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# * See the License for the specific language governing permissions and\n# * limitations under the License.\n# */\nyarn.nodemanager.local-dirs={{nm_local_dirs}}\nyarn.nodemanager.log-dirs={{nm_log_dirs}}\nyarn.nodemanager.linux-container-executor.group={{yarn_executor_container_group}}\nbanned.users=hdfs,yarn,mapred,bin\nmin.user.id={{min_user_id}}\n\n{{ \'[docker]\' }}\n  module.enabled={{docker_module_enabled}}\n  docker.binary={{docker_binary}}\n  docker.allowed.capabilities={{docker_allowed_capabilities}}\n  docker.allowed.devices={{docker_allowed_devices}}\n  docker.allowed.networks={{docker_allowed_networks}}\n  docker.allowed.ro-mounts={{nm_local_dirs}},{{docker_allowed_ro_mounts}}\n  docker.allowed.rw-mounts={{nm_local_dirs}},{{nm_log_dirs}},{{docker_allowed_rw_mounts}}\n  docker.privileged-containers.enabled={{docker_privileged_containers_enabled}}\n  docker.trusted.registries={{docker_trusted_registries}}\n  docker.allowed.volume-drivers={{docker_allowed_volume_drivers}}\n\n{{ \'[gpu]\' }}\n  module.enabled={{gpu_module_enabled}}\n\n{{ \'[cgroups]\' }}\n  root={{cgroup_root}}\n  yarn-hierarchy={{yarn_hierarchy}}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:16','system','2022-12-11 06:57:16'),(266,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_devices','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:17','system','2022-12-11 06:57:17'),(267,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_ro-mounts','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:17','system','2022-12-11 06:57:17'),(268,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_rw-mounts','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:18','system','2022-12-11 06:57:18'),(269,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_volume-drivers','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:18','system','2022-12-11 06:57:18'),(270,'SDP-1.0','YARN','NULL','container-executor','docker_binary','/usr/bin/docker',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:18','system','2022-12-11 06:57:18'),(271,'SDP-1.0','YARN','NULL','container-executor','docker_module_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:19','system','2022-12-11 06:57:19'),(272,'SDP-1.0','YARN','NULL','container-executor','docker_privileged-containers_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:19','system','2022-12-11 06:57:19'),(273,'SDP-1.0','YARN','NULL','container-executor','docker_trusted_registries','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:19','system','2022-12-11 06:57:19'),(274,'SDP-1.0','YARN','NULL','container-executor','gpu_module_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:20','system','2022-12-11 06:57:20'),(275,'SDP-1.0','YARN','NULL','container-executor','min_user_id','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:20','system','2022-12-11 06:57:20'),(276,'SDP-1.0','YARN','NULL','container-executor','yarn_hierarchy','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:21','system','2022-12-11 06:57:21'),(277,'SDP-1.0','YARN','NULL','ranger-yarn-audit','ranger.plugin.yarn.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:21','system','2022-12-11 06:57:21'),(278,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.credential.provider.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:21','system','2022-12-11 06:57:21'),(279,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:22','system','2022-12-11 06:57:22'),(280,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.batch.filespool.dir','/var/log/hadoop/yarn/audit/db/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:22','system','2022-12-11 06:57:22'),(281,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.jdbc.driver','{{jdbc_driver}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:22','system','2022-12-11 06:57:22'),(282,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.jdbc.url','{{audit_jdbc_url}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:23','system','2022-12-11 06:57:23'),(283,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.password','crypted',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:23','system','2022-12-11 06:57:23'),(284,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.user','{{xa_audit_db_user}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:24','system','2022-12-11 06:57:24'),(285,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:24','system','2022-12-11 06:57:24'),(286,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hadoop/yarn/audit/hdfs/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:24','system','2022-12-11 06:57:24'),(287,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:25','system','2022-12-11 06:57:25'),(288,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:25','system','2022-12-11 06:57:25'),(289,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hadoop/yarn/audit/solr/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:25','system','2022-12-11 06:57:25'),(290,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:26','system','2022-12-11 06:57:26'),(291,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:26','system','2022-12-11 06:57:26'),(292,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.is.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:27','system','2022-12-11 06:57:27'),(293,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:27','system','2022-12-11 06:57:27'),(294,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','REPOSITORY_CONFIG_PASSWORD','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:27','system','2022-12-11 06:57:27'),(295,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','REPOSITORY_CONFIG_USERNAME','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:28','system','2022-12-11 06:57:28'),(296,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','common.name.for.certificate','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:28','system','2022-12-11 06:57:28'),(297,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:28','system','2022-12-11 06:57:28'),(298,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:29','system','2022-12-11 06:57:29'),(299,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_ranger_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:29','system','2022-12-11 06:57:29'),(300,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_ranger_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:30','system','2022-12-11 06:57:30'),(301,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','hadoop.rpc.protection','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:30','system','2022-12-11 06:57:30'),(302,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','policy_user','ambari-qa',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:30','system','2022-12-11 06:57:30'),(303,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','ranger-yarn-plugin-enabled','No',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:31','system','2022-12-11 06:57:31'),(304,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:31','system','2022-12-11 06:57:31'),(305,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:32','system','2022-12-11 06:57:32'),(306,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:32','system','2022-12-11 06:57:32'),(307,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:32','system','2022-12-11 06:57:32'),(308,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:33','system','2022-12-11 06:57:33'),(309,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:33','system','2022-12-11 06:57:33'),(310,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.add-yarn-authorization','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:33','system','2022-12-11 06:57:33'),(311,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:34','system','2022-12-11 06:57:34'),(312,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.pollIntervalMs','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:34','system','2022-12-11 06:57:34'),(313,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.rest.ssl.config.file','/etc/hadoop/conf/ranger-policymgr-ssl-yarn.xml',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:35','system','2022-12-11 06:57:35'),(314,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:35','system','2022-12-11 06:57:35'),(315,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:35','system','2022-12-11 06:57:35'),(316,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.service.name','{{repo_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:36','system','2022-12-11 06:57:36'),(317,'SDP-1.0','HDFS','NULL','resource-types','yarn.resource-types','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:36','system','2022-12-11 06:57:36'),(318,'SDP-1.0','HDFS','NULL','resource-types','yarn.resource-types.yarn.io_gpu.maximum-allocation','8',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:36','system','2022-12-11 06:57:36'),(319,'SDP-1.0','YARN','NULL','yarn-env','min_user_id','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:37','system','2022-12-11 06:57:37'),(320,'SDP-1.0','YARN','NULL','yarn-env','apptimelineserver_heapsize','8072',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:37','system','2022-12-11 06:57:37'),(321,'SDP-1.0','YARN','NULL','yarn-env','content','\nexport HADOOP_YARN_HOME=/usr/sdp/current/hadoop\nexport HADOOP_LOG_DIR={{yarn_log_dir}}\nexport HADOOP_SECURE_LOG_DIR={{yarn_log_dir}}\nexport HADOOP_PID_DIR={{yarn_pid_dir}}\nexport HADOOP_SECURE_PID_DIR={{yarn_pid_dir}}\nexport HADOOP_LIBEXEC_DIR=/usr/sdp/current/hadoop/libexec\nexport JAVA_HOME={{java64_home}}\nexport JAVA_LIBRARY_PATH=\"${JAVA_LIBRARY_PATH}:{{hadoop_java_io_tmpdir}}\"\n\n# We need to add the EWMA and RFA appender for the yarn daemons only;\n# however, HADOOP_ROOT_LOGGER is shared by the yarn client and the\n# daemons. This is restrict the EWMA appender to daemons only.\nexport HADOOP_LOGLEVEL=${HADOOP_LOGLEVEL:-INFO}\nexport HADOOP_ROOT_LOGGER=${HADOOP_ROOT_LOGGER:-INFO,console}\nexport HADOOP_DAEMON_ROOT_LOGGER=${HADOOP_DAEMON_ROOT_LOGGER:-${HADOOP_LOGLEVEL},EWMA,RFA}\n\n# User for YARN daemons\nexport HADOOP_YARN_USER=${HADOOP_YARN_USER:-yarn}\n\n# some Java parameters\n# export JAVA_HOME=/home/y/libexec/jdk1.6.0/\nif [ \"$JAVA_HOME\" != \"\" ]; then\n#echo \"run java in $JAVA_HOME\"\nJAVA_HOME=$JAVA_HOME\nfi\n\nif [ \"$JAVA_HOME\" = \"\" ]; then\necho \"Error: JAVA_HOME is not set.\"\nexit 1\nfi\n\nJAVA=$JAVA_HOME/bin/java\nJAVA_HEAP_MAX=-Xmx1000m\n\n# For setting YARN specific HEAP sizes please use this\n# Parameter and set appropriately\nYARN_HEAPSIZE={{yarn_heapsize}}\n\n# check envvars which might override default args\nif [ \"$YARN_HEAPSIZE\" != \"\" ]; then\nJAVA_HEAP_MAX=\"-Xmx\"\"$YARN_HEAPSIZE\"\"m\"\nfi\n\n# Resource Manager specific parameters\n\n# Specify the max Heapsize for the ResourceManager using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1000.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_RESOURCEMANAGER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_RESOURCEMANAGER_HEAPSIZE={{resourcemanager_heapsize}}\n\n# Specify the JVM options to be used when starting the ResourceManager.\n# These options will be appended to the options specified as HADOOP_OPTS\n# and therefore may override any similar flags set in HADOOP_OPTS\n{% if security_enabled %}\nexport YARN_RESOURCEMANAGER_OPTS=\"-Djava.security.auth.login.config={{yarn_jaas_file}}\"\n{% endif %}\n\n# Node Manager specific parameters\n\n# Specify the max Heapsize for the NodeManager using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1000.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_NODEMANAGER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_NODEMANAGER_HEAPSIZE={{nodemanager_heapsize}}\n\n# Specify the max Heapsize for the timeline server using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1024.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_TIMELINESERVER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_TIMELINESERVER_HEAPSIZE={{apptimelineserver_heapsize}}\n\n{% if security_enabled %}\nexport YARN_TIMELINESERVER_OPTS=\"-Djava.security.auth.login.config={{yarn_ats_jaas_file}}\"\n{% endif %}\n\n{% if security_enabled %}\nexport YARN_TIMELINEREADER_OPTS=\"-Djava.security.auth.login.config={{yarn_ats_jaas_file}}\"\n{% endif %}\n\n{% if security_enabled %}\nexport YARN_REGISTRYDNS_OPTS=\"-Djava.security.auth.login.config={{yarn_registry_dns_jaas_file}}\"\n{% endif %}\n\n# Specify the JVM options to be used when starting the NodeManager.\n# These options will be appended to the options specified as HADOOP_OPTS\n# and therefore may override any similar flags set in HADOOP_OPTS\n{% if security_enabled %}\nexport YARN_NODEMANAGER_OPTS=\"-Djava.security.auth.login.config={{yarn_nm_jaas_file}} -Dsun.security.krb5.rcache=none\"\n{% endif %}\n\n# so that filenames w/ spaces are handled correctly in loops below\nIFS=\n\n\n# default log directory and file\nif [ \"$HADOOP_LOG_DIR\" = \"\" ]; then\nHADOOP_LOG_DIR=\"$HADOOP_YARN_HOME/logs\"\nfi\nif [ \"$HADOOP_LOGFILE\" = \"\" ]; then\nHADOOP_LOGFILE=\'yarn.log\'\nfi\n\n# default policy file for service-level authorization\nif [ \"$YARN_POLICYFILE\" = \"\" ]; then\nYARN_POLICYFILE=\"hadoop-policy.xml\"\nfi\n\n# restore ordinary behaviour\nunset IFS\n\n# YARN now uses specific subcommand options of the pattern (command)_(subcommand)_OPTS for every\n# component. Because of this, HADDOP_OPTS is now used as a simple way to specify common properties\n# between all YARN components.\nHADOOP_OPTS=\"$HADOOP_OPTS -Dyarn.id.str=$YARN_IDENT_STRING\"\nHADOOP_OPTS=\"$HADOOP_OPTS -Dyarn.policy.file=$YARN_POLICYFILE\"\nHADOOP_OPTS=\"$HADOOP_OPTS -Djava.io.tmpdir={{hadoop_java_io_tmpdir}}\"\n\n{% if security_enabled %}\nHADOOP_OPTS=\"$HADOOP_OPTS -Djavax.security.auth.useSubjectCredsOnly=false\"\n{% endif %}\n\n{% if rm_security_opts is defined %}\nYARN_RESOURCEMANAGER_OPTS=\"{{rm_security_opts}} $YARN_RESOURCEMANAGER_OPTS\"\n{% endif %}\n\nexport YARN_NODEMANAGER_OPTS=\"$YARN_NODEMANAGER_OPTS -Dnm.audit.logger=INFO,NMAUDIT\"\nexport YARN_RESOURCEMANAGER_OPTS=\"$YARN_RESOURCEMANAGER_OPTS -Dyarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY -Drm.audit.logger=INFO,RMAUDIT\"\n\n{% if registry_dns_needs_privileged_access %}\n# If the DNS server is configured to use the standard privileged port 53,\n# the environment variables YARN_REGISTRYDNS_SECURE_USER and\n# YARN_REGISTRYDNS_SECURE_EXTRA_OPTS must be set.\nexport YARN_REGISTRYDNS_SECURE_USER={{yarn_user}}\nexport YARN_REGISTRYDNS_SECURE_EXTRA_OPTS=\"-jvm server\"\n{% endif %}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:37','system','2022-12-11 06:57:37'),(322,'SDP-1.0','YARN','NULL','yarn-env','is_supported_yarn_ranger','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:38','system','2022-12-11 06:57:38'),(323,'SDP-1.0','YARN','NULL','yarn-env','nodemanager_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:38','system','2022-12-11 06:57:38'),(324,'SDP-1.0','YARN','NULL','yarn-env','registry.dns.bind-port','53',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:39','system','2022-12-11 06:57:39'),(325,'SDP-1.0','YARN','NULL','yarn-env','resourcemanager_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:39','system','2022-12-11 06:57:39'),(326,'SDP-1.0','YARN','NULL','yarn-env','service_check.queue.name','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:39','system','2022-12-11 06:57:39'),(327,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_principal_name','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:40','system','2022-12-11 06:57:40'),(328,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_user_keytab','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:40','system','2022-12-11 06:57:40'),(329,'SDP-1.0','YARN','NULL','yarn-env','yarn_cgroups_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:40','system','2022-12-11 06:57:40'),(330,'SDP-1.0','YARN','NULL','yarn-env','yarn_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:41','system','2022-12-11 06:57:41'),(331,'SDP-1.0','YARN','NULL','yarn-env','yarn_log_dir_prefix','/var/log/hadoop-yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:41','system','2022-12-11 06:57:41'),(332,'SDP-1.0','YARN','NULL','yarn-env','yarn_pid_dir_prefix','/var/run/hadoop-yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:42','system','2022-12-11 06:57:42'),(333,'SDP-1.0','YARN','NULL','yarn-env','yarn_user_nofile_limit','32768',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:42','system','2022-12-11 06:57:42'),(334,'SDP-1.0','YARN','NULL','yarn-env','yarn_user_nproc_limit','65536',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:42','system','2022-12-11 06:57:42'),(335,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_user','yarn-ats',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:43','system','2022-12-11 06:57:43'),(336,'SDP-1.0','YARN','NULL','yarn-env','yarn_user','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:57:43','system','2022-12-11 06:57:43'),(410,'SDP-1.0','YARN','NULL','yarn-log4j','content','\n#Relative to Yarn Log Dir Prefix\nyarn.log.dir=.\n#\n# Job Summary Appender\n#\n# Use following logger to send summary to separate file defined by\n# hadoop.mapreduce.jobsummary.log.file rolled daily:\n# hadoop.mapreduce.jobsummary.logger=INFO,JSA\n#\nhadoop.mapreduce.jobsummary.logger=${hadoop.root.logger}\nhadoop.mapreduce.jobsummary.log.file=hadoop-mapreduce.jobsummary.log\nlog4j.appender.JSA=org.apache.log4j.DailyRollingFileAppender\n# Set the ResourceManager summary log filename\nyarn.server.resourcemanager.appsummary.log.file=hadoop-mapreduce.jobsummary.log\n# Set the ResourceManager summary log level and appender\nyarn.server.resourcemanager.appsummary.logger=${hadoop.root.logger}\n#yarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY\n\n# To enable AppSummaryLogging for the RM,\n# set yarn.server.resourcemanager.appsummary.logger to\n# LEVEL,RMSUMMARY in hadoop-env.sh\n\n# Appender for ResourceManager Application Summary Log\n# Requires the following properties to be set\n#    - hadoop.log.dir (Hadoop Log directory)\n#    - yarn.server.resourcemanager.appsummary.log.file (resource manager app summary log filename)\n#    - yarn.server.resourcemanager.appsummary.logger (resource manager app summary log level and appender)\nlog4j.appender.RMSUMMARY=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RMSUMMARY.File=${yarn.log.dir}/${yarn.server.resourcemanager.appsummary.log.file}\nlog4j.appender.RMSUMMARY.MaxFileSize={{yarn_rm_summary_log_max_backup_size}}MB\nlog4j.appender.RMSUMMARY.MaxBackupIndex={{yarn_rm_summary_log_number_of_backup_files}}\nlog4j.appender.RMSUMMARY.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RMSUMMARY.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.JSA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.JSA.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n\nlog4j.appender.JSA.DatePattern=\'.\'yyyy-MM-dd-HH\nlog4j.appender.JSA.layout=org.apache.log4j.PatternLayout\nlog4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary=${yarn.server.resourcemanager.appsummary.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary=false\n\n# Appender for viewing information for errors and warnings\nyarn.ewma.cleanupInterval=300\nyarn.ewma.messageAgeLimitSeconds=86400\nyarn.ewma.maxUniqueMessages=250\nlog4j.appender.EWMA=org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender\nlog4j.appender.EWMA.cleanupInterval=${yarn.ewma.cleanupInterval}\nlog4j.appender.EWMA.messageAgeLimitSeconds=${yarn.ewma.messageAgeLimitSeconds}\nlog4j.appender.EWMA.maxUniqueMessages=${yarn.ewma.maxUniqueMessages}\n\n# Audit logging for ResourceManager\nrm.audit.logger=${hadoop.root.logger}\nlog4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger=${rm.audit.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger=false\nlog4j.appender.RMAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RMAUDIT.File=${yarn.log.dir}/rm-audit.log\nlog4j.appender.RMAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RMAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.RMAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n# Audit logging for NodeManager\nnm.audit.logger=${hadoop.root.logger}\nlog4j.logger.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger=${nm.audit.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger=false\nlog4j.appender.NMAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.NMAUDIT.File=${yarn.log.dir}/nm-audit.log\nlog4j.appender.NMAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.NMAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.NMAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:10','system','2022-12-11 06:58:10'),(411,'SDP-1.0','YARN','NULL','yarn-log4j','yarn_rm_summary_log_max_backup_size','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:11','system','2022-12-11 06:58:11'),(412,'SDP-1.0','YARN','NULL','yarn-log4j','yarn_rm_summary_log_number_of_backup_files','20',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:11','system','2022-12-11 06:58:11'),(413,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.proxyuser.root.hosts','%HOSTGROUP::MASTER1%',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:11','system','2022-12-11 06:58:11'),(414,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.proxyuser.root.groups','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:12','system','2022-12-11 06:58:12'),(415,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.app-cache-size','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:12','system','2022-12-11 06:58:12'),(416,'SDP-1.0','YARN','NULL','yarn-site','hadoop.http.cross-origin.allowed-origins','{{cross_origins}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:13','system','2022-12-11 06:58:13'),(417,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.bind-address','0.0.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:13','system','2022-12-11 06:58:13'),(418,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.bind-port','53',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:13','system','2022-12-11 06:58:13'),(419,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.domain-name','EXAMPLE.COM',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:14','system','2022-12-11 06:58:14'),(420,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:14','system','2022-12-11 06:58:14'),(421,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.zone-mask','255.255.255.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:14','system','2022-12-11 06:58:14'),(422,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.zone-subnet','172.17.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:15','system','2022-12-11 06:58:15'),(423,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.zk.quorum','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:15','system','2022-12-11 06:58:15'),(424,'SDP-1.0','YARN','NULL','yarn-site','manage.include.files','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:16','system','2022-12-11 06:58:16'),(425,'SDP-1.0','YARN','NULL','yarn-site','yarn.acl.enable','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:16','system','2022-12-11 06:58:16'),(426,'SDP-1.0','YARN','NULL','yarn-site','yarn.admin.acl','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:16','system','2022-12-11 06:58:16'),(427,'SDP-1.0','YARN','NULL','yarn-site','yarn.application.classpath','$HADOOP_CONF_DIR,/usr/sdp/current/hadoop/*,/usr/sdp/current/hadoop/share/hadoop/client/*,/usr/sdp/current/hadoop/share/hadoop/common/*,/usr/sdp/current/hadoop/share/hadoop/common/lib/*,/usr/sdp/current/hadoop/share/hadoop/hdfs/*,/usr/sdp/current/hadoop/share/hadoop/hdfs/lib/*,,/usr/sdp/current/hadoop/share/hadoop/mapreduce/*,/usr/sdp/current/hadoop/share/hadoop/yarn/*,/usr/sdp/current/hadoop/share/hadoop/yarn/lib/*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:17','system','2022-12-11 06:58:17'),(428,'SDP-1.0','YARN','NULL','yarn-site','yarn.client.nodemanager-connect.max-wait-ms','60000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:17','system','2022-12-11 06:58:17'),(429,'SDP-1.0','YARN','NULL','yarn-site','yarn.client.nodemanager-connect.retry-interval-ms','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:17','system','2022-12-11 06:58:17'),(430,'SDP-1.0','YARN','NULL','yarn-site','yarn.http.policy','HTTP_ONLY',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:18','system','2022-12-11 06:58:18'),(431,'SDP-1.0','YARN','NULL','yarn-site','yarn.log-aggregation-enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:18','system','2022-12-11 06:58:18'),(432,'SDP-1.0','YARN','NULL','yarn-site','yarn.log-aggregation.retain-seconds','2592000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:18','system','2022-12-11 06:58:18'),(433,'SDP-1.0','YARN','NULL','yarn-site','yarn.log.server.url','http://%HOSTGROUP::MASTER1%:19888/jobhistory/logs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:19','system','2022-12-11 06:58:19'),(434,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:19','system','2022-12-11 06:58:19'),(435,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.fs-store.retry-policy-spec','2000, 500',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:20','system','2022-12-11 06:58:20'),(436,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.fs-store.root-dir','/system/yarn/node-labels',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:20','system','2022-12-11 06:58:20'),(437,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.address','0.0.0.0:45454',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:20','system','2022-12-11 06:58:20'),(438,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.admin-env','MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:21','system','2022-12-11 06:58:21'),(439,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services','mapreduce_shuffle,spark_shuffle,spark2_shuffle,{{timeline_collector}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:21','system','2022-12-11 06:58:21'),(440,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.mapreduce_shuffle.class','org.apache.hadoop.mapred.ShuffleHandler',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:22','system','2022-12-11 06:58:22'),(441,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark2_shuffle.class','org.apache.spark.network.yarn.YarnShuffleService',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:22','system','2022-12-11 06:58:22'),(442,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark2_shuffle.classpath','/usr/sdp/current/spark/yarn/*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:22','system','2022-12-11 06:58:22'),(443,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark_shuffle.class','org.apache.spark.network.yarn.YarnShuffleService',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:23','system','2022-12-11 06:58:23'),(444,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark_shuffle.classpath','/usr/sdp/current/spark/yarn/*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:23','system','2022-12-11 06:58:23'),(445,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.timeline_collector.class','org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:23','system','2022-12-11 06:58:23'),(446,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.bind-host','0.0.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:24','system','2022-12-11 06:58:24'),(447,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-executor.class','org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:24','system','2022-12-11 06:58:24'),(448,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-metrics.unregister-delay-ms','60000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:25','system','2022-12-11 06:58:25'),(449,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-monitor.interval-ms','3000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:25','system','2022-12-11 06:58:25'),(450,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.delete.debug-delay-sec','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:25','system','2022-12-11 06:58:25'),(451,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage','90',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:26','system','2022-12-11 06:58:26'),(452,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:26','system','2022-12-11 06:58:26'),(453,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.min-healthy-disks','0.25',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:26','system','2022-12-11 06:58:26'),(454,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.health-checker.interval-ms','135000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:27','system','2022-12-11 06:58:27'),(455,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.health-checker.script.timeout-ms','60000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:27','system','2022-12-11 06:58:27'),(456,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:28','system','2022-12-11 06:58:28'),(457,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.group','hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:28','system','2022-12-11 06:58:28'),(458,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:28','system','2022-12-11 06:58:28'),(459,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.compression-type','gz',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:29','system','2022-12-11 06:58:29'),(460,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.debug-enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:29','system','2022-12-11 06:58:29'),(461,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.num-log-files-per-app','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:30','system','2022-12-11 06:58:30'),(462,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds','3600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:30','system','2022-12-11 06:58:30'),(463,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log.retain-seconds','604800',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:30','system','2022-12-11 06:58:30'),(464,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.dir','{{yarn_log_dir_prefix}}/nodemanager/recovery-state',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:31','system','2022-12-11 06:58:31'),(465,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:31','system','2022-12-11 06:58:31'),(466,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.supervised','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:32','system','2022-12-11 06:58:32'),(467,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.remote-app-log-dir','/app-logs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:32','system','2022-12-11 06:58:32'),(468,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.remote-app-log-dir-suffix','logs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:32','system','2022-12-11 06:58:32'),(469,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:33','system','2022-12-11 06:58:33'),(470,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:33','system','2022-12-11 06:58:33'),(471,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.docker-plugin','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:33','system','2022-12-11 06:58:33'),(472,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidiadocker-v1.endpoint','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:34','system','2022-12-11 06:58:34'),(473,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.path-to-discovery-executables','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:34','system','2022-12-11 06:58:34'),(474,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.cpu-vcores','12',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:35','system','2022-12-11 06:58:35'),(475,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.memory-mb','77824',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:35','system','2022-12-11 06:58:35'),(476,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.percentage-physical-cpu-limit','80',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:35','system','2022-12-11 06:58:35'),(477,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resourcemanager.connect.wait.secs','1800',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:36','system','2022-12-11 06:58:36'),(478,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.allowed-runtimes','default,docker',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:36','system','2022-12-11 06:58:36'),(479,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.allowed-container-networks','host,none,bridge',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:36','system','2022-12-11 06:58:36'),(480,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.capabilities','\n      CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,\n      SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:37','system','2022-12-11 06:58:37'),(481,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.default-container-network','host',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:37','system','2022-12-11 06:58:37'),(482,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.privileged-containers.acl','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:38','system','2022-12-11 06:58:38'),(483,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:38','system','2022-12-11 06:58:38'),(484,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.vmem-check-enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:38','system','2022-12-11 06:58:38'),(485,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.vmem-pmem-ratio','2.1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:39','system','2022-12-11 06:58:39'),(486,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.webapp.cross-origin.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:39','system','2022-12-11 06:58:39'),(487,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.am.max-attempts','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:40','system','2022-12-11 06:58:40'),(488,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.bind-host','0.0.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:40','system','2022-12-11 06:58:40'),(489,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.connect.max-wait.ms','900000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:40','system','2022-12-11 06:58:40'),(490,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.connect.retry-interval.ms','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:41','system','2022-12-11 06:58:41'),(491,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.display.per-user-apps','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:41','system','2022-12-11 06:58:41'),(492,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.fs.state-store.retry-policy-spec','2000, 500',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:42','system','2022-12-11 06:58:42'),(493,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.fs.state-store.uri',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:42','system','2022-12-11 06:58:42'),(494,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.ha.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:42','system','2022-12-11 06:58:42'),(495,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.intra-queue-preemption.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:43','system','2022-12-11 06:58:43'),(496,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.monitoring_interval','15000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:43','system','2022-12-11 06:58:43'),(497,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:44','system','2022-12-11 06:58:44'),(498,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round','0.33',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:44','system','2022-12-11 06:58:44'),(499,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.nodes.exclude-path','/etc/hadoop/conf/yarn.exclude',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:44','system','2022-12-11 06:58:44'),(500,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.placement-constraints.handler','scheduler',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:45','system','2022-12-11 06:58:45'),(501,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.recovery.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:45','system','2022-12-11 06:58:45'),(502,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.scheduler.class','org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:46','system','2022-12-11 06:58:46'),(503,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.scheduler.monitor.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:46','system','2022-12-11 06:58:46'),(504,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.state-store.max-completed-applications','${yarn.resourcemanager.max-completed-applications}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:47','system','2022-12-11 06:58:47'),(505,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.store.class','org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:47','system','2022-12-11 06:58:47'),(506,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:47','system','2022-12-11 06:58:47'),(507,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.system-metrics-publisher.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:48','system','2022-12-11 06:58:48'),(508,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.cross-origin.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:48','system','2022-12-11 06:58:48'),(509,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:49','system','2022-12-11 06:58:49'),(510,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.https.address','%HOSTGROUP::MASTER1%:8090',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:49','system','2022-12-11 06:58:49'),(511,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.work-preserving-recovery.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:49','system','2022-12-11 06:58:49'),(512,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:50','system','2022-12-11 06:58:50'),(513,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-acl','world:anyone:rwcda',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:50','system','2022-12-11 06:58:50'),(514,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-num-retries','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:51','system','2022-12-11 06:58:51'),(515,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-retry-interval-ms','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:51','system','2022-12-11 06:58:51'),(516,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-state-store.parent-path','/rmstore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:51','system','2022-12-11 06:58:51'),(517,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-timeout-ms','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:52','system','2022-12-11 06:58:52'),(518,'SDP-1.0','YARN','NULL','yarn-site','yarn.rm.system-metricspublisher.emit-container-events','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:52','system','2022-12-11 06:58:52'),(519,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.capacity.ordering-policy.priority-utilization.underutilized-preemption.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:53','system','2022-12-11 06:58:53'),(520,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.maximum-allocation-mb','77824',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:53','system','2022-12-11 06:58:53'),(521,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.maximum-allocation-vcores','12',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:53','system','2022-12-11 06:58:53'),(522,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.minimum-allocation-mb','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:54','system','2022-12-11 06:58:54'),(523,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.minimum-allocation-vcores','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:54','system','2022-12-11 06:58:54'),(524,'SDP-1.0','YARN','NULL','yarn-site','yarn.service.framework.path','/sdp/apps/yarn/service-dep.tar.gz',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:54','system','2022-12-11 06:58:54'),(525,'SDP-1.0','YARN','NULL','yarn-site','yarn.service.system-service.dir','/services',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:55','system','2022-12-11 06:58:55'),(526,'SDP-1.0','YARN','NULL','yarn-site','yarn.system-metricspublisher.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:55','system','2022-12-11 06:58:55'),(527,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.bind-host','0.0.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:56','system','2022-12-11 06:58:56'),(528,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.client.max-retries','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:56','system','2022-12-11 06:58:56'),(529,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.client.retry-interval-ms','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:56','system','2022-12-11 06:58:56'),(530,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:57','system','2022-12-11 06:58:57'),(531,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.active-dir','/ats/active/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:57','system','2022-12-11 06:58:57'),(532,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds','3600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:58','system','2022-12-11 06:58:58'),(533,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.done-dir','/ats/done/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:58','system','2022-12-11 06:58:58'),(534,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.group-id-plugin-classes','org.apache.hadoop.yarn.applications.distributedshell.DistributedShellTimelinePlugin',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:58','system','2022-12-11 06:58:58'),(535,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.group-id-plugin-classpath','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:59','system','2022-12-11 06:58:59'),(536,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.retain-seconds','604800',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:59','system','2022-12-11 06:58:59'),(537,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.scan-interval-seconds','60',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:58:59','system','2022-12-11 06:58:59'),(538,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.summary-store','org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:00','system','2022-12-11 06:59:00'),(539,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.generic-application-history.save-non-am-container-meta-info','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:00','system','2022-12-11 06:59:00'),(540,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.generic-application-history.store-class','org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:01','system','2022-12-11 06:59:01'),(541,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase-schema.prefix','prod.',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:01','system','2022-12-11 06:59:01'),(542,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase.configuration.file','file://{{yarn_hbase_conf_dir}}/hbase-site.xml',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:01','system','2022-12-11 06:59:01'),(543,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase.coprocessor.jar.hdfs.location','{{yarn_timeline_jar_location}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:02','system','2022-12-11 06:59:02'),(544,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.simple.anonymous.allowed','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:02','system','2022-12-11 06:59:02'),(545,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.type','simple',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:02','system','2022-12-11 06:59:02'),(546,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-cross-origin.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:03','system','2022-12-11 06:59:03'),(547,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.read-cache-size','104857600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:03','system','2022-12-11 06:59:03'),(548,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:04','system','2022-12-11 06:59:04'),(549,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:04','system','2022-12-11 06:59:04'),(550,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms','300000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:05','system','2022-12-11 06:59:05'),(553,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.recovery.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:06','system','2022-12-11 06:59:06'),(554,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.state-store-class','org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:06','system','2022-12-11 06:59:06'),(555,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.store-class','org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:06','system','2022-12-11 06:59:06'),(556,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.ttl-enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:07','system','2022-12-11 06:59:07'),(557,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.ttl-ms','2678400000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:07','system','2022-12-11 06:59:07'),(558,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.version','2.0f',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:07','system','2022-12-11 06:59:07'),(559,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.versions','1.5f,2.0f',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:08','system','2022-12-11 06:59:08'),(560,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.webapp.address','%HOSTGROUP::MASTER1%:8188',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:08','system','2022-12-11 06:59:08'),(561,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.webapp.https.address','%HOSTGROUP::MASTER1%:8190',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:09','system','2022-12-11 06:59:09'),(562,'SDP-1.0','YARN','NULL','yarn-site','yarn.webapp.api-service.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:09','system','2022-12-11 06:59:09'),(563,'SDP-1.0','YARN','NULL','yarn-site','yarn.webapp.ui2.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:09','system','2022-12-11 06:59:09'),(564,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','content','\n      # export JAVA_HOME=/home/y/libexec/jdk1.8.0/\n\n      export HADOOP_JOB_HISTORYSERVER_HEAPSIZE={{jobhistory_heapsize}}\n\n      # We need to add the RFA appender for the mr daemons only;\n      # however, HADOOP_MAPRED_LOGGER is shared by the mapred client and the\n      # daemons. This will restrict the RFA appender to daemons only.\n      export HADOOP_LOGLEVEL=${HADOOP_LOGLEVEL:-INFO}\n      export HADOOP_ROOT_LOGGER=${HADOOP_ROOT_LOGGER:-INFO,console}\n      export HADOOP_DAEMON_ROOT_LOGGER=${HADOOP_DAEMON_ROOT_LOGGER:-${HADOOP_LOGLEVEL},RFA}\n\n      {% if security_enabled %}\n      export MAPRED_HISTORYSERVER_OPTS=\"-Djava.security.auth.login.config={{mapred_jaas_file}}  -Djavax.security.auth.useSubjectCredsOnly=false\"\n      {% endif %}\n\n      #export HADOOP_JHS_LOGGER=INFO,RFA # Hadoop JobSummary logger.\n      #export HADOOP_IDENT_STRING= #A string representing this instance of hadoop. $USER by default\n      #export HADOOP_NICENESS= #The scheduling priority for daemons. Defaults to 0.\n      export HADOOP_OPTS=\"-Dsdp.version=$SDP_VERSION $HADOOP_OPTS\"\n      export HADOOP_OPTS=\"-Djava.io.tmpdir={{hadoop_java_io_tmpdir}} $HADOOP_OPTS\"\n      export JAVA_LIBRARY_PATH=\"${JAVA_LIBRARY_PATH}:{{hadoop_java_io_tmpdir}}\"\n\n      # History server logs\n      export HADOOP_LOG_DIR={{mapred_log_dir_prefix}}/$USER\n\n      # History server pid\n      export HADOOP_PID_DIR={{mapred_pid_dir_prefix}}/$USER',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:10','system','2022-12-11 06:59:10'),(565,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','jobhistory_heapsize','900',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:10','system','2022-12-11 06:59:10'),(566,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_log_dir_prefix','/var/log/hadoop-mapreduce',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:10','system','2022-12-11 06:59:10'),(567,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_pid_dir_prefix','/var/run/hadoop-mapreduce',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:11','system','2022-12-11 06:59:11'),(568,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user_nofile_limit','32768',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:11','system','2022-12-11 06:59:11'),(569,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user_nproc_limit','65536',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:12','system','2022-12-11 06:59:12'),(570,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user','mapred',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:12','system','2022-12-11 06:59:12'),(571,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapred.local.dir','/data/disk0/hadoop/mapred',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:12','system','2022-12-11 06:59:12'),(572,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.map.child.java.opts','-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:13','system','2022-12-11 06:59:13'),(573,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.reduce.child.java.opts','-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:13','system','2022-12-11 06:59:13'),(574,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.user.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:13','system','2022-12-11 06:59:13'),(575,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.am.max-attempts','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:14','system','2022-12-11 06:59:14'),(576,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.application.classpath','$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/sdp/${sdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${sdp.version}.jar:/etc/hadoop/conf/secure',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:14','system','2022-12-11 06:59:14'),(577,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.application.framework.path','/sdp/apps/mapreduce/mapreduce.tar.gz#mr-framework',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:14','system','2022-12-11 06:59:14'),(578,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.cluster.acls.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:15','system','2022-12-11 06:59:15'),(579,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.cluster.administrators',' hadoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:15','system','2022-12-11 06:59:15'),(580,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.framework.name','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:16','system','2022-12-11 06:59:16'),(581,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.acl-modify-job',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:16','system','2022-12-11 06:59:16'),(582,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.acl-view-job',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:16','system','2022-12-11 06:59:16'),(583,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.counters.max','130',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:17','system','2022-12-11 06:59:17'),(584,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.emit-timeline-data','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:17','system','2022-12-11 06:59:17'),(585,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.queuename','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:17','system','2022-12-11 06:59:17'),(586,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.reduce.slowstart.completedmaps','0.05',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:18','system','2022-12-11 06:59:18'),(587,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.address','%HOSTGROUP::MASTER1%:10020',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:18','system','2022-12-11 06:59:18'),(588,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.admin.acl','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:19','system','2022-12-11 06:59:19'),(589,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.bind-host','0.0.0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:19','system','2022-12-11 06:59:19'),(590,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.done-dir','/mr-history/done',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:19','system','2022-12-11 06:59:19'),(591,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.http.policy','HTTP_ONLY',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:20','system','2022-12-11 06:59:20'),(592,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.intermediate-done-dir','/mr-history/tmp',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:20','system','2022-12-11 06:59:20'),(593,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:20','system','2022-12-11 06:59:20'),(594,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.store.class','org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:21','system','2022-12-11 06:59:21'),(595,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.store.leveldb.path','/hadoop/mapreduce/jhs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:21','system','2022-12-11 06:59:21'),(596,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.webapp.address','%HOSTGROUP::MASTER1%:19888',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:22','system','2022-12-11 06:59:22'),(597,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.java.opts','-Xmx15564m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:22','system','2022-12-11 06:59:22'),(598,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:22','system','2022-12-11 06:59:22'),(599,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.memory.mb','19456',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:23','system','2022-12-11 06:59:23'),(600,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.output.compress','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:23','system','2022-12-11 06:59:23'),(601,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.sort.spill.percent','0.7',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:23','system','2022-12-11 06:59:23'),(602,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.speculative','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:24','system','2022-12-11 06:59:24'),(603,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.output.fileoutputformat.compress','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:24','system','2022-12-11 06:59:24'),(604,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.output.fileoutputformat.compress.type','BLOCK',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:24','system','2022-12-11 06:59:24'),(605,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.input.buffer.percent','0.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:25','system','2022-12-11 06:59:25'),(606,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.java.opts','-Xmx31129m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:25','system','2022-12-11 06:59:25'),(607,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:26','system','2022-12-11 06:59:26'),(608,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.memory.mb','38912',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:26','system','2022-12-11 06:59:26'),(609,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.enabled','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:26','system','2022-12-11 06:59:26'),(610,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.interval-ms','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:27','system','2022-12-11 06:59:27'),(611,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.timeout-ms','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:27','system','2022-12-11 06:59:27'),(612,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.input.buffer.percent','0.7',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:27','system','2022-12-11 06:59:27'),(613,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.merge.percent','0.66',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:28','system','2022-12-11 06:59:28'),(614,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.parallelcopies','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:28','system','2022-12-11 06:59:28'),(615,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.speculative','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:29','system','2022-12-11 06:59:29'),(616,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.shuffle.port','13562',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:29','system','2022-12-11 06:59:29'),(617,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.io.sort.factor','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:29','system','2022-12-11 06:59:29'),(618,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.io.sort.mb','2047',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:30','system','2022-12-11 06:59:30'),(619,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.timeout','300000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:30','system','2022-12-11 06:59:30'),(620,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.admin-command-opts','-Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:31','system','2022-12-11 06:59:31'),(621,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.command-opts','-Xmx15564m -Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:31','system','2022-12-11 06:59:31'),(622,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:31','system','2022-12-11 06:59:31'),(623,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.resource.mb','19456',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:32','system','2022-12-11 06:59:32'),(624,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.staging-dir','/user',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:32','system','2022-12-11 06:59:32'),(625,'SDP-1.0','TEZ','NULL','tez-env','content','\n# Tez specific configuration\nexport TEZ_CONF_DIR={{config_dir}}\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n# The java implementation to use.\nexport JAVA_HOME={{java64_home}}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:32','system','2022-12-11 06:59:32'),(626,'SDP-1.0','TEZ','NULL','tez-env','enable_heap_dump','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:33','system','2022-12-11 06:59:33'),(627,'SDP-1.0','TEZ','NULL','tez-env','heap_dump_location','/tmp',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:33','system','2022-12-11 06:59:33'),(628,'SDP-1.0','TEZ','NULL','tez-env','tez_user','tez',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:34','system','2022-12-11 06:59:34'),(629,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.service.class','org.apache.tez.dag.history.logging.proto.ProtoHistoryLoggingService',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:34','system','2022-12-11 06:59:34'),(630,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.proto-base-dir','/warehouse/tablespace/external/hive/sys.db',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:34','system','2022-12-11 06:59:34'),(631,'SDP-1.0','TEZ','NULL','tez-site','tez.queue.name','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:35','system','2022-12-11 06:59:35'),(632,'SDP-1.0','TEZ','NULL','tez-site','tez.am.java.opts','-server -Xmx15564m -Djava.net.preferIPv4Stack=true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:35','system','2022-12-11 06:59:35'),(633,'SDP-1.0','TEZ','NULL','tez-site','tez.am.am-rm.heartbeat.interval-ms.max','250',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:35','system','2022-12-11 06:59:35'),(634,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.idle.release-timeout-max.millis','20000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:36','system','2022-12-11 06:59:36'),(635,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.idle.release-timeout-min.millis','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:36','system','2022-12-11 06:59:36'),(636,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:36','system','2022-12-11 06:59:36'),(637,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.locality.delay-allocation-millis','250',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:37','system','2022-12-11 06:59:37'),(638,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.non-local-fallback.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:37','system','2022-12-11 06:59:37'),(639,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.rack-fallback.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:38','system','2022-12-11 06:59:38'),(640,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.cluster-default.cmd-opts','-server -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:38','system','2022-12-11 06:59:38'),(641,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.cmd-opts','-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB{{heap_dump_opts}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:38','system','2022-12-11 06:59:38'),(642,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:39','system','2022-12-11 06:59:39'),(643,'SDP-1.0','TEZ','NULL','tez-site','tez.am.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:39','system','2022-12-11 06:59:39'),(644,'SDP-1.0','TEZ','NULL','tez-site','tez.am.max.app.attempts','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:39','system','2022-12-11 06:59:39'),(645,'SDP-1.0','TEZ','NULL','tez-site','tez.am.maxtaskfailures.per.node','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:40','system','2022-12-11 06:59:40'),(646,'SDP-1.0','TEZ','NULL','tez-site','tez.am.resource.memory.mb','19456',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:40','system','2022-12-11 06:59:40'),(647,'SDP-1.0','TEZ','NULL','tez-site','tez.am.tez-ui.history-url.template','__HISTORY_URL_BASE__?viewPath=%2F%23%2Ftez-app%2F__APPLICATION_ID__',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:41','system','2022-12-11 06:59:41'),(648,'SDP-1.0','TEZ','NULL','tez-site','tez.am.view-acls','*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:41','system','2022-12-11 06:59:41'),(649,'SDP-1.0','TEZ','NULL','tez-site','tez.cluster.additional.classpath.prefix','/usr/sdp/${sdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${sdp.version}.jar:/etc/hadoop/conf/secure',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:41','system','2022-12-11 06:59:41'),(650,'SDP-1.0','TEZ','NULL','tez-site','tez.counters.max','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:42','system','2022-12-11 06:59:42'),(651,'SDP-1.0','TEZ','NULL','tez-site','tez.counters.max.groups','3000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:42','system','2022-12-11 06:59:42'),(652,'SDP-1.0','TEZ','NULL','tez-site','tez.generate.debug.artifacts','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:42','system','2022-12-11 06:59:42'),(653,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.max-size','1073741824',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:43','system','2022-12-11 06:59:43'),(654,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.min-size','16777216',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:43','system','2022-12-11 06:59:43'),(655,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.split-waves','1.7',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:43','system','2022-12-11 06:59:43'),(656,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.timeline-cache-plugin.old-num-dags-per-group','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:44','system','2022-12-11 06:59:44'),(657,'SDP-1.0','TEZ','NULL','tez-site','tez.lib.uris','/sdp/apps/tez/tez.tar.gz',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:44','system','2022-12-11 06:59:44'),(658,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.compress','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:45','system','2022-12-11 06:59:45'),(659,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.compress.codec','org.apache.hadoop.io.compress.SnappyCodec',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:45','system','2022-12-11 06:59:45'),(660,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.convert.user-payload.to.history-text','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:45','system','2022-12-11 06:59:45'),(661,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.io.sort.mb','5136',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:46','system','2022-12-11 06:59:46'),(662,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.optimize.local.fetch','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:46','system','2022-12-11 06:59:46'),(663,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.pipelined.sorter.sort.threads','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:46','system','2022-12-11 06:59:46'),(664,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.shuffle.fetch.buffer.percent','0.6',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:47','system','2022-12-11 06:59:47'),(665,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.shuffle.memory.limit.percent','0.25',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:47','system','2022-12-11 06:59:47'),(666,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.sorter.class','PIPELINED',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:48','system','2022-12-11 06:59:48'),(667,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.unordered.output.buffer.size-mb','1459',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:48','system','2022-12-11 06:59:48'),(668,'SDP-1.0','TEZ','NULL','tez-site','tez.session.am.dag.submit.timeout.secs','600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:48','system','2022-12-11 06:59:48'),(669,'SDP-1.0','TEZ','NULL','tez-site','tez.session.client.timeout.secs','-1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:49','system','2022-12-11 06:59:49'),(670,'SDP-1.0','TEZ','NULL','tez-site','tez.shuffle-vertex-manager.max-src-fraction','0.4',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:49','system','2022-12-11 06:59:49'),(671,'SDP-1.0','TEZ','NULL','tez-site','tez.shuffle-vertex-manager.min-src-fraction','0.2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:49','system','2022-12-11 06:59:49'),(672,'SDP-1.0','TEZ','NULL','tez-site','tez.staging-dir','/tmp/${user.name}/staging',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:50','system','2022-12-11 06:59:50'),(673,'SDP-1.0','TEZ','NULL','tez-site','tez.task.am.heartbeat.counter.interval-ms.max','4000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:50','system','2022-12-11 06:59:50'),(674,'SDP-1.0','TEZ','NULL','tez-site','tez.task.generate.counters.per.io','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:51','system','2022-12-11 06:59:51'),(675,'SDP-1.0','TEZ','NULL','tez-site','tez.task.get-task.sleep.interval-ms.max','200',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:51','system','2022-12-11 06:59:51'),(676,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.cluster-default.cmd-opts','-server -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:51','system','2022-12-11 06:59:51'),(677,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.cmd-opts','-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB{{heap_dump_opts}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:52','system','2022-12-11 06:59:52'),(678,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:52','system','2022-12-11 06:59:52'),(679,'SDP-1.0','TEZ','NULL','tez-site','tez.task.max-events-per-heartbeat','500',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:52','system','2022-12-11 06:59:52'),(680,'SDP-1.0','TEZ','NULL','tez-site','tez.task.resource.memory.mb','19456',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:53','system','2022-12-11 06:59:53'),(681,'SDP-1.0','TEZ','NULL','tez-site','tez.tez-ui.history-url.base','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:53','system','2022-12-11 06:59:53'),(682,'SDP-1.0','TEZ','NULL','tez-site','tez.use.cluster.hadoop-libs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:54','system','2022-12-11 06:59:54'),(683,'SDP-1.0','TEZ','NULL','tez-site','yarn.timeline-service.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:54','system','2022-12-11 06:59:54'),(684,'SDP-1.0','HIVE','NULL','beeline-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = BeelineLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = console\n\n# list of all appenders\nappenders = console\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# list of all loggers\nloggers = HiveConnection\n\n# HiveConnection logs useful info for dynamic service discovery\nlogger.HiveConnection.name = org.apache.hive.jdbc.HiveConnection\nlogger.HiveConnection.level = INFO\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:54','system','2022-12-11 06:59:54'),(685,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.keepAliveTime','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:55','system','2022-12-11 06:59:55'),(686,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.maxThreads','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:55','system','2022-12-11 06:59:55'),(687,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.minThreads','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:55','system','2022-12-11 06:59:55'),(688,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.numRetries','3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:56','system','2022-12-11 06:59:56'),(689,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.queueSize','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:56','system','2022-12-11 06:59:56'),(690,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.synchronous','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:57','system','2022-12-11 06:59:57'),(691,'SDP-1.0','HIVE','NULL','hive-env','alert_ldap_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:57','system','2022-12-11 06:59:57'),(692,'SDP-1.0','HIVE','NULL','hive-env','alert_ldap_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:57','system','2022-12-11 06:59:57'),(693,'SDP-1.0','HIVE','NULL','hive-env','beeline_jdbc_url_default','container',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:58','system','2022-12-11 06:59:58'),(694,'SDP-1.0','HIVE','NULL','hive-env','content','\n# The heap size of the jvm, and jvm args stared by hive shell script can be controlled via:\nif [ \"$SERVICE\" = \"metastore\" ]; then\n\n  export HADOOP_HEAPSIZE={{hive_metastore_heapsize}} # Setting for HiveMetastore\n  export HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hivemetastore-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hms_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hivemetastore.log\"\n\nfi\n\nif [ \"$SERVICE\" = \"hiveserver2\" ]; then\n\n  export HADOOP_HEAPSIZE={{hive_heapsize}} # Setting for HiveServer2 and Client\n  export HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hiveserver2-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hs2_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hiveserver2.log\"\n\nfi\n\n{% if security_enabled %}\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}\n\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS  -Xmx${HADOOP_HEAPSIZE}m\"\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS{{heap_dump_opts}}\"\n\n# Larger heap size may be required when running queries over large number of files or partitions.\n# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be\n# appropriate for hive server (hwi etc).\n\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nHADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\nexport HIVE_HOME=${HIVE_HOME:-{{hive_home_dir}}}\n\n# Hive Configuration Directory can be controlled by:\nexport HIVE_CONF_DIR=${HIVE_CONF_DIR:-{{hive_config_dir}}}\n\n# Folder containing extra libraries required for hive compilation/execution can be controlled by:\nif [ \"${HIVE_AUX_JARS_PATH}\" != \"\" ]; then\n  if [ -f \"${HIVE_AUX_JARS_PATH}\" ]; then\n    export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}\n  elif [ -d \"/usr/sdp/current/hive-webhcat/share/hcatalog\" ]; then\n    export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar\n  fi\nelif [ -d \"/usr/sdp/current/hive-webhcat/share/hcatalog\" ]; then\n  export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar\nfi\n\nexport METASTORE_PORT={{hive_metastore_port}}\n\n{% if sqla_db_used or lib_dir_available %}\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:{{jdbc_libs_dir}}\"\nexport JAVA_LIBRARY_PATH=\"$JAVA_LIBRARY_PATH:{{jdbc_libs_dir}}\"\n{% endif %}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:58','system','2022-12-11 06:59:58'),(695,'SDP-1.0','HIVE','NULL','hive-env','enable_heap_dump','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:58','system','2022-12-11 06:59:58'),(696,'SDP-1.0','HIVE','NULL','hive-env','heap_dump_location','/tmp',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:59','system','2022-12-11 06:59:59'),(697,'SDP-1.0','HIVE','NULL','hive-env','hive.atlas.hook','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:59','system','2022-12-11 06:59:59'),(698,'SDP-1.0','HIVE','NULL','hive-env','hive.heapsize','48311',0,0,NULL,'NON_HA','VALID','system','2022-12-11 06:59:59','system','2022-12-11 06:59:59'),(699,'SDP-1.0','HIVE','NULL','hive-env','hive.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:00','system','2022-12-11 07:00:00'),(700,'SDP-1.0','HIVE','NULL','hive-env','hive.metastore.heapsize','16103',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:00','system','2022-12-11 07:00:00'),(701,'SDP-1.0','HIVE','NULL','hive-env','hive_ambari_database','MySQL',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:01','system','2022-12-11 07:00:01'),(702,'SDP-1.0','HIVE','NULL','hive-env','hive_database','Existing MySQL / MariaDB Database',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:01','system','2022-12-11 07:00:01'),(703,'SDP-1.0','HIVE','NULL','hive-env','hive_database_name','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:01','system','2022-12-11 07:00:01'),(704,'SDP-1.0','HIVE','NULL','hive-env','hive_database_type','mysql',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:02','system','2022-12-11 07:00:02'),(705,'SDP-1.0','HIVE','NULL','hive-env','hive_log_dir','/var/log/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:02','system','2022-12-11 07:00:02'),(706,'SDP-1.0','HIVE','NULL','hive-env','hive_pid_dir','/var/run/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:02','system','2022-12-11 07:00:02'),(707,'SDP-1.0','HIVE','NULL','hive-env','hive_security_authorization','None',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:03','system','2022-12-11 07:00:03'),(708,'SDP-1.0','HIVE','NULL','hive-env','hive_timeline_logging_enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:03','system','2022-12-11 07:00:03'),(709,'SDP-1.0','HIVE','NULL','hive-env','hive_user_nofile_limit','32000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:04','system','2022-12-11 07:00:04'),(710,'SDP-1.0','HIVE','NULL','hive-env','hive_user_nproc_limit','16000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:04','system','2022-12-11 07:00:04'),(711,'SDP-1.0','HIVE','NULL','hive-env','test_db_connection','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:04','system','2022-12-11 07:00:04'),(712,'SDP-1.0','HIVE','NULL','hive-env','hive_user','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:05','system','2022-12-11 07:00:05'),(713,'SDP-1.0','HIVE','NULL','hive-exec-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = HiveExecLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = FA\nproperty.hive.query.id = hadoop\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = ${sys:hive.query.id}.log\n\n# list of all appenders\nappenders = console, FA\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# simple file appender\nappender.FA.type = File\nappender.FA.name = FA\nappender.FA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\nappender.FA.layout.type = PatternLayout\nappender.FA.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n\n\n# list of all loggers\nloggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:05','system','2022-12-11 07:00:05'),(714,'SDP-1.0','HIVE','NULL','hive-interactive-env','content','\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hiveserverinteractive-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hsi_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hiveserver2Interactive.log\"\n\n# The heap size of the jvm stared by hive shell script can be controlled via:\nexport HADOOP_HEAPSIZE={{hive_interactive_heapsize}} # Setting for HiveServer2 and Client\n\n{% if security_enabled %}\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}\n\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS  -Xmx${HADOOP_HEAPSIZE}m\"\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS{{heap_dump_opts}}\"\n\n# Larger heap size may be required when running queries over large number of files or partitions.\n# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be\n# appropriate for hive server (hwi etc).\n\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nHADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n# Hive Configuration Directory can be controlled by:\nexport HIVE_CONF_DIR={{hive_server_interactive_conf_dir}}\n\n# Add additional hcatalog jars\nif [ \"${HIVE_AUX_JARS_PATH}\" != \"\" ]; then\n  export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}\nelse\n  export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-server2/lib/hive-hcatalog-core.jar\nfi\n\nexport METASTORE_PORT={{hive_metastore_port}}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:05','system','2022-12-11 07:00:05'),(715,'SDP-1.0','HIVE','NULL','hive-interactive-env','enable_hive_interactive','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:06','system','2022-12-11 07:00:06'),(716,'SDP-1.0','HIVE','NULL','hive-interactive-env','hive_aux_jars','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:06','system','2022-12-11 07:00:06'),(717,'SDP-1.0','HIVE','NULL','hive-interactive-env','hive_heapsize','512',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:07','system','2022-12-11 07:00:07'),(718,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_app_name','llap0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:07','system','2022-12-11 07:00:07'),(719,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_headroom_space','12288',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:07','system','2022-12-11 07:00:07'),(720,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_heap_size','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:08','system','2022-12-11 07:00:08'),(721,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_java_opts','-XX:+AlwaysPreTouch -XX:+UseG1GC -XX:TLABSize=8m -XX:+ResizeTLAB -XX:+UseNUMA -XX:+AggressiveOpts -XX:InitiatingHeapOccupancyPercent=70 -XX:+UnlockExperimentalVMOptions -XX:G1MaxNewSizePercent=40 -XX:G1ReservePercent=20 -XX:MaxGCPauseMillis=200{{heap_dump_opts}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:08','system','2022-12-11 07:00:08'),(722,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_log_level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:08','system','2022-12-11 07:00:08'),(723,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_llap_nodes','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:09','system','2022-12-11 07:00:09'),(724,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_llap_nodes_for_llap_daemons','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:09','system','2022-12-11 07:00:09'),(725,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_retries_for_checking_llap_status','20',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:10','system','2022-12-11 07:00:10'),(726,'SDP-1.0','HIVE','NULL','hive-interactive-site','dfs.client.mmap.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:10','system','2022-12-11 07:00:10'),(727,'SDP-1.0','HIVE','NULL','hive-interactive-site','dfs.short.circuit.shared.memory.watcher.interrupt.check.ms','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:10','system','2022-12-11 07:00:10'),(728,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.auto.convert.join.noconditionaltask.size','1000000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:11','system','2022-12-11 07:00:11'),(729,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.driver.parallel.compilation','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:11','system','2022-12-11 07:00:11'),(730,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.basePersistDirectory','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:11','system','2022-12-11 07:00:11'),(731,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.bitmap.type','roaring',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:12','system','2022-12-11 07:00:12'),(732,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.broker.address.default','localhost:8082',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:12','system','2022-12-11 07:00:12'),(733,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.coordinator.address.default','localhost:8082',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:13','system','2022-12-11 07:00:13'),(734,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.http.read.timeout','PT10M',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:13','system','2022-12-11 07:00:13'),(735,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.memory.rownum.max','75000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:13','system','2022-12-11 07:00:13'),(736,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.partition.size.max','1000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:14','system','2022-12-11 07:00:14'),(737,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.segments.granularity','DAY',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:14','system','2022-12-11 07:00:14'),(738,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.maxTries','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:14','system','2022-12-11 07:00:14'),(739,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.db.type','mysql',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:15','system','2022-12-11 07:00:15'),(740,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.password','{{druid_metadata_password}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:15','system','2022-12-11 07:00:15'),(741,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.uri','jdbc:mysql://localhost:3355/druid',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:15','system','2022-12-11 07:00:15'),(742,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.username','druid',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:16','system','2022-12-11 07:00:16'),(743,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.overlord.address.default','localhost:8090',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:16','system','2022-12-11 07:00:16'),(744,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.passiveWaitTimeMs','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:17','system','2022-12-11 07:00:17'),(745,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.select.distribute','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:17','system','2022-12-11 07:00:17'),(746,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.storage.storageDirectory','{{druid_storage_dir}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:17','system','2022-12-11 07:00:17'),(747,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.working.directory','/tmp/druid-indexing',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:18','system','2022-12-11 07:00:18'),(748,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.exec.orc.split.strategy','HYBRID',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:18','system','2022-12-11 07:00:18'),(749,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.execution.mode','llap',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:18','system','2022-12-11 07:00:18'),(750,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.limit.optimize.enable','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:19','system','2022-12-11 07:00:19'),(751,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.auto.allow.uber','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:19','system','2022-12-11 07:00:19'),(752,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.client.consistent.splits','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:20','system','2022-12-11 07:00:20'),(753,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.am.liveness.heartbeat.interval.ms','10000ms',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:20','system','2022-12-11 07:00:20'),(754,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.logger','query-routing',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:20','system','2022-12-11 07:00:20'),(755,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.num.executors','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:21','system','2022-12-11 07:00:21'),(756,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.queue.name','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:21','system','2022-12-11 07:00:21'),(757,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.rpc.port','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:21','system','2022-12-11 07:00:21'),(758,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.service.hosts','@llap0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:22','system','2022-12-11 07:00:22'),(759,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.task.scheduler.enable.preemption','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:22','system','2022-12-11 07:00:22'),(760,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.vcpus.per.instance','{hive_llap_daemon_num_executors}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:23','system','2022-12-11 07:00:23'),(761,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.yarn.container.mb','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:23','system','2022-12-11 07:00:23'),(762,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.yarn.shuffle.port','15551',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:23','system','2022-12-11 07:00:23'),(763,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.enable.grace.join.in.llap','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:24','system','2022-12-11 07:00:24'),(764,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.execution.mode','only',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:24','system','2022-12-11 07:00:24'),(765,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.allocator.mmap','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:24','system','2022-12-11 07:00:24'),(766,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.allocator.mmap.path','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:25','system','2022-12-11 07:00:25'),(767,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:25','system','2022-12-11 07:00:25'),(768,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.memory.mode','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:26','system','2022-12-11 07:00:26'),(769,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.memory.size','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:26','system','2022-12-11 07:00:26'),(770,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.threadpool.size','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:26','system','2022-12-11 07:00:26'),(771,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.use.lrfu','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:27','system','2022-12-11 07:00:27'),(772,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.management.rpc.port','15004',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:27','system','2022-12-11 07:00:27'),(773,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.mapjoin.memory.oversubscribe.factor','0.3f',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:27','system','2022-12-11 07:00:27'),(774,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.object.cache.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:28','system','2022-12-11 07:00:28'),(775,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.task.scheduler.locality.delay','5000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:28','system','2022-12-11 07:00:28'),(776,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.zk.sm.connectionString','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:29','system','2022-12-11 07:00:29'),(777,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.load.data.owner','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:29','system','2022-12-11 07:00:29'),(778,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.lock.manager','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:29','system','2022-12-11 07:00:29'),(779,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.map.aggr.hash.min.reduction','0.99',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:30','system','2022-12-11 07:00:30'),(780,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.mapjoin.hybridgrace.hashtable','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:30','system','2022-12-11 07:00:30'),(781,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.materializedview.rewriting.incremental','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:30','system','2022-12-11 07:00:30'),(782,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.merge.nway.joins','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:31','system','2022-12-11 07:00:31'),(783,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.metastore.event.listeners','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:31','system','2022-12-11 07:00:31'),(784,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.optimize.dynamic.partition.hashjoin','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:31','system','2022-12-11 07:00:31'),(785,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.prewarm.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:32','system','2022-12-11 07:00:32'),(786,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.active.passive.ha.registry.namespace','hs2ActivePassiveHA',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:32','system','2022-12-11 07:00:32'),(787,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.enable.doAs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:33','system','2022-12-11 07:00:33'),(788,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.idle.operation.timeout','6h',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:33','system','2022-12-11 07:00:33'),(789,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.idle.session.timeout','1d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:33','system','2022-12-11 07:00:33'),(790,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.default.queues','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:34','system','2022-12-11 07:00:34'),(791,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.initialize.default.sessions','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:34','system','2022-12-11 07:00:34'),(792,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.custom.queue.allowed','ignore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:34','system','2022-12-11 07:00:34'),(793,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.per.default.queue','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:35','system','2022-12-11 07:00:35'),(794,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.restricted.configs','hive.execution.mode,hive.execution.engine',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:35','system','2022-12-11 07:00:35'),(795,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.thrift.http.port','10501',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:36','system','2022-12-11 07:00:36'),(796,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.thrift.port','10500',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:36','system','2022-12-11 07:00:36'),(797,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.cors.allowed.headers','X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:36','system','2022-12-11 07:00:36'),(798,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.enable.cors','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:37','system','2022-12-11 07:00:37'),(799,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.port','10502',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:37','system','2022-12-11 07:00:37'),(800,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.use.ssl','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:37','system','2022-12-11 07:00:37'),(801,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.zookeeper.namespace','hiveserver2-interactive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:38','system','2022-12-11 07:00:38'),(802,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.strict.managed.tables','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:38','system','2022-12-11 07:00:38'),(803,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.bucket.pruning','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:38','system','2022-12-11 07:00:38'),(804,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.cartesian-product.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:39','system','2022-12-11 07:00:39'),(805,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.container.size','682',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:39','system','2022-12-11 07:00:39'),(806,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.exec.print.summary','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:40','system','2022-12-11 07:00:40'),(807,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.input.generate.consistent.splits','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:40','system','2022-12-11 07:00:40'),(808,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.txn.strict.locking.mode','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:40','system','2022-12-11 07:00:40'),(809,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.minmax.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:41','system','2022-12-11 07:00:41'),(810,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.native.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:41','system','2022-12-11 07:00:41'),(811,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:41','system','2022-12-11 07:00:41'),(812,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.reduce.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:42','system','2022-12-11 07:00:42'),(813,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.groupby.maxentries','1000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:42','system','2022-12-11 07:00:42'),(814,'SDP-1.0','HIVE','NULL','hive-interactive-site','llap.shuffle.connection-keep-alive.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:43','system','2022-12-11 07:00:43'),(815,'SDP-1.0','HIVE','NULL','hive-interactive-site','llap.shuffle.connection-keep-alive.timeout','60',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:43','system','2022-12-11 07:00:43'),(816,'SDP-1.0','HIVE','NULL','hive-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = HiveLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = DRFA\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = hive.log\n\n# list of all appenders\nappenders = console, DRFA\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# daily rolling file appender\nappender.DRFA.type = RollingFile\nappender.DRFA.name = DRFA\nappender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\n# Use %pid in the filePattern to append process-id@host-name to the filename if you want separate log files for different CLI session\nappender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd-HH}\nappender.DRFA.layout.type = PatternLayout\nappender.DRFA.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n\nappender.DRFA.policies.type = Policies\nappender.DRFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.DRFA.policies.time.interval = 1\nappender.DRFA.policies.time.modulate = true\nappender.DRFA.strategy.type = DefaultRolloverStrategy\nappender.DRFA.strategy.max = {{hive2_log_maxbackupindex}}\nappender.DRFA.policies.fsize.type = SizeBasedTriggeringPolicy\nappender.DRFA.policies.fsize.size = {{hive2_log_maxfilesize}}MB\n\n# list of all loggers\nloggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:43','system','2022-12-11 07:00:43'),(817,'SDP-1.0','HIVE','NULL','hive-log4j2','hive2_log_maxbackupindex','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:44','system','2022-12-11 07:00:44'),(818,'SDP-1.0','HIVE','NULL','hive-log4j2','hive2_log_maxfilesize','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:44','system','2022-12-11 07:00:44'),(819,'SDP-1.0','HIVE','NULL','hive-site','ambari.hive.db.schema.name','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:44','system','2022-12-11 07:00:44'),(820,'SDP-1.0','HIVE','NULL','hive-site','atlas.hook.hive.maxThreads','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:45','system','2022-12-11 07:00:45'),(821,'SDP-1.0','HIVE','NULL','hive-site','atlas.hook.hive.minThreads','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:45','system','2022-12-11 07:00:45'),(822,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.autoCreateSchema','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:46','system','2022-12-11 07:00:46'),(823,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.cache.level2.type','none',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:46','system','2022-12-11 07:00:46'),(824,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.fixedDatastore','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:46','system','2022-12-11 07:00:46'),(825,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:47','system','2022-12-11 07:00:47'),(826,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join.noconditionaltask','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:47','system','2022-12-11 07:00:47'),(827,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join.noconditionaltask.size','20000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:47','system','2022-12-11 07:00:47'),(828,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.sortmerge.join','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:48','system','2022-12-11 07:00:48'),(829,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.sortmerge.join.to.mapjoin','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:48','system','2022-12-11 07:00:48'),(830,'SDP-1.0','HIVE','NULL','hive-site','hive.cbo.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:48','system','2022-12-11 07:00:48'),(831,'SDP-1.0','HIVE','NULL','hive-site','hive.cli.print.header','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:49','system','2022-12-11 07:00:49'),(832,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.class','org.apache.hadoop.hive.thrift.ZooKeeperTokenStore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:49','system','2022-12-11 07:00:49'),(833,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.zookeeper.connectString','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:50','system','2022-12-11 07:00:50'),(834,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.zookeeper.znode','/hive/cluster/delegation',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:50','system','2022-12-11 07:00:50'),(835,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.abortedtxn.threshold','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:50','system','2022-12-11 07:00:50'),(836,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.check.interval','300',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:51','system','2022-12-11 07:00:51'),(837,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.delta.num.threshold','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:51','system','2022-12-11 07:00:51'),(838,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.delta.pct.threshold','0.1f',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:51','system','2022-12-11 07:00:51'),(839,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.initiator.on','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:52','system','2022-12-11 07:00:52'),(840,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.worker.threads','2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:52','system','2022-12-11 07:00:52'),(841,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.worker.timeout','86400',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:53','system','2022-12-11 07:00:53'),(842,'SDP-1.0','HIVE','NULL','hive-site','hive.compute.query.using.stats','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:53','system','2022-12-11 07:00:53'),(843,'SDP-1.0','HIVE','NULL','hive-site','hive.convert.join.bucket.mapjoin.tez','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:53','system','2022-12-11 07:00:53'),(844,'SDP-1.0','HIVE','NULL','hive-site','hive.create.as.insert.only','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:54','system','2022-12-11 07:00:54'),(845,'SDP-1.0','HIVE','NULL','hive-site','hive.default.fileformat','TextFile',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:54','system','2022-12-11 07:00:54'),(846,'SDP-1.0','HIVE','NULL','hive-site','hive.default.fileformat.managed','ORC',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:54','system','2022-12-11 07:00:54'),(847,'SDP-1.0','HIVE','NULL','hive-site','hive.driver.parallel.compilation','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:55','system','2022-12-11 07:00:55'),(848,'SDP-1.0','HIVE','NULL','hive-site','hive.enforce.sortmergebucketmapjoin','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:55','system','2022-12-11 07:00:55'),(849,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.compress.intermediate','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:55','system','2022-12-11 07:00:55'),(850,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.compress.output','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:56','system','2022-12-11 07:00:56'),(851,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.dynamic.partition','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:56','system','2022-12-11 07:00:56'),(852,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.dynamic.partition.mode','nonstrict',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:57','system','2022-12-11 07:00:57'),(853,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.failure.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:57','system','2022-12-11 07:00:57'),(854,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.created.files','100000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:57','system','2022-12-11 07:00:57'),(855,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.dynamic.partitions','5000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:58','system','2022-12-11 07:00:58'),(856,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.dynamic.partitions.pernode','2000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:58','system','2022-12-11 07:00:58'),(857,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.orc.split.strategy','HYBRID',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:58','system','2022-12-11 07:00:58'),(858,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.parallel','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:59','system','2022-12-11 07:00:59'),(859,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.parallel.thread.number','8',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:00:59','system','2022-12-11 07:00:59'),(860,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.post.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:00','system','2022-12-11 07:01:00'),(861,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.pre.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:00','system','2022-12-11 07:01:00'),(862,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.reducers.bytes.per.reducer','67108864',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:00','system','2022-12-11 07:01:00'),(863,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.reducers.max','1009',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:01','system','2022-12-11 07:01:01'),(864,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.scratchdir','hdfs:///tmp/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:01','system','2022-12-11 07:01:01'),(865,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.submit.local.task.via.child','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:01','system','2022-12-11 07:01:01'),(866,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.submitviachild','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:02','system','2022-12-11 07:01:02'),(867,'SDP-1.0','HIVE','NULL','hive-site','hive.execution.mode','container',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:02','system','2022-12-11 07:01:02'),(868,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.aggr','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:03','system','2022-12-11 07:01:03'),(869,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.conversion','more',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:03','system','2022-12-11 07:01:03'),(870,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.conversion.threshold','1073741824',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:03','system','2022-12-11 07:01:03'),(871,'SDP-1.0','HIVE','NULL','hive-site','hive.heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:04','system','2022-12-11 07:01:04'),(872,'SDP-1.0','HIVE','NULL','hive-site','hive.hook.proto.base-directory','{hive_metastore_warehouse_external_dir}/sys.db/query_data/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:04','system','2022-12-11 07:01:04'),(873,'SDP-1.0','HIVE','NULL','hive-site','hive.limit.optimize.enable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:04','system','2022-12-11 07:01:04'),(874,'SDP-1.0','HIVE','NULL','hive-site','hive.limit.pushdown.memory.usage','0.04',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:05','system','2022-12-11 07:01:05'),(875,'SDP-1.0','HIVE','NULL','hive-site','hive.load.data.owner','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:05','system','2022-12-11 07:01:05'),(876,'SDP-1.0','HIVE','NULL','hive-site','hive.lock.manager','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:05','system','2022-12-11 07:01:05'),(877,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:06','system','2022-12-11 07:01:06'),(878,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.force.flush.memory.threshold','0.9',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:06','system','2022-12-11 07:01:06'),(879,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.min.reduction','0.5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:07','system','2022-12-11 07:01:07'),(880,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.percentmemory','0.5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:07','system','2022-12-11 07:01:07'),(881,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.bucket.cache.size','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:07','system','2022-12-11 07:01:07'),(882,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.hybridgrace.hashtable','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:08','system','2022-12-11 07:01:08'),(883,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.optimized.hashtable','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:08','system','2022-12-11 07:01:08'),(884,'SDP-1.0','HIVE','NULL','hive-site','hive.mapred.reduce.tasks.speculative.execution','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:08','system','2022-12-11 07:01:08'),(885,'SDP-1.0','HIVE','NULL','hive-site','hive.materializedview.rewriting.incremental','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:09','system','2022-12-11 07:01:09'),(886,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.mapfiles','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:09','system','2022-12-11 07:01:09'),(887,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.mapredfiles','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:10','system','2022-12-11 07:01:10'),(888,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.nway.joins','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:10','system','2022-12-11 07:01:10'),(889,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.orcfile.stripe.level','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:10','system','2022-12-11 07:01:10'),(890,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.rcfile.block.level','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:11','system','2022-12-11 07:01:11'),(891,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.size.per.task','256000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:11','system','2022-12-11 07:01:11'),(892,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.smallfiles.avgsize','16000000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:11','system','2022-12-11 07:01:11'),(893,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.tezfiles','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:12','system','2022-12-11 07:01:12'),(894,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.authorization.storage.checks','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:12','system','2022-12-11 07:01:12'),(895,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.cache.pinobjtypes','Table,Database,Type,FieldSchema,Order',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:13','system','2022-12-11 07:01:13'),(896,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.client.connect.retry.delay','5s',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:13','system','2022-12-11 07:01:13'),(897,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.client.socket.timeout','1800s',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:13','system','2022-12-11 07:01:13'),(898,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.connect.retries','24',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:14','system','2022-12-11 07:01:14'),(899,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.db.type','{{hive_metastore_db_type}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:14','system','2022-12-11 07:01:14'),(900,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.dml.events','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:14','system','2022-12-11 07:01:14'),(901,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.event.listeners','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:15','system','2022-12-11 07:01:15'),(902,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.execute.setugi','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:15','system','2022-12-11 07:01:15'),(903,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.failure.retries','24',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:16','system','2022-12-11 07:01:16'),(904,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.kerberos.keytab.file','/etc/security/keytabs/hive.service.keytab',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:16','system','2022-12-11 07:01:16'),(905,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.kerberos.principal','hive/_HOST@EXAMPLE.COM',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:16','system','2022-12-11 07:01:16'),(906,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.pre.event.listeners','org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:17','system','2022-12-11 07:01:17'),(907,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.sasl.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:17','system','2022-12-11 07:01:17'),(908,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.server.max.threads','100000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:17','system','2022-12-11 07:01:17'),(909,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.transactional.event.listeners','org.apache.hive.hcatalog.listener.DbNotificationListener',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:18','system','2022-12-11 07:01:18'),(910,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.uris','thrift://%HOSTGROUP::MASTER1%:9083',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:18','system','2022-12-11 07:01:18'),(911,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.warehouse.dir','/warehouse/tablespace/managed/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:19','system','2022-12-11 07:01:19'),(912,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.warehouse.external.dir','/warehouse/tablespace/external/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:19','system','2022-12-11 07:01:19'),(913,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.bucketmapjoin','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:19','system','2022-12-11 07:01:19'),(914,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.bucketmapjoin.sortedmerge','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:20','system','2022-12-11 07:01:20'),(915,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.constant.propagation','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:20','system','2022-12-11 07:01:20'),(916,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.dynamic.partition.hashjoin','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:20','system','2022-12-11 07:01:20'),(917,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.index.filter','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:21','system','2022-12-11 07:01:21'),(918,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.metadataonly','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:21','system','2022-12-11 07:01:21'),(919,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.null.scan','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:21','system','2022-12-11 07:01:21'),(920,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.reducededuplication','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:22','system','2022-12-11 07:01:22'),(921,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.reducededuplication.min.reducer','4',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:22','system','2022-12-11 07:01:22'),(922,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.sort.dynamic.partition','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:23','system','2022-12-11 07:01:23'),(923,'SDP-1.0','HIVE','NULL','hive-site','hive.orc.compute.splits.num.threads','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:23','system','2022-12-11 07:01:23'),(924,'SDP-1.0','HIVE','NULL','hive-site','hive.orc.splits.include.file.footer','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:23','system','2022-12-11 07:01:23'),(925,'SDP-1.0','HIVE','NULL','hive-site','hive.prewarm.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:24','system','2022-12-11 07:01:24'),(926,'SDP-1.0','HIVE','NULL','hive-site','hive.prewarm.numcontainers','3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:24','system','2022-12-11 07:01:24'),(927,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.cm.enabled','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:24','system','2022-12-11 07:01:24'),(928,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.cmrootdir','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:25','system','2022-12-11 07:01:25'),(929,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.rootdir','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:25','system','2022-12-11 07:01:25'),(930,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authenticator.manager','org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:25','system','2022-12-11 07:01:25'),(931,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authorization.auth.reads','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:26','system','2022-12-11 07:01:26'),(932,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authorization.manager','org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:26','system','2022-12-11 07:01:26'),(933,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.allow.user.substitution','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:27','system','2022-12-11 07:01:27'),(934,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication','NONE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:27','system','2022-12-11 07:01:27'),(935,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.ldap.baseDN','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:27','system','2022-12-11 07:01:27'),(936,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.pam.services','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:28','system','2022-12-11 07:01:28'),(937,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.spnego.keytab','HTTP/_HOST@EXAMPLE.COM',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:28','system','2022-12-11 07:01:28'),(938,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.spnego.principal','/etc/security/keytabs/spnego.service.keytab',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:28','system','2022-12-11 07:01:28'),(939,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.custom.authentication.class','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:29','system','2022-12-11 07:01:29'),(940,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.enable.doAs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:29','system','2022-12-11 07:01:29'),(941,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.idle.operation.timeout','6h',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:30','system','2022-12-11 07:01:30'),(942,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.idle.session.timeout','1d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:30','system','2022-12-11 07:01:30'),(943,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.logging.operation.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:30','system','2022-12-11 07:01:30'),(944,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.logging.operation.log.location','/tmp/hive/operation_logs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:31','system','2022-12-11 07:01:31'),(945,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.max.start.attempts','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:31','system','2022-12-11 07:01:31'),(946,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.support.dynamic.service.discovery','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:31','system','2022-12-11 07:01:31'),(947,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.table.type.mapping','CLASSIC',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:32','system','2022-12-11 07:01:32'),(948,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.default.queues','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:32','system','2022-12-11 07:01:32'),(949,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.initialize.default.sessions','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:33','system','2022-12-11 07:01:33'),(950,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.sessions.per.default.queue','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:33','system','2022-12-11 07:01:33'),(951,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.http.path','cliservice',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:33','system','2022-12-11 07:01:33'),(952,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.http.port','10001',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:34','system','2022-12-11 07:01:34'),(953,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.max.worker.threads','500',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:34','system','2022-12-11 07:01:34'),(954,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.port','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:34','system','2022-12-11 07:01:34'),(955,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.sasl.qop','auth',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:35','system','2022-12-11 07:01:35'),(956,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.transport.mode','binary',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:35','system','2022-12-11 07:01:35'),(957,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.use.SSL','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:36','system','2022-12-11 07:01:36'),(958,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.cors.allowed.headers','X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:36','system','2022-12-11 07:01:36'),(959,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.enable.cors','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:36','system','2022-12-11 07:01:36'),(960,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.port','10002',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:37','system','2022-12-11 07:01:37'),(961,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.use.ssl','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:37','system','2022-12-11 07:01:37'),(962,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.zookeeper.namespace','hiveserver2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:37','system','2022-12-11 07:01:37'),(963,'SDP-1.0','HIVE','NULL','hive-site','hive.service.metrics.codahale.reporter.classes','org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.Metrics2Reporter',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:38','system','2022-12-11 07:01:38'),(964,'SDP-1.0','HIVE','NULL','hive-site','hive.smbjoin.cache.rows','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:38','system','2022-12-11 07:01:38'),(965,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.autogather','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:38','system','2022-12-11 07:01:38'),(966,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.dbclass','fs',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:39','system','2022-12-11 07:01:39'),(967,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.fetch.column.stats','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:39','system','2022-12-11 07:01:39'),(968,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.fetch.partition.stats','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:40','system','2022-12-11 07:01:40'),(969,'SDP-1.0','HIVE','NULL','hive-site','hive.strict.managed.tables','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:40','system','2022-12-11 07:01:40'),(970,'SDP-1.0','HIVE','NULL','hive-site','hive.support.concurrency','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:40','system','2022-12-11 07:01:40'),(971,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.auto.reducer.parallelism','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:41','system','2022-12-11 07:01:41'),(972,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.bucket.pruning','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:41','system','2022-12-11 07:01:41'),(973,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.cartesian-product.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:41','system','2022-12-11 07:01:41'),(974,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.container.size','19456',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:42','system','2022-12-11 07:01:42'),(975,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.cpu.vcores','-1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:42','system','2022-12-11 07:01:42'),(976,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:43','system','2022-12-11 07:01:43'),(977,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning.max.data.size','104857600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:43','system','2022-12-11 07:01:43'),(978,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning.max.event.size','1048576',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:43','system','2022-12-11 07:01:43'),(979,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.exec.print.summary','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:44','system','2022-12-11 07:01:44'),(980,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.input.format','org.apache.hadoop.hive.ql.io.HiveInputFormat',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:44','system','2022-12-11 07:01:44'),(981,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.input.generate.consistent.splits','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:44','system','2022-12-11 07:01:44'),(982,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.java.opts','-server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:45','system','2022-12-11 07:01:45'),(983,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.log.level','INFO',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:45','system','2022-12-11 07:01:45'),(984,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.max.partition.factor','2.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:46','system','2022-12-11 07:01:46'),(985,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.min.partition.factor','0.25',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:46','system','2022-12-11 07:01:46'),(986,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.smb.number.waves','0.5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:46','system','2022-12-11 07:01:46'),(987,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.manager','org.apache.hadoop.hive.ql.lockmgr.DbTxnManager',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:47','system','2022-12-11 07:01:47'),(988,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.max.open.batch','1000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:47','system','2022-12-11 07:01:47'),(989,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.strict.locking.mode','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:47','system','2022-12-11 07:01:47'),(990,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.timeout','300',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:48','system','2022-12-11 07:01:48'),(991,'SDP-1.0','HIVE','NULL','hive-site','hive.user.install.directory','/user/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:48','system','2022-12-11 07:01:48'),(992,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.adaptor.usage.mode','chosen',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:48','system','2022-12-11 07:01:48'),(993,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:49','system','2022-12-11 07:01:49'),(994,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.minmax.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:49','system','2022-12-11 07:01:49'),(995,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.native.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:50','system','2022-12-11 07:01:50'),(996,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:50','system','2022-12-11 07:01:50'),(997,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.reduce.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:50','system','2022-12-11 07:01:50'),(998,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.checkinterval','4096',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:51','system','2022-12-11 07:01:51'),(999,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.flush.percent','0.1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:51','system','2022-12-11 07:01:51'),(1000,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.maxentries','100000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:51','system','2022-12-11 07:01:51'),(1001,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.client.port','2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:52','system','2022-12-11 07:01:52'),(1002,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.namespace','hive_zookeeper_namespace',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:52','system','2022-12-11 07:01:52'),(1003,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.quorum','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:53','system','2022-12-11 07:01:53'),(1004,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionDriverName','com.mysql.jdbc.Driver',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:53','system','2022-12-11 07:01:53'),(1005,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionPassword','admin',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:53','system','2022-12-11 07:01:53'),(1006,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionURL','jdbc:mysql://%HOSTGROUP::MASTER1%:3306/hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:54','system','2022-12-11 07:01:54'),(1007,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionUserName','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:54','system','2022-12-11 07:01:54'),(1008,'SDP-1.0','HIVE','NULL','hive-site','metastore.create.as.acid','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:54','system','2022-12-11 07:01:54'),(1009,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.compactor.initiator.on','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:55','system','2022-12-11 07:01:55'),(1010,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.compactor.worker.threads','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:55','system','2022-12-11 07:01:55'),(1011,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.dml.events','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:56','system','2022-12-11 07:01:56'),(1012,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.event.listeners','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:56','system','2022-12-11 07:01:56'),(1013,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:56','system','2022-12-11 07:01:56'),(1014,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.transactional.event.listeners','org.apache.hive.hcatalog.listener.DbNotificationListener',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:57','system','2022-12-11 07:01:57'),(1015,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.server2.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:57','system','2022-12-11 07:01:57'),(1016,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.service.metrics.hadoop2.component','hivemetastore',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:57','system','2022-12-11 07:01:57'),(1017,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:58','system','2022-12-11 07:01:58'),(1018,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.async.log.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:58','system','2022-12-11 07:01:58'),(1019,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.metastore.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:59','system','2022-12-11 07:01:59'),(1020,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.server2.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:59','system','2022-12-11 07:01:59'),(1021,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.service.metrics.hadoop2.component','hiveserver2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:01:59','system','2022-12-11 07:01:59'),(1022,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:00','system','2022-12-11 07:02:00'),(1023,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.metastore.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:00','system','2022-12-11 07:02:00'),(1024,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.security.authorization.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:00','system','2022-12-11 07:02:00'),(1025,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.server2.metrics.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:01','system','2022-12-11 07:02:01'),(1026,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.service.metrics.hadoop2.component','hiveserver2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:01','system','2022-12-11 07:02:01'),(1027,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:01','system','2022-12-11 07:02:01'),(1028,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = WARN\nname = LlapCliLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = WARN\nproperty.hive.root.logger = console\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = llap-cli.log\nproperty.hive.llapstatus.consolelogger.level = INFO\n\n# list of all appenders\nappenders = console, DRFA, llapstatusconsole\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %p %c{2}: %m%n\n\n# llapstatusconsole appender\nappender.llapstatusconsole.type = Console\nappender.llapstatusconsole.name = llapstatusconsole\nappender.llapstatusconsole.target = SYSTEM_OUT\nappender.llapstatusconsole.layout.type = PatternLayout\nappender.llapstatusconsole.layout.pattern = %m%n\n\n# daily rolling file appender\nappender.DRFA.type = RollingRandomAccessFile\nappender.DRFA.name = DRFA\nappender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\n# Use %pid in the filePattern to append process-id@host-name to the filename if you want separate log files for different CLI session\nappender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd-HH}\nappender.DRFA.layout.type = PatternLayout\nappender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n\nappender.DRFA.policies.type = Policies\nappender.DRFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.DRFA.policies.time.interval = 1\nappender.DRFA.policies.time.modulate = true\nappender.DRFA.strategy.type = DefaultRolloverStrategy\nappender.DRFA.strategy.max = {{llap_cli_log_maxbackupindex}}\nappender.DRFA.policies.fsize.type = SizeBasedTriggeringPolicy\nappender.DRFA.policies.fsize.size = {{llap_cli_log_maxfilesize}}MB\n\n# list of all loggers\nloggers = ZooKeeper, DataNucleus, Datastore, JPOX, HadoopConf, LlapStatusServiceDriverConsole\n\nlogger.ZooKeeper.name = org.apache.zookeeper\nlogger.ZooKeeper.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\nlogger.HadoopConf.name = org.apache.hadoop.conf.Configuration\nlogger.HadoopConf.level = ERROR\n\nlogger.LlapStatusServiceDriverConsole.name = LlapStatusServiceDriverConsole\nlogger.LlapStatusServiceDriverConsole.additivity = false\nlogger.LlapStatusServiceDriverConsole.level = ${sys:hive.llapstatus.consolelogger.level}\n\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root, DRFA\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}\nrootLogger.appenderRef.DRFA.ref = DRFA\nlogger.LlapStatusServiceDriverConsole.appenderRefs = llapstatusconsole, DRFA\nlogger.LlapStatusServiceDriverConsole.appenderRef.llapstatusconsole.ref = llapstatusconsole\nlogger.LlapStatusServiceDriverConsole.appenderRef.DRFA.ref = DRFA\n',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:02','system','2022-12-11 07:02:02'),(1029,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','llap_cli_log_maxbackupindex','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:02','system','2022-12-11 07:02:02'),(1030,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','llap_cli_log_maxfilesize','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:03','system','2022-12-11 07:02:03'),(1031,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# This is the log4j2 properties file used by llap-daemons. There\'s several loggers defined, which\n# can be selected while configuring LLAP.\n# Based on the one selected - UI links etc need to be manipulated in the system.\n# Note: Some names and logic is common to this file and llap LogHelpers. Make sure to change that\n# as well, if changing this file.\n\nstatus = INFO\nname = LlapDaemonLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.llap.daemon.log.level = {{hive_log_level}}\nproperty.llap.daemon.root.logger = console\nproperty.llap.daemon.log.dir = .\nproperty.llap.daemon.log.file = llapdaemon.log\nproperty.llap.daemon.historylog.file = llapdaemon_history.log\nproperty.llap.daemon.log.maxfilesize = {{hive_llap_log_maxfilesize}}MB\nproperty.llap.daemon.log.maxbackupindex = {{hive_llap_log_maxbackupindex}}\n\n# list of all appenders\nappenders = console, RFA, HISTORYAPPENDER, query-routing\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n\n\n# rolling file appender\nappender.RFA.type = RollingRandomAccessFile\nappender.RFA.name = RFA\nappender.RFA.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}\nappender.RFA.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}_%d{yyyy-MM-dd-HH}_%i.done\nappender.RFA.layout.type = PatternLayout\nappender.RFA.layout.pattern = %d{ISO8601} %-5p [%t (%X{fragmentId})] %c: %m%n\nappender.RFA.policies.type = Policies\nappender.RFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.RFA.policies.time.interval = 1\nappender.RFA.policies.time.modulate = true\nappender.RFA.policies.size.type = SizeBasedTriggeringPolicy\nappender.RFA.policies.size.size = ${sys:llap.daemon.log.maxfilesize}\nappender.RFA.strategy.type = DefaultRolloverStrategy\nappender.RFA.strategy.max = ${sys:llap.daemon.log.maxbackupindex}\n\n# history file appender\nappender.HISTORYAPPENDER.type = RollingRandomAccessFile\nappender.HISTORYAPPENDER.name = HISTORYAPPENDER\nappender.HISTORYAPPENDER.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}\nappender.HISTORYAPPENDER.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}_%d{yyyy-MM-dd-HH}_%i.done\nappender.HISTORYAPPENDER.layout.type = PatternLayout\nappender.HISTORYAPPENDER.layout.pattern = %m%n\nappender.HISTORYAPPENDER.policies.type = Policies\nappender.HISTORYAPPENDER.policies.size.type = SizeBasedTriggeringPolicy\nappender.HISTORYAPPENDER.policies.size.size = ${sys:llap.daemon.log.maxfilesize}\nappender.HISTORYAPPENDER.policies.time.type = TimeBasedTriggeringPolicy\nappender.HISTORYAPPENDER.policies.time.interval = 1\nappender.HISTORYAPPENDER.policies.time.modulate = true\nappender.HISTORYAPPENDER.strategy.type = DefaultRolloverStrategy\nappender.HISTORYAPPENDER.strategy.max = ${sys:llap.daemon.log.maxbackupindex}\n\n# queryId based routing file appender\nappender.query-routing.type = Routing\nappender.query-routing.name = query-routing\nappender.query-routing.routes.type = Routes\nappender.query-routing.routes.pattern = $${ctx:queryId}\n#Purge polciy for query-based Routing Appender\nappender.query-routing.purgePolicy.type = LlapRoutingAppenderPurgePolicy\n# Note: Do not change this name without changing the corresponding entry in LlapConstants\nappender.query-routing.purgePolicy.name = llapLogPurgerQueryRouting\n# default route\nappender.query-routing.routes.route-default.type = Route\nappender.query-routing.routes.route-default.key = $${ctx:queryId}\nappender.query-routing.routes.route-default.ref = RFA\n# queryId based route\nappender.query-routing.routes.route-mdc.type = Route\nappender.query-routing.routes.route-mdc.file-mdc.type = LlapWrappedAppender\nappender.query-routing.routes.route-mdc.file-mdc.name = IrrelevantName-query-routing\nappender.query-routing.routes.route-mdc.file-mdc.app.type = RandomAccessFile\nappender.query-routing.routes.route-mdc.file-mdc.app.name = file-mdc\nappender.query-routing.routes.route-mdc.file-mdc.app.fileName = ${sys:llap.daemon.log.dir}/${ctx:queryId}-${ctx:dagId}.log\nappender.query-routing.routes.route-mdc.file-mdc.app.layout.type = PatternLayout\nappender.query-routing.routes.route-mdc.file-mdc.app.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n\n\n# list of all loggers\nloggers = PerfLogger, EncodedReader, NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, HistoryLogger, LlapIoImpl, LlapIoOrc, LlapIoCache, LlapIoLocking, TezSM, TezSS, TezHC\n\nlogger.TezSM.name = org.apache.tez.runtime.library.common.shuffle.impl.ShuffleManager.fetch\nlogger.TezSM.level = WARN\nlogger.TezSS.name = org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.fetch\nlogger.TezSS.level = WARN\nlogger.TezHC.name = org.apache.tez.http.HttpConnection.url\nlogger.TezHC.level = WARN\n\nlogger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger\nlogger.PerfLogger.level = DEBUG\n\nlogger.EncodedReader.name = org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl\nlogger.EncodedReader.level = INFO\n\nlogger.LlapIoImpl.name = LlapIoImpl\nlogger.LlapIoImpl.level = INFO\n\nlogger.LlapIoOrc.name = LlapIoOrc\nlogger.LlapIoOrc.level = WARN\n\nlogger.LlapIoCache.name = LlapIoCache\nlogger.LlapIoCache.level = WARN\n\nlogger.LlapIoLocking.name = LlapIoLocking\nlogger.LlapIoLocking.level = WARN\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\nlogger.HistoryLogger.name = org.apache.hadoop.hive.llap.daemon.HistoryLogger\nlogger.HistoryLogger.level = INFO\nlogger.HistoryLogger.additivity = false\nlogger.HistoryLogger.appenderRefs = HistoryAppender\nlogger.HistoryLogger.appenderRef.HistoryAppender.ref = HISTORYAPPENDER\n\n# root logger\nrootLogger.level = ${sys:llap.daemon.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:llap.daemon.root.logger}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:03','system','2022-12-11 07:02:03'),(1032,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','hive_llap_log_maxbackupindex','240',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:03','system','2022-12-11 07:02:03'),(1033,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','hive_llap_log_maxfilesize','256',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:04','system','2022-12-11 07:02:04'),(1034,'SDP-1.0','HIVE','NULL','parquet-logging','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Properties file which configures the operation of the JDK\n# logging facility.\n\n# The system will look for this config file, first using\n# a System property specified at startup:\n#\n# >java -Djava.util.logging.config.file=myLoggingConfigFilePath\n#\n# If this property is not specified, then the config file is\n# retrieved from its default location at:\n#\n# JDK_HOME/jre/lib/logging.properties\n\n# Global logging properties.\n# ------------------------------------------\n# The set of handlers to be loaded upon startup.\n# Comma-separated list of class names.\n# (? LogManager docs say no comma here, but JDK example has comma.)\n# handlers=java.util.logging.ConsoleHandler\norg.apache.parquet.handlers= java.util.logging.FileHandler\n\n# Default global logging level.\n# Loggers and Handlers may override this level\n.level=INFO\n\n# Handlers\n# -----------------------------------------\n\n# --- ConsoleHandler ---\n# Override of global logging level\njava.util.logging.ConsoleHandler.level=INFO\njava.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter\njava.util.logging.SimpleFormatter.format=[%1$tc] %4$s: %2$s - %5$s %6$s%n\n\n# --- FileHandler ---\n# Override of global logging level\njava.util.logging.FileHandler.level=ALL\n\n# Naming style for the output file:\n# (The output file is placed in the system temporary directory.\n# %u is used to provide unique identifier for the file.\n# For more information refer\n# https://docs.oracle.com/javase/7/docs/api/java/util/logging/FileHandler.html)\njava.util.logging.FileHandler.pattern=%t/parquet-%u.log\n\n# Limiting size of output file in bytes:\njava.util.logging.FileHandler.limit=50000000\n\n# Number of output files to cycle through, by appending an\n# integer to the base file name:\njava.util.logging.FileHandler.count=1\n\n# Style of output (Simple or XML):\njava.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:04','system','2022-12-11 07:02:04'),(1035,'SDP-1.0','HIVE','NULL','ranger-hive-audit','ranger.plugin.hive.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:04','system','2022-12-11 07:02:04'),(1036,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:05','system','2022-12-11 07:02:05'),(1037,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hive/audit/hdfs/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:05','system','2022-12-11 07:02:05'),(1038,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:05','system','2022-12-11 07:02:05'),(1039,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:06','system','2022-12-11 07:02:06'),(1040,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hive/audit/solr/spool',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:06','system','2022-12-11 07:02:06'),(1041,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:07','system','2022-12-11 07:02:07'),(1042,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:07','system','2022-12-11 07:02:07'),(1043,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.is.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:07','system','2022-12-11 07:02:07'),(1044,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:08','system','2022-12-11 07:02:08'),(1045,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','REPOSITORY_CONFIG_PASSWORD','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:08','system','2022-12-11 07:02:08'),(1046,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','REPOSITORY_CONFIG_USERNAME','hive',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:08','system','2022-12-11 07:02:08'),(1047,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','common.name.for.certificate','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:09','system','2022-12-11 07:02:09'),(1048,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:09','system','2022-12-11 07:02:09'),(1049,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:10','system','2022-12-11 07:02:10'),(1050,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_ranger_admin_password','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:10','system','2022-12-11 07:02:10'),(1051,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_ranger_admin_username','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:10','system','2022-12-11 07:02:10'),(1052,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','jdbc.driverClassName','org.apache.hive.jdbc.HiveDriver',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:11','system','2022-12-11 07:02:11'),(1053,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','policy_user','ambari-qa',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:11','system','2022-12-11 07:02:11'),(1054,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:11','system','2022-12-11 07:02:11'),(1055,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:12','system','2022-12-11 07:02:12'),(1056,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:12','system','2022-12-11 07:02:12'),(1057,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:13','system','2022-12-11 07:02:13'),(1058,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:13','system','2022-12-11 07:02:13'),(1059,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:13','system','2022-12-11 07:02:13'),(1060,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:14','system','2022-12-11 07:02:14'),(1061,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.pollIntervalMs','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:14','system','2022-12-11 07:02:14'),(1062,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.rest.ssl.config.file','{{ranger_hive_ssl_config_file}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:14','system','2022-12-11 07:02:14'),(1063,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:15','system','2022-12-11 07:02:15'),(1064,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:15','system','2022-12-11 07:02:15'),(1065,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.service.name','{{repo_name}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:15','system','2022-12-11 07:02:15'),(1066,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.urlauth.filesystem.schemes','hdfs:,file:,wasb:,adl:',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:16','system','2022-12-11 07:02:16'),(1067,'SDP-1.0','HIVE','NULL','ranger-hive-security','xasecure.hive.update.xapolicies.on.grant.revoke','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:16','system','2022-12-11 07:02:16'),(1068,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.am-rm.heartbeat.interval-ms.max','10000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:17','system','2022-12-11 07:02:17'),(1069,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.client.heartbeat.poll.interval.millis','6000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:17','system','2022-12-11 07:02:17'),(1070,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.client.heartbeat.timeout.secs','90',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:17','system','2022-12-11 07:02:17'),(1071,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.node-blacklisting.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:18','system','2022-12-11 07:02:18'),(1072,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.resource.memory.mb','1536',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:18','system','2022-12-11 07:02:18'),(1073,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.task.listener.thread-count','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:18','system','2022-12-11 07:02:18'),(1074,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.task.reschedule.higher.priority','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:19','system','2022-12-11 07:02:19'),(1075,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.container.max.java.heap.fraction','-1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:19','system','2022-12-11 07:02:19'),(1076,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.dag.recovery.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:20','system','2022-12-11 07:02:20'),(1077,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.grouping.node.local.only','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:20','system','2022-12-11 07:02:20'),(1078,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.log.level','TASK_ATTEMPT',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:20','system','2022-12-11 07:02:20'),(1079,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.taskattempt-filters','SERVICE_BUSY,EXTERNAL_PREEMPTION',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:21','system','2022-12-11 07:02:21'),(1080,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.timeline.num-dags-per-group','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:21','system','2022-12-11 07:02:21'),(1081,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.lib.uris','/sdp/apps/tez/tez.tar.gz',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:21','system','2022-12-11 07:02:21'),(1082,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.enable.final-merge.in.output','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:22','system','2022-12-11 07:02:22'),(1083,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.io.sort.mb','512',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:22','system','2022-12-11 07:02:22'),(1084,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.pipelined-shuffle.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:22','system','2022-12-11 07:02:22'),(1085,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.pipelined.sorter.lazy-allocate.memory','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:23','system','2022-12-11 07:02:23'),(1086,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.report.partition.stats','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:23','system','2022-12-11 07:02:23'),(1087,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.connect.timeout','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:24','system','2022-12-11 07:02:24'),(1088,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.fetch.buffer.percent','0.6',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:24','system','2022-12-11 07:02:24'),(1089,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.fetch.verify-disk-checksum','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:24','system','2022-12-11 07:02:24'),(1090,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.keep-alive.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:25','system','2022-12-11 07:02:25'),(1091,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.memory.limit.percent','0.25',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:25','system','2022-12-11 07:02:25'),(1092,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.parallel.copies','8',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:25','system','2022-12-11 07:02:25'),(1093,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.read.timeout','30000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:26','system','2022-12-11 07:02:26'),(1094,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.ssl.enable','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:26','system','2022-12-11 07:02:26'),(1095,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.unordered.output.buffer.size-mb','100',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:27','system','2022-12-11 07:02:27'),(1096,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.unordered.output.max-per-buffer.size-bytes','134217728',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:27','system','2022-12-11 07:02:27'),(1097,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.session.am.dag.submit.timeout.secs','1209600',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:27','system','2022-12-11 07:02:27'),(1098,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.task.heartbeat.timeout.check-ms','15000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:28','system','2022-12-11 07:02:28'),(1099,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.task.timeout-ms','90000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:02:28','system','2022-12-11 07:02:28'),(1217,'SDP-1.0','SQOOP','NULL','sqoop-atlas-application.properties','atlas.jaas.KafkaClient.option.renewTicket','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:12','system','2022-12-11 07:03:12'),(1218,'SDP-1.0','SQOOP','NULL','sqoop-atlas-application.properties','atlas.jaas.KafkaClient.option.useTicketCache','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:12','system','2022-12-11 07:03:12'),(1219,'SDP-1.0','SQOOP','NULL','sqoop-env','content','\n# Set Hadoop-specific environment variables here.\n\n#Set path to where bin/hadoop is available\n#Set path to where bin/hadoop is available\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n#set the path to where bin/hbase is available\nexport HBASE_HOME=${HBASE_HOME:-{{hbase_home}}}\n\n#Set the path to where bin/hive is available\nexport HIVE_HOME=${HIVE_HOME:-{{hive_home}}}\n\n#Set the path for where zookeper config dir is\nexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}\n\n# add libthrift in hive to sqoop class path first so hive imports work\nexport SQOOP_USER_CLASSPATH=\"`ls ${HIVE_HOME}/lib/libthrift-*.jar 2> /dev/null`:${SQOOP_USER_CLASSPATH}\"',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:12','system','2022-12-11 07:03:12'),(1220,'SDP-1.0','SQOOP','NULL','sqoop-env','jdbc_drivers',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:13','system','2022-12-11 07:03:13'),(1221,'SDP-1.0','SQOOP','NULL','sqoop-env','sqoop.atlas.hook','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:13','system','2022-12-11 07:03:13'),(1222,'SDP-1.0','SQOOP','NULL','sqoop-env','sqoop_user','sqoop',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:13','system','2022-12-11 07:03:13'),(1223,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','autopurge.purgeInterval','24',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:14','system','2022-12-11 07:03:14'),(1224,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','autopurge.snapRetainCount','30',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:14','system','2022-12-11 07:03:14'),(1225,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','clientPort','2181',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:15','system','2022-12-11 07:03:15'),(1226,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','dataDir','/hadoop/zookeeper',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:15','system','2022-12-11 07:03:15'),(1227,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','initLimit','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:15','system','2022-12-11 07:03:15'),(1228,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','quorum.auth.enableSasl','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:16','system','2022-12-11 07:03:16'),(1229,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','quorum.cnxn.threads.size','20',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:16','system','2022-12-11 07:03:16'),(1230,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','syncLimit','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:16','system','2022-12-11 07:03:16'),(1231,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','tickTime','3000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:17','system','2022-12-11 07:03:17'),(1232,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','content','\nexport JAVA_HOME={{java64_home}}\nexport ZOOKEEPER_HOME={{zk_home}}\nexport ZOO_LOG_DIR={{zk_log_dir}}\nexport ZOOPIDFILE={{zk_pid_file}}\nexport SERVER_JVMFLAGS={{zk_server_heapsize}}\nexport JAVA=$JAVA_HOME/bin/java\nexport CLASSPATH=$CLASSPATH:/usr/share/zookeeper/*\n\n{% if security_enabled %}\nexport SERVER_JVMFLAGS=\"$SERVER_JVMFLAGS -Djava.security.auth.login.config={{zk_server_jaas_file}}\"\nexport CLIENT_JVMFLAGS=\"$CLIENT_JVMFLAGS -Djava.security.auth.login.config={{zk_client_jaas_file}} -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:17','system','2022-12-11 07:03:17'),(1233,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_log_dir','/var/log/zookeeper',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:17','system','2022-12-11 07:03:17'),(1234,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_pid_dir','/var/run/zookeeper',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:18','system','2022-12-11 07:03:18'),(1235,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_server_heapsize','1024',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:18','system','2022-12-11 07:03:18'),(1236,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zookeeper_keytab_path','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:19','system','2022-12-11 07:03:19'),(1237,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zookeeper_principal_name','null',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:19','system','2022-12-11 07:03:19'),(1238,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_user','zookeeper',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:19','system','2022-12-11 07:03:19'),(1239,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','content','   \n#\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#\n#\n\n#\n# ZooKeeper Logging Configuration\n#\n\n# DEFAULT: console appender only\nlog4j.rootLogger=INFO, CONSOLE, ROLLINGFILE\n\n# Example with rolling log file\n#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE\n\n# Example with rolling log file and tracing\n#log4j.rootLogger=TRACE, CONSOLE, ROLLINGFILE, TRACEFILE\n\n#\n# Log INFO level and above messages to the console\n#\nlog4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\nlog4j.appender.CONSOLE.Threshold=INFO\nlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\n\n#\n# Add ROLLINGFILE to rootLogger to get log file output\n#    Log DEBUG level and above messages to a log file\nlog4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.ROLLINGFILE.Threshold=DEBUG\nlog4j.appender.ROLLINGFILE.File={{zk_log_dir}}/zookeeper.log\nlog4j.appender.ROLLINGFILE.DatePattern=\'.\'yyyy-MM-dd-HH\n# Max log file size of 10MB\nlog4j.appender.ROLLINGFILE.MaxFileSize={{zookeeper_log_max_backup_size}}MB\n# uncomment the next line to limit number of backup files\n#log4j.appender.ROLLINGFILE.MaxBackupIndex={{zookeeper_log_number_of_backup_files}}\n\nlog4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.ROLLINGFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\n\n\n#\n# Add TRACEFILE to rootLogger to get log file output\n#    Log DEBUG level and above messages to a log file\nlog4j.appender.TRACEFILE=org.apache.log4j.FileAppender\nlog4j.appender.TRACEFILE.Threshold=TRACE\nlog4j.appender.TRACEFILE.File=zookeeper_trace.log\n\nlog4j.appender.TRACEFILE.layout=org.apache.log4j.PatternLayout\n### Notice we are including log4j\'s NDC here (%x)\nlog4j.appender.TRACEFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L][%x] - %m%n\n',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:20','system','2022-12-11 07:03:20'),(1240,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','zookeeper_log_max_backup_size','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:20','system','2022-12-11 07:03:20'),(1241,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','zookeeper_log_number_of_backup_files','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:20','system','2022-12-11 07:03:20'),(1242,'SDP-1.0','SPARK3','NULL','livy3-client-conf','livy.rsc.launcher.address',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:21','system','2022-12-11 07:03:21'),(1243,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.environment','production',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:21','system','2022-12-11 07:03:21'),(1244,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.impersonation.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:22','system','2022-12-11 07:03:22'),(1245,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.repl.enableHiveContext','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:22','system','2022-12-11 07:03:22'),(1246,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.access-control.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:22','system','2022-12-11 07:03:22'),(1247,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.csrf_protection.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:23','system','2022-12-11 07:03:23'),(1248,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.port','8999',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:23','system','2022-12-11 07:03:23'),(1249,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.mode','recovery',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:23','system','2022-12-11 07:03:23'),(1250,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.state-store','filesystem',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:24','system','2022-12-11 07:03:24'),(1251,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.state-store.url','/livy2-recovery',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:24','system','2022-12-11 07:03:24'),(1252,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.session.timeout','3600000',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:24','system','2022-12-11 07:03:24'),(1253,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.spark.master','yarn-cluster',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:25','system','2022-12-11 07:03:25'),(1254,'SDP-1.0','SPARK3','NULL','livy3-env','content','\n            #!/usr/bin/env bash\n\n            # - SPARK_HOME      Spark which you would like to use in livy\n            # - SPARK_CONF_DIR  Directory containing the Spark configuration to use.\n            # - HADOOP_CONF_DIR Directory containing the Hadoop / YARN configuration to use.\n            # - LIVY_LOG_DIR    Where log files are stored.  (Default: ${LIVY_HOME}/logs)\n            # - LIVY_PID_DIR    Where the pid file is stored. (Default: /tmp)\n            # - LIVY_SERVER_JAVA_OPTS  Java Opts for running livy server (You can set jvm related setting here, like jvm memory/gc algorithm and etc.)\n            export SPARK_HOME=/usr/sdp/current/spark3-client\n            export SPARK_CONF_DIR=/etc/spark3/conf\n            export JAVA_HOME={{java_home}}\n            export HADOOP_CONF_DIR=/etc/hadoop/conf\n            export LIVY_LOG_DIR={{livy2_log_dir}}\n            export LIVY_PID_DIR={{livy2_pid_dir}}\n            export LIVY_SERVER_JAVA_OPTS=\"-Xmx2g\"',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:25','system','2022-12-11 07:03:25'),(1255,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_log_dir','/var/log/livy2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:26','system','2022-12-11 07:03:26'),(1256,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_pid_dir','/var/run/livy2',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:26','system','2022-12-11 07:03:26'),(1257,'SDP-1.0','SPARK3','NULL','livy3-env','spark_home','/usr/sdp/current/spark3-client',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:26','system','2022-12-11 07:03:26'),(1258,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_group','livy',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:27','system','2022-12-11 07:03:27'),(1259,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_user','livy',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:27','system','2022-12-11 07:03:27'),(1260,'SDP-1.0','SPARK3','NULL','livy3-log4j-properties','content','\n            # Set everything to be logged to the console\n            log4j.rootCategory=INFO, console\n            log4j.appender.console=org.apache.log4j.ConsoleAppender\n            log4j.appender.console.target=System.err\n            log4j.appender.console.layout=org.apache.log4j.PatternLayout\n            log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\n\n            log4j.logger.org.eclipse.jetty=WARN',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:27','system','2022-12-11 07:03:27'),(1261,'SDP-1.0','SPARK3','NULL','livy3-spark-blacklist','content','\n            #\n            # Configuration override / blacklist. Defines a list of properties that users are not allowed\n            # to override when starting Spark sessions.\n            #\n            # This file takes a list of property names (one per line). Empty lines and lines starting with \"#\"\n            # are ignored.\n            #\n\n            # Disallow overriding the master and the deploy mode.\n            spark.master\n            spark.submit.deployMode\n\n            # Disallow overriding the location of Spark cached jars.\n            spark.yarn.jar\n            spark.yarn.jars\n            spark.yarn.archive\n\n            # Don\'t allow users to override the RSC timeout.\n            livy.rsc.server.idle_timeout',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:28','system','2022-12-11 07:03:28'),(1262,'SDP-1.0','SPARK3','NULL','spark3-atlas-application-properties-override','atlas.spark.enabled','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:28','system','2022-12-11 07:03:28'),(1263,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.driver.extraClassPath',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:29','system','2022-12-11 07:03:29'),(1264,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.driver.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:29','system','2022-12-11 07:03:29'),(1265,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.eventLog.dir','hdfs:///spark3-history/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:29','system','2022-12-11 07:03:29'),(1266,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.eventLog.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:30','system','2022-12-11 07:03:30'),(1267,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.executor.extraJavaOptions','-XX:+UseNUMA',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:30','system','2022-12-11 07:03:30'),(1268,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.executor.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:30','system','2022-12-11 07:03:30'),(1269,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.extraListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:31','system','2022-12-11 07:03:31'),(1270,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:31','system','2022-12-11 07:03:31'),(1271,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.interval','7d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:31','system','2022-12-11 07:03:31'),(1272,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.maxAge','90d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:32','system','2022-12-11 07:03:32'),(1273,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.logDirectory','hdfs:///spark3-history/',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:32','system','2022-12-11 07:03:32'),(1274,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.kerberos.keytab','none',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:33','system','2022-12-11 07:03:33'),(1275,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.kerberos.principal','none',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:33','system','2022-12-11 07:03:33'),(1276,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.provider','org.apache.spark.deploy.history.FsHistoryProvider',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:33','system','2022-12-11 07:03:33'),(1277,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.store.path','/var/lib/spark3/shs_db',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:34','system','2022-12-11 07:03:34'),(1278,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.ui.port','18081',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:34','system','2022-12-11 07:03:34'),(1279,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.io.compression.lz4.blockSize','128kb',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:34','system','2022-12-11 07:03:34'),(1280,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.master','yarn',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:35','system','2022-12-11 07:03:35'),(1281,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.file.buffer','1m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:35','system','2022-12-11 07:03:35'),(1282,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.io.backLog','8192',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:36','system','2022-12-11 07:03:36'),(1283,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.io.serverThreads','128',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:36','system','2022-12-11 07:03:36'),(1284,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.unsafe.file.output.buffer','5m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:36','system','2022-12-11 07:03:36'),(1285,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.autoBroadcastJoinThreshold','26214400',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:37','system','2022-12-11 07:03:37'),(1286,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.convertMetastoreOrc','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:37','system','2022-12-11 07:03:37'),(1287,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.metastore.jars','/usr/sdp/current/spark/standalone-metastore/*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:37','system','2022-12-11 07:03:37'),(1288,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.metastore.version','3.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:38','system','2022-12-11 07:03:38'),(1289,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.orc.filterPushdown','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:38','system','2022-12-11 07:03:38'),(1290,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.orc.impl','native',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:39','system','2022-12-11 07:03:39'),(1291,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.queryExecutionListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:39','system','2022-12-11 07:03:39'),(1292,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.statistics.fallBackToHdfs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:39','system','2022-12-11 07:03:39'),(1293,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.streaming.streamingQueryListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:40','system','2022-12-11 07:03:40'),(1294,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.warehouse.dir','/apps/spark/warehouse',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:40','system','2022-12-11 07:03:40'),(1295,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.unsafe.sorter.spill.reader.buffer.size','1m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:40','system','2022-12-11 07:03:40'),(1296,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.dist.files',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:41','system','2022-12-11 07:03:41'),(1297,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.historyServer.address','{{spark_history_server_host}}:{{spark_history_ui_port}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:41','system','2022-12-11 07:03:41'),(1298,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.queue','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:41','system','2022-12-11 07:03:41'),(1299,'SDP-1.0','SPARK3','NULL','spark3-env','content','\n#!/usr/bin/env bash\n\n# This file is sourced when running various Spark programs.\n# Copy it as spark-env.sh and edit that to configure Spark for your site.\n\n# Options read in YARN client mode\n#SPARK_EXECUTOR_INSTANCES=\"2\" #Number of workers to start (Default: 2)\n#SPARK_EXECUTOR_CORES=\"1\" #Number of cores for the workers (Default: 1).\n#SPARK_EXECUTOR_MEMORY=\"1G\" #Memory per Worker (e.g. 1000M, 2G) (Default: 1G)\n#SPARK_DRIVER_MEMORY=\"512M\" #Memory for Master (e.g. 1000M, 2G) (Default: 512 Mb)\n#SPARK_YARN_APP_NAME=\"spark\" #The name of your application (Default: Spark)\n#SPARK_YARN_QUEUE=\"default\" #The hadoop queue to use for allocation requests (Default: default)\n#SPARK_YARN_DIST_FILES=\"\" #Comma separated list of files to be distributed with the job.\n#SPARK_YARN_DIST_ARCHIVES=\"\" #Comma separated list of archives to be distributed with the job.\n\n{% if security_enabled %}\nexport SPARK_HISTORY_OPTS=\'-Dspark.ui.filters=org.apache.hadoop.security.authentication.server.AuthenticationFilter -Dspark.org.apache.hadoop.security.authentication.server.AuthenticationFilter.params=\"type=kerberos,kerberos.principal={{spnego_principal}},kerberos.keytab={{spnego_keytab}}\"\'\n{% endif %}\n\n\n# Generic options for the daemons used in the standalone deploy mode\n\n# Alternate conf dir. (Default: ${SPARK_HOME}/conf)\nexport SPARK_CONF_DIR=${SPARK_CONF_DIR:-{{spark_home}}/conf}\n\n# Where log files are stored.(Default:${SPARK_HOME}/logs)\n#export SPARK_LOG_DIR=${SPARK_HOME:-{{spark_home}}}/logs\nexport SPARK_LOG_DIR={{spark_log_dir}}\n\n# Where the pid file is stored. (Default: /tmp)\nexport SPARK_PID_DIR={{spark_pid_dir}}\n\n#Memory for Master, Worker and history server (default: 1024MB)\nexport SPARK_DAEMON_MEMORY={{spark_daemon_memory}}m\n\n# A string representing this instance of spark.(Default: $USER)\nSPARK_IDENT_STRING=$USER\n\n# The scheduling priority for daemons. (Default: 0)\nSPARK_NICENESS=0\n\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\nexport HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-{{hadoop_conf_dir}}}\n\n# The java implementation to use.\nexport JAVA_HOME={{java_home}}',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:42','system','2022-12-11 07:03:42'),(1300,'SDP-1.0','SPARK3','NULL','spark3-env','hive_kerberos_keytab','{{hive_kerberos_keytab}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:42','system','2022-12-11 07:03:42'),(1301,'SDP-1.0','SPARK3','NULL','spark3-env','hive_kerberos_principal','{{hive_kerberos_principal}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:43','system','2022-12-11 07:03:43'),(1302,'SDP-1.0','SPARK3','NULL','spark3-env','spark_daemon_memory','2048',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:43','system','2022-12-11 07:03:43'),(1303,'SDP-1.0','SPARK3','NULL','spark3-env','spark_log_dir','/var/log/spark3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:43','system','2022-12-11 07:03:43'),(1304,'SDP-1.0','SPARK3','NULL','spark3-env','spark_pid_dir','/var/run/spark3',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:44','system','2022-12-11 07:03:44'),(1305,'SDP-1.0','SPARK3','NULL','spark3-env','spark_thrift_cmd_opts','',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:44','system','2022-12-11 07:03:44'),(1306,'SDP-1.0','SPARK3','NULL','spark3-env','spark_group','spark',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:44','system','2022-12-11 07:03:44'),(1307,'SDP-1.0','SPARK3','NULL','spark3-env','spark_user','spark',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:45','system','2022-12-11 07:03:45'),(1308,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.exec.scratchdir','/tmp/spark',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:45','system','2022-12-11 07:03:45'),(1309,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.metastore.client.connect.retry.delay','5',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:46','system','2022-12-11 07:03:46'),(1310,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.metastore.client.socket.timeout','1800',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:46','system','2022-12-11 07:03:46'),(1311,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.enable.doAs','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:46','system','2022-12-11 07:03:46'),(1312,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.thrift.http.port','10002',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:47','system','2022-12-11 07:03:47'),(1313,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.thrift.port','10016',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:47','system','2022-12-11 07:03:47'),(1314,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.transport.mode','binary',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:47','system','2022-12-11 07:03:47'),(1315,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','metastore.catalog.default','spark',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:48','system','2022-12-11 07:03:48'),(1316,'SDP-1.0','SPARK3','NULL','spark3-log4j-properties','content','log4j.rootLogger=INFO, ROOT\nlog4j.appender.ROOT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.ROOT.DatePattern=\'.\'yyyy-MM-dd-HH\nlog4j.appender.ROOT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.ROOT.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\nlog4j.appender.ROOT.file=/var/log/spark3/spark.log\nlog4j.logger.org.apache.spark.repl.Main=WARN\nlog4j.logger.org.sparkproject.jetty=WARN\nlog4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle=ERROR\nlog4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO\nlog4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO\nlog4j.logger.org.apache.parquet=ERROR\nlog4j.logger.parquet=ERROR\nlog4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL\nlog4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR\nlog4j.appender.console.filter.1=org.apache.log4j.varia.StringMatchFilter\nlog4j.appender.console.filter.1.AcceptOnMatch=false',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:48','system','2022-12-11 07:03:48'),(1317,'SDP-1.0','SPARK3','NULL','spark3-metrics-properties','content','\n# syntax: [instance].sink|source.[name].[options]=[value]\n\n# This file configures Spark\'s internal metrics system. The metrics system is\n# divided into instances which correspond to internal components.\n# Each instance can be configured to report its metrics to one or more sinks.\n# Accepted values for [instance] are \"master\", \"worker\", \"executor\", \"driver\",\n# and \"applications\". A wild card \"*\" can be used as an instance name, in\n# which case all instances will inherit the supplied property.\n#\n# Within an instance, a \"source\" specifies a particular set of grouped metrics.\n# there are two kinds of sources:\n# 1. Spark internal sources, like MasterSource, WorkerSource, etc, which will\n# collect a Spark component\'s internal state. Each instance is paired with a\n# Spark source that is added automatically.\n# 2. Common sources, like JvmSource, which will collect low level state.\n# These can be added through configuration options and are then loaded\n# using reflection.\n#\n# A \"sink\" specifies where metrics are delivered to. Each instance can be\n# assigned one or more sinks.\n#\n# The sink|source field specifies whether the property relates to a sink or\n# source.\n#\n# The [name] field specifies the name of source or sink.\n#\n# The [options] field is the specific property of this source or sink. The\n# source or sink is responsible for parsing this property.\n#\n# Notes:\n# 1. To add a new sink, set the \"class\" option to a fully qualified class\n# name (see examples below).\n# 2. Some sinks involve a polling period. The minimum allowed polling period\n# is 1 second.\n# 3. Wild card properties can be overridden by more specific properties.\n# For example, master.sink.console.period takes precedence over\n# *.sink.console.period.\n# 4. A metrics specific configuration\n# \"spark.metrics.conf=${SPARK_HOME}/conf/metrics.properties\" should be\n# added to Java properties using -Dspark.metrics.conf=xxx if you want to\n# customize metrics system. You can also put the file in ${SPARK_HOME}/conf\n# and it will be loaded automatically.\n# 5. MetricsServlet is added by default as a sink in master, worker and client\n# driver, you can send http request \"/metrics/json\" to get a snapshot of all the\n# registered metrics in json format. For master, requests \"/metrics/master/json\" and\n# \"/metrics/applications/json\" can be sent seperately to get metrics snapshot of\n# instance master and applications. MetricsServlet may not be configured by self.\n#\n\n## List of available sinks and their properties.\n\n# org.apache.spark.metrics.sink.ConsoleSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n\n# org.apache.spark.metrics.sink.CSVSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n# directory /tmp Where to store CSV files\n\n# org.apache.spark.metrics.sink.GangliaSink\n# Name: Default: Description:\n# host NONE Hostname or multicast group of Ganglia server\n# port NONE Port of Ganglia server(s)\n# period 10 Poll period\n# unit seconds Units of poll period\n# ttl 1 TTL of messages sent by Ganglia\n# mode multicast Ganglia network mode (\'unicast\' or \'multicast\')\n\n# org.apache.spark.metrics.sink.JmxSink\n\n# org.apache.spark.metrics.sink.MetricsServlet\n# Name: Default: Description:\n# path VARIES* Path prefix from the web server root\n# sample false Whether to show entire set of samples for histograms (\'false\' or \'true\')\n#\n# * Default path is /metrics/json for all instances except the master. The master has two paths:\n# /metrics/aplications/json # App information\n# /metrics/master/json # Master information\n\n# org.apache.spark.metrics.sink.GraphiteSink\n# Name: Default: Description:\n# host NONE Hostname of Graphite server\n# port NONE Port of Graphite server\n# period 10 Poll period\n# unit seconds Units of poll period\n# prefix EMPTY STRING Prefix to prepend to metric name\n\n## Examples\n# Enable JmxSink for all instances by class name\n#*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink\n\n# Enable ConsoleSink for all instances by class name\n#*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink\n\n# Polling period for ConsoleSink\n#*.sink.console.period=10\n\n#*.sink.console.unit=seconds\n\n# Master instance overlap polling period\n#master.sink.console.period=15\n\n#master.sink.console.unit=seconds\n\n# Enable CsvSink for all instances\n#*.sink.csv.class=org.apache.spark.metrics.sink.CsvSink\n\n# Polling period for CsvSink\n#*.sink.csv.period=1\n\n#*.sink.csv.unit=minutes\n\n# Polling directory for CsvSink\n#*.sink.csv.directory=/tmp/\n\n# Worker instance overlap polling period\n#worker.sink.csv.period=10\n\n#worker.sink.csv.unit=minutes\n\n# Enable jvm source for instance master, worker, driver and executor\n#master.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource',1,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:49','system','2022-12-11 07:03:49'),(1318,'SDP-1.0','SPARK3','NULL','spark3-thrift-fairscheduler','fairscheduler_content','<?xml version=\"1.0\"?>\n            <allocations>\n            <pool name=\"default\">\n            <schedulingMode>FAIR</schedulingMode>\n            <weight>1</weight>\n            <minShare>2</minShare>\n            </pool>\n            </allocations>',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:49','system','2022-12-11 07:03:49'),(1319,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.driver.extraClassPath',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:49','system','2022-12-11 07:03:49'),(1320,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.driver.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:50','system','2022-12-11 07:03:50'),(1321,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:50','system','2022-12-11 07:03:50'),(1322,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.initialExecutors','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:50','system','2022-12-11 07:03:50'),(1323,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.maxExecutors','10',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:51','system','2022-12-11 07:03:51'),(1324,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.minExecutors','0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:51','system','2022-12-11 07:03:51'),(1325,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.eventLog.dir','{{spark_history_dir}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:51','system','2022-12-11 07:03:51'),(1326,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.eventLog.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:52','system','2022-12-11 07:03:52'),(1327,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.executor.extraJavaOptions','-XX:+UseNUMA',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:52','system','2022-12-11 07:03:52'),(1328,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.executor.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:53','system','2022-12-11 07:03:53'),(1329,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.extraListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:53','system','2022-12-11 07:03:53'),(1330,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.hadoop.cacheConf','false',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:53','system','2022-12-11 07:03:53'),(1331,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:54','system','2022-12-11 07:03:54'),(1332,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.interval','7d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:54','system','2022-12-11 07:03:54'),(1333,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.maxAge','90d',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:54','system','2022-12-11 07:03:54'),(1334,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.logDirectory','{{spark_history_dir}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:55','system','2022-12-11 07:03:55'),(1335,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.provider','org.apache.spark.deploy.history.FsHistoryProvider',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:55','system','2022-12-11 07:03:55'),(1336,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.io.compression.lz4.blockSize','128kb',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:56','system','2022-12-11 07:03:56'),(1337,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.master','{{spark_thrift_master}}',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:56','system','2022-12-11 07:03:56'),(1338,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.scheduler.allocation.file','{{spark_conf}}/spark-thrift-fairscheduler.xml',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:56','system','2022-12-11 07:03:56'),(1339,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.scheduler.mode','FAIR',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:57','system','2022-12-11 07:03:57'),(1340,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.file.buffer','1m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:57','system','2022-12-11 07:03:57'),(1341,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.io.backLog','8192',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:57','system','2022-12-11 07:03:57'),(1342,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.io.serverThreads','128',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:58','system','2022-12-11 07:03:58'),(1343,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.service.enabled','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:58','system','2022-12-11 07:03:58'),(1344,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.unsafe.file.output.buffer','5m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:59','system','2022-12-11 07:03:59'),(1345,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.autoBroadcastJoinThreshold','26214400',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:59','system','2022-12-11 07:03:59'),(1346,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.convertMetastoreOrc','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:03:59','system','2022-12-11 07:03:59'),(1347,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.metastore.jars','/usr/sdp/current/spark/standalone-metastore/*',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:00','system','2022-12-11 07:04:00'),(1348,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.metastore.version','3.0',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:00','system','2022-12-11 07:04:00'),(1349,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.orc.filterPushdown','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:00','system','2022-12-11 07:04:00'),(1350,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.orc.impl','native',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:01','system','2022-12-11 07:04:01'),(1351,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.queryExecutionListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:01','system','2022-12-11 07:04:01'),(1352,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.statistics.fallBackToHdfs','true',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:01','system','2022-12-11 07:04:01'),(1353,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.streaming.streamingQueryListeners',' ',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:02','system','2022-12-11 07:04:02'),(1354,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.warehouse.dir','/apps/spark/warehouse',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:02','system','2022-12-11 07:04:02'),(1355,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.unsafe.sorter.spill.reader.buffer.size','1m',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:03','system','2022-12-11 07:04:03'),(1356,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.executor.failuresValidityInterval','2h',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:03','system','2022-12-11 07:04:03'),(1357,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.maxAppAttempts','1',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:03','system','2022-12-11 07:04:03'),(1358,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.queue','default',0,0,NULL,'NON_HA','VALID','system','2022-12-11 07:04:04','system','2022-12-11 07:04:04'),(1359,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.hostname','%HOSTGROUP::AMBARI%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1360,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.zk-address','%HOSTGROUP::MASTER1%:2181,%HOSTGROUP::MASTER2%:2181,%HOSTGROUP::AMBARI%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1361,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.log.server.web-service.url','http://%HOSTGROUP::MASTER1%:8188/ws/v1/applicationhistory',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1362,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.webapp.address','%HOSTGROUP::AMBARI%:8088',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1363,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.address','%HOSTGROUP::AMBARI%:10200',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1364,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.admin.address','%HOSTGROUP::AMBARI%:8141',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1365,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.resource-tracker.address','%HOSTGROUP::AMBARI%:8025',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1366,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.scheduler.address','%HOSTGROUP::AMBARI%:8030',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1367,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.resourcemanager.address','%HOSTGROUP::AMBARI%:8050',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1368,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.nodemanager.local-dirs','/data/disk0/hadoop/yarn/local',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1369,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.leveldb-timeline-store.path','/data/disk0/hadoop/yarn/timeline',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1370,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.timeline-service.leveldb-state-store.path','/data/disk0/hadoop/yarn/timeline',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1371,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','yarn.nodemanager.log-dirs','/data/disk0/hadoop/yarn/log',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1372,'SDP-1.0','STACK','NULL','cluster-env','agent_mounts_ignore_list','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1373,'SDP-1.0','STACK','NULL','cluster-env','alerts_repeat_tolerance','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1374,'SDP-1.0','STACK','NULL','cluster-env','enable_external_ranger','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1375,'SDP-1.0','STACK','NULL','cluster-env','fetch_nonlocal_groups','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1376,'SDP-1.0','STACK','NULL','cluster-env','hide_yarn_memory_widget','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1377,'SDP-1.0','STACK','NULL','cluster-env','ignore_bad_mounts','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1378,'SDP-1.0','STACK','NULL','cluster-env','ignore_groupsusers_create','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1379,'SDP-1.0','STACK','NULL','cluster-env','kerberos_domain','EXAMPLE.COM',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1380,'SDP-1.0','STACK','NULL','cluster-env','manage_dirs_on_root','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1381,'SDP-1.0','STACK','NULL','cluster-env','managed_hdfs_resource_property_names','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1382,'SDP-1.0','STACK','NULL','cluster-env','namenode_rolling_restart_safemode_exit_timeout','3600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1383,'SDP-1.0','STACK','NULL','cluster-env','namenode_rolling_restart_timeout','4200',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1384,'SDP-1.0','STACK','NULL','cluster-env','one_dir_per_partition','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1385,'SDP-1.0','STACK','NULL','cluster-env','override_uid','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1386,'SDP-1.0','STACK','NULL','cluster-env','recovery_enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1387,'SDP-1.0','STACK','NULL','cluster-env','recovery_lifetime_max_count','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1388,'SDP-1.0','STACK','NULL','cluster-env','recovery_max_count','6',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1389,'SDP-1.0','STACK','NULL','cluster-env','recovery_retry_interval','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1390,'SDP-1.0','STACK','NULL','cluster-env','recovery_type','AUTO_START',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1391,'SDP-1.0','STACK','NULL','cluster-env','recovery_window_in_minutes','60',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1392,'SDP-1.0','STACK','NULL','cluster-env','repo_suse_rhel_template','[{{repo_id}}]\nname={{repo_id}}\n{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}\n\npath=/\nenabled=1\ngpgcheck=0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1394,'SDP-1.0','STACK','NULL','cluster-env','security_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1395,'SDP-1.0','STACK','NULL','cluster-env','smokeuser','ambari-qa',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1396,'SDP-1.0','STACK','NULL','cluster-env','smokeuser_keytab','/etc/security/keytabs/smokeuser.headless.keytab',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1397,'SDP-1.0','STACK','NULL','cluster-env','stack_features','{\n  \"SDP\": {\n    \"stack_features\": [\n      {\n        \"name\": \"snappy\",\n        \"description\": \"Snappy compressor/decompressor support\",\n        \"min_version\": \"2.0.0.0\",\n        \"max_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"lzo\",\n        \"description\": \"LZO libraries support\",\n        \"min_version\": \"2.2.1.0\"\n      },\n      {\n        \"name\": \"express_upgrade\",\n        \"description\": \"Express upgrade support\",\n        \"min_version\": \"2.1.0.0\"\n      },\n      {\n        \"name\": \"rolling_upgrade\",\n        \"description\": \"Rolling upgrade support\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"config_versioning\",\n        \"description\": \"Configurable versions support\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"datanode_non_root\",\n        \"description\": \"DataNode running as non-root support (AMBARI-7615)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"tez_for_spark\",\n        \"description\": \"Tez dependency for Spark\",\n        \"min_version\": \"2.2.0.0\",\n        \"max_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"timeline_state_store\",\n        \"description\": \"Yarn application timeline-service supports state store property (AMBARI-11442)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"copy_tarball_to_hdfs\",\n        \"description\": \"Copy tarball to HDFS support (AMBARI-12113)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"spark_thriftserver\",\n        \"description\": \"Spark Thrift Server\",\n        \"min_version\": \"2.3.2.0\"\n      },\n      {\n        \"name\": \"hive_metastore_upgrade_schema\",\n        \"description\": \"Hive metastore upgrade schema support (AMBARI-11176)\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"hive_server_interactive\",\n        \"description\": \"Hive server interactive support (AMBARI-15573)\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"hive_purge_table\",\n        \"description\": \"Hive purge table support (AMBARI-12260)\",\n        \"min_version\": \"2.3.0.0\"\n      },\n      {\n        \"name\": \"hive_server2_kerberized_env\",\n        \"description\": \"Hive server2 working on kerberized environment (AMBARI-13749)\",\n        \"min_version\": \"2.2.3.0\",\n        \"max_version\": \"2.2.5.0\"\n      },\n      {\n        \"name\": \"hive_env_heapsize\",\n        \"description\": \"Hive heapsize property defined in hive-env (AMBARI-12801)\",\n        \"min_version\": \"2.2.0.0\"\n      },\n      {\n        \"name\": \"hive_metastore_site_support\",\n        \"description\": \"Hive Metastore site support\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"hbase_home_directory\",\n        \"description\": \"Hbase home directory in HDFS needed for HBASE backup\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"spark_java_opts_support\",\n        \"description\": \"Allow Spark to generate java-opts file\",\n        \"min_version\": \"2.2.0.0\",\n        \"max_version\": \"2.4.0.0\"\n      },\n      {\n        \"name\": \"zkfc_version_advertised\",\n        \"description\": \"ZKFC advertise version\",\n        \"min_version\": \"2.5.0.0\"\n      },\n      {\n        \"name\": \"toolkit_config_update\",\n        \"description\": \"Support separate input and output for toolkit configuration\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"nifi_encrypt_config\",\n        \"description\": \"Encrypt sensitive properties written to nifi property file\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"tls_toolkit_san\",\n        \"description\": \"Support subject alternative name flag\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"admin_toolkit_support\",\n        \"description\": \"Supports the nifi admin toolkit\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"nifi_jaas_conf_create\",\n        \"description\": \"Create NIFI jaas configuration when kerberos is enabled\",\n        \"min_version\": \"2.6.0.0\"\n      },\n      {\n        \"name\": \"registry_remove_rootpath\",\n        \"description\": \"Registry remove root path setting\",\n        \"min_version\": \"2.6.3.0\"\n      },\n      {\n        \"name\": \"nifi_encrypted_authorizers_config\",\n        \"description\": \"Support encrypted authorizers.xml configuration for version 3.1 onwards\",\n        \"min_version\": \"2.6.5.0\"\n      },\n      {\n        \"name\": \"multiple_env_sh_files_support\",\n        \"description\": \"This feature is supported by RANGER and RANGER_KMS service to remove multiple env sh files during upgrade to stack 3.0\",\n        \"max_version\": \"2.6.99.99\"\n      },\n      {\n        \"name\": \"registry_allowed_resources_support\",\n        \"description\": \"Registry allowed resources\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_rewriteuri_filter_support\",\n        \"description\": \"Registry RewriteUri servlet filter\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_support_schema_migrate\",\n        \"description\": \"Support schema migrate in registry for version 3.1 onwards\",\n        \"min_version\": \"3.0.0.0\"\n      },\n      {\n        \"name\": \"registry_support_db_user_creation\",\n        \"description\": \"Supports registry\'s database and user creation on the fly\",\n        \"min_version\": \"3.0.0.0\"\n      }\n    ]\n  }\n}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1398,'SDP-1.0','STACK','NULL','cluster-env','stack_name','SDP',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1399,'SDP-1.0','STACK','NULL','cluster-env','stack_packages','{\n  \"SDP\": {\n    \"stack-select\": {\n      \"HBASE\": {\n        \"HBASE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-client\",\n          \"INSTALL\": [\n            \"hbase-client\"\n          ],\n          \"PATCH\": [\n            \"hbase-client\"\n          ],\n          \"STANDARD\": [\n            \"hbase-client\",\n            \"phoenix-client\",\n            \"hadoop-client\"\n          ]\n        },\n        \"HBASE_MASTER\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-master\",\n          \"INSTALL\": [\n            \"hbase-master\"\n          ],\n          \"PATCH\": [\n            \"hbase-master\"\n          ],\n          \"STANDARD\": [\n            \"hbase-master\"\n          ]\n        },\n        \"HBASE_REGIONSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hbase-regionserver\",\n          \"INSTALL\": [\n            \"hbase-regionserver\"\n          ],\n          \"PATCH\": [\n            \"hbase-regionserver\"\n          ],\n          \"STANDARD\": [\n            \"hbase-regionserver\"\n          ]\n        },\n        \"PHOENIX_QUERY_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"phoenix-server\",\n          \"INSTALL\": [\n            \"phoenix-server\"\n          ],\n          \"PATCH\": [\n            \"phoenix-server\"\n          ],\n          \"STANDARD\": [\n            \"phoenix-server\"\n          ]\n        }\n      },\n      \"HDFS\": {\n        \"DATANODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-datanode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-datanode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-datanode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-datanode\"\n          ]\n        },\n        \"HDFS_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-client\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        },\n        \"NAMENODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-namenode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-namenode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-namenode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-namenode\"\n          ]\n        },\n        \"NFS_GATEWAY\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-nfs3\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-nfs3\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-nfs3\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-nfs3\"\n          ]\n        },\n        \"JOURNALNODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-journalnode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-journalnode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-journalnode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-journalnode\"\n          ]\n        },\n        \"SECONDARY_NAMENODE\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-secondarynamenode\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-secondarynamenode\"\n          ]\n        },\n        \"ZKFC\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-hdfs-zkfc\",\n          \"INSTALL\": [\n            \"hadoop-hdfs-zkfc\"\n          ],\n          \"PATCH\": [\n            \"hadoop-hdfs-zkfc\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-hdfs-zkfc\"\n          ]\n        }\n      },\n      \"HIVE\": {\n        \"HIVE_METASTORE\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-metastore\",\n          \"INSTALL\": [\n            \"hive-metastore\"\n          ],\n          \"PATCH\": [\n            \"hive-metastore\"\n          ],\n          \"STANDARD\": [\n            \"hive-metastore\"\n          ]\n        },\n        \"HIVE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-server2\",\n          \"INSTALL\": [\n            \"hive-server2\"\n          ],\n          \"PATCH\": [\n            \"hive-server2\"\n          ],\n          \"STANDARD\": [\n            \"hive-server2\"\n          ]\n        },\n        \"HIVE_SERVER_INTERACTIVE\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-server2-hive\",\n          \"INSTALL\": [\n            \"hive-server2-hive\"\n          ],\n          \"PATCH\": [\n            \"hive-server2-hive\"\n          ],\n          \"STANDARD\": [\n            \"hive-server2-hive\"\n          ]\n        },\n        \"HIVE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hive-client\",\n          \"INSTALL\": [\n            \"hive-client\"\n          ],\n          \"PATCH\": [\n            \"hive-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"MAPREDUCE2\": {\n        \"HISTORYSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-mapreduce-historyserver\",\n          \"INSTALL\": [\n            \"hadoop-mapreduce-historyserver\"\n          ],\n          \"PATCH\": [\n            \"hadoop-mapreduce-historyserver\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-mapreduce-historyserver\"\n          ]\n        },\n        \"MAPREDUCE2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-mapreduce-client\",\n          \"INSTALL\": [\n            \"hadoop-mapreduce-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-mapreduce-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"OOZIE\": {\n        \"OOZIE_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"oozie-client\",\n          \"INSTALL\": [\n            \"oozie-client\"\n          ],\n          \"PATCH\": [\n            \"oozie-client\"\n          ],\n          \"STANDARD\": [\n            \"oozie-client\"\n          ]\n        },\n        \"OOZIE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"oozie-server\",\n          \"INSTALL\": [\n            \"oozie-client\",\n            \"oozie-server\"\n          ],\n          \"PATCH\": [\n            \"oozie-server\",\n            \"oozie-client\"\n          ],\n          \"STANDARD\": [\n            \"oozie-client\",\n            \"oozie-server\"\n          ]\n        }\n      },\n      \"SPARK3\": {\n        \"LIVY2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"livy2-client\",\n          \"INSTALL\": [\n            \"livy2-client\"\n          ],\n          \"PATCH\": [\n            \"livy2-client\"\n          ],\n          \"STANDARD\": [\n            \"livy2-client\"\n          ]\n        },\n        \"SPARK2_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-client\",\n          \"INSTALL\": [\n            \"spark3-client\"\n          ],\n          \"PATCH\": [\n            \"spark3-client\",\n            \"hive_warehouse_connector\"\n          ],\n          \"STANDARD\": [\n            \"spark3-client\",\n            \"livy2-client\",\n            \"hive_warehouse_connector\"\n          ]\n        },\n        \"SPARK2_JOBHISTORYSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-historyserver\",\n          \"INSTALL\": [\n            \"spark3-historyserver\"\n          ],\n          \"PATCH\": [\n            \"spark3-historyserver\"\n          ],\n          \"STANDARD\": [\n            \"spark3-historyserver\"\n          ]\n        },\n        \"SPARK2_THRIFTSERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"spark3-thriftserver\",\n          \"INSTALL\": [\n            \"spark3-thriftserver\"\n          ],\n          \"PATCH\": [\n            \"spark3-thriftserver\"\n          ],\n          \"STANDARD\": [\n            \"spark3-thriftserver\"\n          ]\n        }\n      },\n      \"TEZ\": {\n        \"TEZ_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"tez-client\",\n          \"INSTALL\": [\n            \"tez-client\"\n          ],\n          \"PATCH\": [\n            \"tez-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"YARN\": {\n        \"APP_TIMELINE_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-timelineserver\",\n          \"INSTALL\": [\n            \"hadoop-yarn-timelineserver\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-timelineserver\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-timelineserver\"\n          ]\n        },\n        \"TIMELINE_READER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-timelinereader\",\n          \"INSTALL\": [\n            \"hadoop-yarn-timelinereader\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-timelinereader\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-timelinereader\"\n          ]\n        },\n        \"NODEMANAGER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-nodemanager\",\n          \"INSTALL\": [\n            \"hadoop-yarn-nodemanager\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-nodemanager\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-nodemanager\"\n          ]\n        },\n        \"RESOURCEMANAGER\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-resourcemanager\",\n          \"INSTALL\": [\n            \"hadoop-yarn-resourcemanager\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-resourcemanager\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-yarn-resourcemanager\"\n          ]\n        },\n        \"YARN_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"hadoop-yarn-client\",\n          \"INSTALL\": [\n            \"hadoop-yarn-client\"\n          ],\n          \"PATCH\": [\n            \"hadoop-yarn-client\"\n          ],\n          \"STANDARD\": [\n            \"hadoop-client\"\n          ]\n        }\n      },\n      \"ZOOKEEPER\": {\n        \"ZOOKEEPER_CLIENT\": {\n          \"STACK-SELECT-PACKAGE\": \"zookeeper-client\",\n          \"INSTALL\": [\n            \"zookeeper-client\"\n          ],\n          \"PATCH\": [\n            \"zookeeper-client\"\n          ],\n          \"STANDARD\": [\n            \"zookeeper-client\"\n          ]\n        },\n        \"ZOOKEEPER_SERVER\": {\n          \"STACK-SELECT-PACKAGE\": \"zookeeper-server\",\n          \"INSTALL\": [\n            \"zookeeper-server\"\n          ],\n          \"PATCH\": [\n            \"zookeeper-server\"\n          ],\n          \"STANDARD\": [\n            \"zookeeper-server\"\n          ]\n        }\n      }\n    },\n    \"conf-select\": {\n      \"hadoop\": [\n        {\n          \"conf_dir\": \"/etc/hadoop/conf\",\n          \"current_dir\": \"{0}/current/hadoop-client/conf\",\n          \"component\": \"hadoop-client\"\n        }\n      ],\n      \"hbase\": [\n        {\n          \"conf_dir\": \"/etc/hbase/conf\",\n          \"current_dir\": \"{0}/current/hbase-client/conf\",\n          \"component\": \"hbase-client\"\n        }\n      ],\n      \"hive\": [\n        {\n          \"conf_dir\": \"/etc/hive/conf\",\n          \"current_dir\": \"{0}/current/hive-client/conf\",\n          \"component\": \"hive-client\"\n        }\n      ],\n      \"hive2\": [\n        {\n          \"conf_dir\": \"/etc/hive2/conf\",\n          \"current_dir\": \"{0}/current/hive-server2-hive/conf\",\n          \"component\": \"hive-server2-hive\"\n        }\n      ],\n      \"hive-hcatalog\": [\n        {\n          \"conf_dir\": \"/etc/hive-webhcat/conf\",\n          \"prefix\": \"/etc/hive-webhcat\",\n          \"current_dir\": \"{0}/current/hive-webhcat/etc/webhcat\",\n          \"component\": \"hive-webhcat\"\n        },\n        {\n          \"conf_dir\": \"/etc/hive-hcatalog/conf\",\n          \"prefix\": \"/etc/hive-hcatalog\",\n          \"current_dir\": \"{0}/current/hive-webhcat/etc/hcatalog\",\n          \"component\": \"hive-webhcat\"\n        }\n      ],\n      \"spark3\": [\n        {\n          \"conf_dir\": \"/etc/spark3/conf\",\n          \"current_dir\": \"{0}/current/spark3-client/conf\",\n          \"component\": \"spark3-client\"\n        }\n      ],\n      \"sqoop\": [\n        {\n          \"conf_dir\": \"/etc/sqoop/conf\",\n          \"current_dir\": \"{0}/current/sqoop-client/conf\",\n          \"component\": \"sqoop-client\"\n        }\n      ],\n      \"tez\": [\n        {\n          \"conf_dir\": \"/etc/tez/conf\",\n          \"current_dir\": \"{0}/current/tez-client/conf\",\n          \"component\": \"tez-client\"\n        }\n      ],\n      \"zookeeper\": [\n        {\n          \"conf_dir\": \"/etc/zookeeper/conf\",\n          \"current_dir\": \"{0}/current/zookeeper-client/conf\",\n          \"component\": \"zookeeper-client\"\n        }\n      ]\n    },\n    \"conf-select-patching\": {\n      \"HBASE\": {\n        \"packages\": [\"hbase\"]\n      },\n      \"HDFS\": {\n        \"packages\": []\n      },\n      \"HIVE\": {\n        \"packages\": [\"hive\", \"hive-hcatalog\", \"hive2\", \"tez_hive2\"]\n      },\n      \"MAPREDUCE2\": {\n        \"packages\": []\n      },\n      \"SPARK3\": {\n        \"packages\": [\"spark3\", \"livy2\"]\n      },\n      \"SQOOP\": {\n        \"packages\": [\"sqoop\"]\n      },\n      \"TEZ\": {\n        \"packages\": [\"tez\"]\n      },\n      \"YARN\": {\n        \"packages\": []\n      },\n      \"ZOOKEEPER\": {\n        \"packages\": [\"zookeeper\"]\n      }\n    },\n    \"upgrade-dependencies\" : {\n      \"HIVE\": [\"TEZ\", \"MAPREDUCE2\", \"SQOOP\"],\n      \"TEZ\": [\"HIVE\"],\n      \"MAPREDUCE2\": [\"HIVE\"]\n    }\n  }\n}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1400,'SDP-1.0','STACK','NULL','cluster-env','stack_root','{\"SDP\":\"/usr/sdp\"}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1401,'SDP-1.0','STACK','NULL','cluster-env','stack_tools','{\n  \"SDP\": {\n    \"stack_selector\": [\n      \"sdp-select\",\n      \"/usr/bin/sdp-select\",\n      \"sdp-select\"\n    ],\n    \"conf_selector\": [\n      \"conf-select\",\n      \"/usr/bin/conf-select\",\n      \"conf-select\"\n    ]\n  }\n}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1402,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_fast_jar_hdfs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1403,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_oozie_share_lib_to_hdfs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1404,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_copy_tarballs_hdfs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1405,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_create_users_and_groups','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1406,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_hive_schema_create','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1407,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_lzo_package_operations','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1408,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_oozie_schema_create','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1409,'SDP-1.0','STACK','NULL','cluster-env','sysprep_skip_setup_jce','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1410,'SDP-1.0','STACK','NULL','cluster-env','user_group','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1411,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hdfs.groups','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1412,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hdfs.hosts','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1413,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hive.groups','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1414,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.root.groups','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1415,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.root.hosts','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1416,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.hive.hosts','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1419,'SDP-1.0','HDFS','NULL','core-site','fs.defaultFS','hdfs://sunboxcluster',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1420,'SDP-1.0','HDFS','NULL','core-site','fs.gs.application.name.suffix',' (GPN:Hortonworks; version 1.0) SDP/{{version}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1421,'SDP-1.0','HDFS','NULL','core-site','fs.gs.path.encoding','uri-path',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1422,'SDP-1.0','HDFS','NULL','core-site','fs.gs.working.dir','/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1423,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.fast.upload','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1424,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.fast.upload.buffer','disk',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1425,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.multipart.size','67108864',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1426,'SDP-1.0','HDFS','NULL','core-site','fs.s3a.user.agent.prefix','User-Agent: APN/1.0 Hortonworks/1.0 SDP/{{version}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1427,'SDP-1.0','HDFS','NULL','core-site','fs.trash.interval','360',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1428,'SDP-1.0','HDFS','NULL','core-site','ha.failover-controller.active-standby-elector.zk.op.retries','120',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1429,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.authentication.simple.anonymous.allowed','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1430,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-headers','X-Requested-With,Content-Type,Accept,Origin,WWW-Authenticate,Accept-Encoding,Transfer-Encoding',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1431,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-methods','GET,PUT,POST,OPTIONS,HEAD,DELETE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1432,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.allowed-origins','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1433,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.cross-origin.max-age','1800',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1434,'SDP-1.0','HDFS','NULL','core-site','hadoop.http.filter.initializers','org.apache.hadoop.security.AuthenticationFilterInitializer,org.apache.hadoop.security.HttpCrossOriginFilterInitializer',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1435,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.auth_to_local','DEFAULT',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1436,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.authentication','simple',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1437,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.authorization','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1438,'SDP-1.0','HDFS','NULL','core-site','hadoop.security.instrumentation.requires.admin','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1439,'SDP-1.0','HDFS','NULL','core-site','io.compression.codecs','org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.SnappyCodec',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1440,'SDP-1.0','HDFS','NULL','core-site','io.file.buffer.size','131072',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1441,'SDP-1.0','HDFS','NULL','core-site','io.serializations','org.apache.hadoop.io.serializer.WritableSerialization',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1442,'SDP-1.0','HDFS','NULL','core-site','ipc.client.connect.max.retries','50',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1443,'SDP-1.0','HDFS','NULL','core-site','ipc.client.connection.maxidletime','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1444,'SDP-1.0','HDFS','NULL','core-site','ipc.client.idlethreshold','8000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1445,'SDP-1.0','HDFS','NULL','core-site','ipc.server.tcpnodelay','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1446,'SDP-1.0','HDFS','NULL','core-site','mapreduce.jobtracker.webinterface.trusted','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1447,'SDP-1.0','HDFS','NULL','core-site','net.topology.script.file.name','/etc/hadoop/conf/topology_script.py',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1448,'SDP-1.0','HDFS','NULL','hadoop-env','content','\n      # Set Hadoop-specific environment variables here.\n\n      # The only required environment variable is JAVA_HOME.  All others are\n      # optional.  When running a distributed configuration it is best to\n      # set JAVA_HOME in this file, so that it is correctly defined on\n      # remote nodes.\n\n      # The java implementation to use.  Required.\n      export JAVA_HOME={{java_home}}\n      export HADOOP_HOME_WARN_SUPPRESS=1\n\n      # Hadoop home directory\n      export HADOOP_HOME=${HADOOP_HOME:-/usr/sdp/current/hadoop}\n\n      # Hadoop Configuration Directory\n\n      {# this is different for SDP1 #}\n      # Path to jsvc required by secure SDP 2.0 datanode\n      export JSVC_HOME={{jsvc_path}}\n\n\n      # The maximum amount of heap to use, in MB. Default is 1000.\n      export HADOOP_HEAPSIZE=\"{{hadoop_heapsize}}\"\n\n      export HADOOP_NAMENODE_INIT_HEAPSIZE=\"-Xms{{namenode_heapsize}}\"\n\n      # Extra Java runtime options.  Empty by default.\n      export HADOOP_OPTS=\"-Djava.net.preferIPv4Stack=true ${HADOOP_OPTS}\"\n\n      USER=\"$(whoami)\"\n\n      # Command specific options appended to HADOOP_OPTS when specified\n      HADOOP_JOBTRACKER_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{jtnode_opt_newsize}} -XX:MaxNewSize={{jtnode_opt_maxnewsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xmx{{jtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dmapred.audit.logger=INFO,MRAUDIT -Dhadoop.mapreduce.jobsummary.logger=INFO,JSA ${HADOOP_JOBTRACKER_OPTS}\"\n\n      HADOOP_TASKTRACKER_OPTS=\"-server -Xmx{{ttnode_heapsize}} -Dhadoop.security.logger=ERROR,console -Dmapred.audit.logger=ERROR,console ${HADOOP_TASKTRACKER_OPTS}\"\n\n      {% if java_version < 8 %}\n      SHARED_HDFS_NAMENODE_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{namenode_opt_newsize}} -XX:MaxNewSize={{namenode_opt_maxnewsize}} -XX:PermSize={{namenode_opt_permsize}} -XX:MaxPermSize={{namenode_opt_maxpermsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms{{namenode_heapsize}} -Xmx{{namenode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT\"\n      export HDFS_NAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-name-node\\\" -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 ${HDFS_NAMENODE_OPTS}\"\n      export HDFS_DATANODE_OPTS=\"-server -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-data-node\\\" -XX:ErrorFile=/var/log/hadoop/$USER/hs_err_pid%p.log -XX:NewSize=200m -XX:MaxNewSize=200m -XX:PermSize=128m -XX:MaxPermSize=256m -Xloggc:/var/log/hadoop/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xms{{dtnode_heapsize}} -Xmx{{dtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT ${HDFS_DATANODE_OPTS} -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly\"\n\n      export HDFS_SECONDARYNAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-secondary-name-node\\\" ${HDFS_SECONDARYNAMENODE_OPTS}\"\n\n      # The following applies to multiple commands (fs, dfs, fsck, distcp etc)\n      export HADOOP_CLIENT_OPTS=\"-Xmx${HADOOP_HEAPSIZE}m -XX:MaxPermSize=512m $HADOOP_CLIENT_OPTS\"\n\n      {% else %}\n      SHARED_HDFS_NAMENODE_OPTS=\"-server -XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:ErrorFile={{hdfs_log_dir_prefix}}/$USER/hs_err_pid%p.log -XX:NewSize={{namenode_opt_newsize}} -XX:MaxNewSize={{namenode_opt_maxnewsize}} -Xloggc:{{hdfs_log_dir_prefix}}/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly -Xms{{namenode_heapsize}} -Xmx{{namenode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT\"\n      export HDFS_NAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-name-node\\\" -Dorg.mortbay.jetty.Request.maxFormContentSize=-1 ${HDFS_NAMENODE_OPTS}\"\n      export HDFS_DATANODE_OPTS=\"-server -XX:ParallelGCThreads=4 -XX:+UseConcMarkSweepGC -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-data-node\\\" -XX:ErrorFile=/var/log/hadoop/$USER/hs_err_pid%p.log -XX:NewSize=200m -XX:MaxNewSize=200m -Xloggc:/var/log/hadoop/$USER/gc.log-`date +\'%Y%m%d%H%M\'` -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Xms{{dtnode_heapsize}} -Xmx{{dtnode_heapsize}} -Dhadoop.security.logger=INFO,DRFAS -Dhdfs.audit.logger=INFO,DRFAAUDIT ${HDFS_DATANODE_OPTS} -XX:CMSInitiatingOccupancyFraction=70 -XX:+UseCMSInitiatingOccupancyOnly\"\n\n      export HDFS_SECONDARYNAMENODE_OPTS=\"${SHARED_HDFS_NAMENODE_OPTS} -XX:OnOutOfMemoryError=\\\"/usr/sdp/current/hadoop/bin/kill-secondary-name-node\\\" ${HDFS_SECONDARYNAMENODE_OPTS}\"\n\n      # The following applies to multiple commands (fs, dfs, fsck, distcp etc)\n      export HADOOP_CLIENT_OPTS=\"-Xmx${HADOOP_HEAPSIZE}m $HADOOP_CLIENT_OPTS\"\n      {% endif %}\n\n      {% if security_enabled %}\n      export HDFS_NAMENODE_OPTS=\"$HDFS_NAMENODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_nn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HDFS_SECONDARYNAMENODE_OPTS=\"$HDFS_SECONDARYNAMENODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_nn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HDFS_DATANODE_OPTS=\"$HDFS_DATANODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_dn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      export HADOOP_JOURNALNODE_OPTS=\"$HADOOP_JOURNALNODE_OPTS -Djava.security.auth.login.config=/etc/hadoop/conf/hdfs_jn_jaas.conf -Djavax.security.auth.useSubjectCredsOnly=false\"\n      {% endif %}\n\n      HDFS_NFS3_OPTS=\"-Xmx{{nfsgateway_heapsize}}m -Dhadoop.security.logger=ERROR,DRFAS ${HDFS_NFS3_OPTS}\"\n      HADOOP_BALANCER_OPTS=\"-server -Xmx{{hadoop_heapsize}}m ${HADOOP_BALANCER_OPTS}\"\n\n\n      # On secure datanodes, user to run the datanode as after dropping privileges\n      export HDFS_DATANODE_SECURE_USER=${HDFS_DATANODE_SECURE_USER:-{{hadoop_secure_dn_user}}}\n\n      # Extra ssh options.  Empty by default.\n      export HADOOP_SSH_OPTS=\"-o ConnectTimeout=5 -o SendEnv=HADOOP_CONF_DIR\"\n\n      # Where log files are stored.  $HADOOP_HOME/logs by default.\n      export HADOOP_LOG_DIR={{hdfs_log_dir_prefix}}/$USER\n\n      # Where log files are stored in the secure data environment.\n      export HADOOP_SECURE_LOG_DIR=${HADOOP_SECURE_LOG_DIR:-{{hdfs_log_dir_prefix}}/$HDFS_DATANODE_SECURE_USER}\n\n      # File naming remote slave hosts.  $HADOOP_HOME/conf/slaves by default.\n      # export HADOOP_WORKERS=${HADOOP_HOME}/conf/slaves\n\n      # host:path where hadoop code should be rsync\'d from.  Unset by default.\n      # export HADOOP_MASTER=master:/home/$USER/src/hadoop\n\n      # Seconds to sleep between slave commands.  Unset by default.  This\n      # can be useful in large clusters, where, e.g., slave rsyncs can\n      # otherwise arrive faster than the master can service them.\n      # export HADOOP_WORKER_SLEEP=0.1\n\n      # The directory where pid files are stored. /tmp by default.\n      export HADOOP_PID_DIR={{hadoop_pid_dir_prefix}}/$USER\n      export HADOOP_SECURE_PID_DIR=${HADOOP_SECURE_PID_DIR:-{{hadoop_pid_dir_prefix}}/$HDFS_DATANODE_SECURE_USER}\n\n      YARN_RESOURCEMANAGER_OPTS=\"-Dyarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY\"\n\n      # A string representing this instance of hadoop. $USER by default.\n      export HADOOP_IDENT_STRING=$USER\n\n      # The scheduling priority for daemon processes.  See \'man nice\'.\n\n      # export HADOOP_NICENESS=10\n\n      # Add database libraries\n      JAVA_JDBC_LIBS=\"\"\n      if [ -d \"/usr/share/java\" ]; then\n      for jarFile in `ls /usr/share/java | grep -E \"(mysql|ojdbc|postgresql|sqljdbc)\" 2>/dev/null`\n      do\n      JAVA_JDBC_LIBS=${JAVA_JDBC_LIBS}:$jarFile\n      done\n      fi\n\n      # Add libraries to the hadoop classpath - some may not need a colon as they already include it\n      export HADOOP_CLASSPATH=${HADOOP_CLASSPATH}${JAVA_JDBC_LIBS}\n\n      # Setting path to hdfs command line\n      export HADOOP_LIBEXEC_DIR=/usr/sdp/current/hadoop/libexec\n\n      # Mostly required for hadoop 2.0\n      export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:/usr/sdp/current/hadoop/lib/native/Linux-{{architecture}}-64\n\n      {% if zk_principal_user is defined %}\n      HADOOP_OPTS=\"-Dzookeeper.sasl.client.username={{zk_principal_user}} $HADOOP_OPTS\"\n      {% endif %}\n\n      export HADOOP_OPTS=\"-Dsdp.version=$SDP_VERSION $HADOOP_OPTS\"\n\n\n      # Fix temporary bug, when ulimit from conf files is not picked up, without full relogin.\n      # Makes sense to fix only when runing DN as root\n      if [ \"$command\" == \"datanode\" ] && [ \"$EUID\" -eq 0 ] && [ -n \"$HDFS_DATANODE_SECURE_USER\" ]; then\n      {% if is_datanode_max_locked_memory_set %}\n      ulimit -l {{datanode_max_locked_memory}}\n      {% endif %}\n      ulimit -n {{hdfs_user_nofile_limit}}\n      fi\n      # Enable ACLs on zookeper znodes if required\n      {% if hadoop_zkfc_opts is defined %}\n      export HDFS_ZKFC_OPTS=\"{{hadoop_zkfc_opts}} $HDFS_ZKFC_OPTS\"\n      {% endif %}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1449,'SDP-1.0','HDFS','NULL','hadoop-env','dtnode_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1450,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1451,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_pid_dir_prefix','/var/run/hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1452,'SDP-1.0','HDFS','NULL','hadoop-env','hadoop_root_logger','INFO,RFA',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1453,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_log_dir_prefix','/var/log/hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1454,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_principal_name','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1455,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_tmp_dir','/tmp',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1456,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_keytab','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1457,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_nofile_limit','128000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1458,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user_nproc_limit','65536',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1459,'SDP-1.0','HDFS','NULL','hadoop-env','keyserver_host',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1460,'SDP-1.0','HDFS','NULL','hadoop-env','keyserver_port','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1461,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_backup_dir','/tmp/upgrades',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1462,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1463,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_maxnewsize','128',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1464,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_maxpermsize','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1465,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_newsize','128',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1466,'SDP-1.0','HDFS','NULL','hadoop-env','namenode_opt_permsize','128',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1467,'SDP-1.0','HDFS','NULL','hadoop-env','nfsgateway_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1468,'SDP-1.0','HDFS','NULL','hadoop-env','hdfs_user','hdfs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1469,'SDP-1.0','HDFS','NULL','hadoop-env','proxyuser_group','users',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1470,'SDP-1.0','HDFS','NULL','hadoop-policy','security.admin.operations.protocol.acl','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1471,'SDP-1.0','HDFS','NULL','hadoop-policy','security.client.datanode.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1472,'SDP-1.0','HDFS','NULL','hadoop-policy','security.client.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1473,'SDP-1.0','HDFS','NULL','hadoop-policy','security.datanode.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1474,'SDP-1.0','HDFS','NULL','hadoop-policy','security.inter.datanode.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1475,'SDP-1.0','HDFS','NULL','hadoop-policy','security.inter.tracker.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1476,'SDP-1.0','HDFS','NULL','hadoop-policy','security.job.client.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1477,'SDP-1.0','HDFS','NULL','hadoop-policy','security.job.task.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1478,'SDP-1.0','HDFS','NULL','hadoop-policy','security.namenode.protocol.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1479,'SDP-1.0','HDFS','NULL','hadoop-policy','security.refresh.policy.protocol.acl','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1480,'SDP-1.0','HDFS','NULL','hadoop-policy','security.refresh.usertogroups.mappings.protocol.acl','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1481,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_log_max_backup_size','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1482,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_log_number_of_backup_files','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1483,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_security_log_max_backup_size','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1484,'SDP-1.0','HDFS','NULL','hdfs-log4j','hadoop_security_log_number_of_backup_files','20',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1485,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.block.access.token.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1486,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.blockreport.initialDelay','120',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1487,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.blocksize','134217728',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1488,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.datanode-restart.timeout','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1489,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.read.shortcircuit','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1490,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.read.shortcircuit.streams.cache.size','4096',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1491,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.retry.policy.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1492,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.cluster.administrators',' hdfs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1493,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.content-summary.limit','5000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1494,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.address','0.0.0.0:50010',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1495,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.balance.bandwidthPerSec','6250000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1496,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.data.dir','/data/disk0/hadoop/hdfs/data',0,1,'MULTI_DISK','HA','VALID',NULL,NULL,NULL,NULL),(1497,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.data.dir.perm','750',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1498,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.du.reserved','135137647104',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1499,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.failed.volumes.tolerated','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1500,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.http.address','0.0.0.0:50075',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1501,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.https.address','0.0.0.0:50475',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1502,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.ipc.address','0.0.0.0:8010',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1503,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.datanode.max.transfer.threads','16384',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1504,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.domain.socket.path','/var/lib/hadoop-hdfs/dn_socket',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1505,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.encrypt.data.transfer.cipher.suites','AES/CTR/NoPadding',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1506,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.heartbeat.interval','3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1507,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.hosts.exclude','/etc/hadoop/conf/dfs.exclude',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1508,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.http.policy','HTTP_ONLY',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1509,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.https.port','50470',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1510,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.edits.dir','/data/disk0/hadoop/hdfs/journalnode',0,1,'MULTI_DISK','HA','VALID',NULL,NULL,NULL,NULL),(1511,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.http-address','0.0.0.0:8480',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1512,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.journalnode.https-address','0.0.0.0:8481',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1513,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.accesstime.precision','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1514,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.acls.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1515,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.audit.log.async','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1516,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.avoid.read.stale.datanode','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1517,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.avoid.write.stale.datanode','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1518,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.dir','/hadoop/hdfs/namesecondary',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1519,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.edits.dir','${dfs.namenode.checkpoint.dir}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1520,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.period','21600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1521,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.checkpoint.txns','1000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1522,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.fslock.fair','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1523,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.handler.count','400',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1524,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.http-address','%HOSTGROUP::MASTER1%:50070',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1525,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.https-address','%HOSTGROUP::MASTER1%:50470',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1526,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.name.dir','/data/disk0/hadoop/hdfs/namenode',0,0,'','HA','VALID',NULL,NULL,NULL,NULL),(1527,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.name.dir.restore','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1528,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.rpc-address','%HOSTGROUP::MASTER1%:8020',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1529,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.safemode.threshold-pct','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1530,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.secondary.http-address','%HOSTGROUP::CORE%:50090',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1531,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.stale.datanode.interval','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1532,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.startup.delay.block.deletion.sec','3600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1533,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.write.stale.datanode.ratio','1.0f',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1534,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.permissions.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1535,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.replication','3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1536,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.replication.max','50',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1537,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.webhdfs.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1538,'SDP-1.0','HDFS','NULL','hdfs-site','fs.permissions.umask-mode','022',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1539,'SDP-1.0','HDFS','NULL','hdfs-site','hadoop.caller.context.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1540,'SDP-1.0','HDFS','NULL','hdfs-site','manage.include.files','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1541,'SDP-1.0','HDFS','NULL','hdfs-site','nfs.exports.allowed.hosts','* rw',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1542,'SDP-1.0','HDFS','NULL','hdfs-site','nfs.file.dump.dir','/tmp/.hdfs-nfs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1543,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.permissions.superusergroup','hdfs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1544,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','ranger.plugin.hdfs.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1545,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1546,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hadoop/hdfs/audit/hdfs/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1547,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1548,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1549,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hadoop/hdfs/audit/solr/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1550,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1551,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1552,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.is.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1553,'SDP-1.0','HDFS','NULL','ranger-hdfs-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1554,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','REPOSITORY_CONFIG_PASSWORD','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1555,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','REPOSITORY_CONFIG_USERNAME','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1556,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','common.name.for.certificate','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1557,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1558,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1559,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_ranger_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1560,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','external_ranger_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1561,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','hadoop.rpc.protection','authentication',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1562,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','policy_user','ambari-qa',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1563,'SDP-1.0','HDFS','NULL','ranger-hdfs-plugin-properties','ranger-hdfs-plugin-enabled','No',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1564,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1565,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1566,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1567,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1568,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1569,'SDP-1.0','HDFS','NULL','ranger-hdfs-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1570,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1571,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.pollIntervalMs','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1572,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.rest.ssl.config.file','/etc/hadoop/conf/ranger-policymgr-ssl.xml',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1573,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1574,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1575,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','ranger.plugin.hdfs.service.name','{{repo_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1576,'SDP-1.0','HDFS','NULL','ranger-hdfs-security','xasecure.add-hadoop-authorization','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1584,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.keypassword','bigdata',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1585,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.location','/etc/security/serverKeys/keystore.jks',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1586,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.password','bigdata',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1587,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.keystore.type','jks',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1588,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.location','/etc/security/serverKeys/all.jks',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1589,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.password','bigdata',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1590,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.reload.interval','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1591,'SDP-1.0','HDFS','NULL','ssl-server','ssl.server.truststore.type','jks',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1592,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.default.minimum-user-limit-percent','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1593,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1594,'SDP-1.0','HDFS','NULL','hadoop-metrics2.properties','content','\n{% if has_ganglia_server %}\n*.period=60\n\n*.sink.ganglia.class=org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31\n*.sink.ganglia.period=10\n\n# default for supportsparse is false\n*.sink.ganglia.supportsparse=true\n\n.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both\n.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHeapUsedM=40\n\n# Hook up to the server\nnamenode.sink.ganglia.servers={{ganglia_server_host}}:8661\ndatanode.sink.ganglia.servers={{ganglia_server_host}}:8659\njobtracker.sink.ganglia.servers={{ganglia_server_host}}:8662\ntasktracker.sink.ganglia.servers={{ganglia_server_host}}:8658\nmaptask.sink.ganglia.servers={{ganglia_server_host}}:8660\nreducetask.sink.ganglia.servers={{ganglia_server_host}}:8660\nresourcemanager.sink.ganglia.servers={{ganglia_server_host}}:8664\nnodemanager.sink.ganglia.servers={{ganglia_server_host}}:8657\nhistoryserver.sink.ganglia.servers={{ganglia_server_host}}:8666\njournalnode.sink.ganglia.servers={{ganglia_server_host}}:8654\nnimbus.sink.ganglia.servers={{ganglia_server_host}}:8649\nsupervisor.sink.ganglia.servers={{ganglia_server_host}}:8650\n\nresourcemanager.sink.ganglia.tagsForPrefix.yarn=Queue\n\n{% endif %}\n\n{% if has_metric_collector %}\n\n*.period={{metrics_collection_period}}\n*.sink.timeline.plugin.urls=file:///usr/lib/ambari-metrics-hadoop-sink/ambari-metrics-hadoop-sink.jar\n*.sink.timeline.class=org.apache.hadoop.metrics2.sink.timeline.HadoopTimelineMetricsSink\n*.sink.timeline.period={{metrics_collection_period}}\n*.sink.timeline.sendInterval={{metrics_report_interval}}000\n*.sink.timeline.slave.host.name={{hostname}}\n*.sink.timeline.zookeeper.quorum={{zookeeper_quorum}}\n*.sink.timeline.protocol={{metric_collector_protocol}}\n*.sink.timeline.port={{metric_collector_port}}\n*.sink.timeline.instanceId = {{cluster_name}}\n*.sink.timeline.set.instanceId = {{set_instanceId}}\n*.sink.timeline.host_in_memory_aggregation = {{host_in_memory_aggregation}}\n*.sink.timeline.host_in_memory_aggregation_port = {{host_in_memory_aggregation_port}}\n{% if is_aggregation_https_enabled %}\n*.sink.timeline.host_in_memory_aggregation_protocol = {{host_in_memory_aggregation_protocol}}\n{% endif %}\n\n# HTTPS properties\n*.sink.timeline.truststore.path = {{metric_truststore_path}}\n*.sink.timeline.truststore.type = {{metric_truststore_type}}\n*.sink.timeline.truststore.password = {{metric_truststore_password}}\n\ndatanode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nnamenode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nresourcemanager.sink.timeline.collector.hosts={{ams_collector_hosts}}\nnodemanager.sink.timeline.collector.hosts={{ams_collector_hosts}}\njobhistoryserver.sink.timeline.collector.hosts={{ams_collector_hosts}}\njournalnode.sink.timeline.collector.hosts={{ams_collector_hosts}}\nmaptask.sink.timeline.collector.hosts={{ams_collector_hosts}}\nreducetask.sink.timeline.collector.hosts={{ams_collector_hosts}}\napplicationhistoryserver.sink.timeline.collector.hosts={{ams_collector_hosts}}\n\nresourcemanager.sink.timeline.tagsForPrefix.yarn=Queue\n\n{% if is_nn_client_port_configured %}\n# Namenode rpc ports customization\nnamenode.sink.timeline.metric.rpc.client.port={{nn_rpc_client_port}}\n{% endif %}\n{% if is_nn_dn_port_configured %}\nnamenode.sink.timeline.metric.rpc.datanode.port={{nn_rpc_dn_port}}\n{% endif %}\n{% if is_nn_healthcheck_port_configured %}\nnamenode.sink.timeline.metric.rpc.healthcheck.port={{nn_rpc_healthcheck_port}}\n{% endif %}\n\n{% endif %}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1595,'SDP-1.0','HDFS','NULL','hdfs-log4j','content','\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#  http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\n\n# Define some default values that can be overridden by system properties\n# To change daemon root logger use hadoop_root_logger in hadoop-env\nhadoop.root.logger=INFO,console\nhadoop.log.dir=.\nhadoop.log.file=hadoop.log\n\n\n# Define the root logger to the system property \\\"hadoop.root.logger\\\".\nlog4j.rootLogger=${hadoop.root.logger}, EventCounter\n\n# Logging Threshold\nlog4j.threshhold=ALL\n\n#\n# Daily Rolling File Appender\n#\n\nlog4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFA.File=${hadoop.log.dir}/${hadoop.log.file}\n\n# Rollver at midnight\nlog4j.appender.DRFA.DatePattern=\'.\'yyyy-MM-dd-HH\n\n# 30-day backup\n#log4j.appender.DRFA.MaxBackupIndex=30\nlog4j.appender.DRFA.layout=org.apache.log4j.PatternLayout\n\n# Pattern format: Date LogLevel LoggerName LogMessage\nlog4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\n# Debugging Pattern format\n#log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n\n\n\n#\n# console\n# Add \\\"console\\\" to rootlogger above if you want to use this\n#\n\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n\n\n#\n# TaskLog Appender\n#\n\n#Default values\nhadoop.tasklog.taskid=null\nhadoop.tasklog.iscleanup=false\nhadoop.tasklog.noKeepSplits=4\nhadoop.tasklog.totalLogFileSize=100\nhadoop.tasklog.purgeLogSplits=true\nhadoop.tasklog.logsRetainHours=12\n\nlog4j.appender.TLA=org.apache.hadoop.mapred.TaskLogAppender\nlog4j.appender.TLA.taskId=${hadoop.tasklog.taskid}\nlog4j.appender.TLA.isCleanup=${hadoop.tasklog.iscleanup}\nlog4j.appender.TLA.totalLogFileSize=${hadoop.tasklog.totalLogFileSize}\n\nlog4j.appender.TLA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.TLA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\n\n#\n#Security audit appender\n#\nhadoop.security.logger=INFO,console\nhadoop.security.log.maxfilesize={{hadoop_security_log_max_backup_size}}MB\nhadoop.security.log.maxbackupindex={{hadoop_security_log_number_of_backup_files}}\nlog4j.category.SecurityLogger=${hadoop.security.logger}\nhadoop.security.log.file=SecurityAuth.audit\nlog4j.additivity.SecurityLogger=false\nlog4j.appender.DRFAS=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFAS.File=${hadoop.log.dir}/${hadoop.security.log.file}\nlog4j.appender.DRFAS.layout=org.apache.log4j.PatternLayout\nlog4j.appender.DRFAS.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\nlog4j.appender.DRFAS.DatePattern=\'.\'yyyy-MM-dd-HH\n\nlog4j.appender.RFAS=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RFAS.File=${hadoop.log.dir}/${hadoop.security.log.file}\nlog4j.appender.RFAS.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RFAS.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n\nlog4j.appender.RFAS.MaxFileSize=${hadoop.security.log.maxfilesize}\nlog4j.appender.RFAS.MaxBackupIndex=${hadoop.security.log.maxbackupindex}\n\n#\n# hdfs audit logging\n#\nhdfs.audit.logger=INFO,console\nlog4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=${hdfs.audit.logger}\nlog4j.additivity.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=false\nlog4j.appender.DRFAAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.DRFAAUDIT.File=${hadoop.log.dir}/hdfs-audit.log\nlog4j.appender.DRFAAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.DRFAAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.DRFAAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n#\n# NameNode metrics logging.\n# The default is to retain two namenode-metrics.log files up to 64MB each.\n#\nnamenode.metrics.logger=INFO,NullAppender\nlog4j.logger.NameNodeMetricsLog=${namenode.metrics.logger}\nlog4j.additivity.NameNodeMetricsLog=false\nlog4j.appender.NNMETRICSRFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.NNMETRICSRFA.File=${hadoop.log.dir}/namenode-metrics.log\nlog4j.appender.NNMETRICSRFA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.NNMETRICSRFA.layout.ConversionPattern=%d{ISO8601} %m%n\nlog4j.appender.NNMETRICSRFA.MaxBackupIndex=1\nlog4j.appender.NNMETRICSRFA.MaxFileSize=64MB\n\n#\n# mapred audit logging\n#\nmapred.audit.logger=INFO,console\nlog4j.logger.org.apache.hadoop.mapred.AuditLogger=${mapred.audit.logger}\nlog4j.additivity.org.apache.hadoop.mapred.AuditLogger=false\nlog4j.appender.MRAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.MRAUDIT.File=${hadoop.log.dir}/mapred-audit.log\nlog4j.appender.MRAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.MRAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.MRAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n#\n# Rolling File Appender\n#\n\nlog4j.appender.RFA=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RFA.File=${hadoop.log.dir}/${hadoop.log.file}\nlog4j.appender.RFA.DatePattern=\'.\'yyyy-MM-dd-HH\n# Logfile size and and 30-day backups\nlog4j.appender.RFA.MaxFileSize={{hadoop_log_max_backup_size}}MB\nlog4j.appender.RFA.MaxBackupIndex={{hadoop_log_number_of_backup_files}}\n\nlog4j.appender.RFA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} - %m%n\nlog4j.appender.RFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n\n\n\n# Custom Logging levels\n\nhadoop.metrics.log.level=INFO\n#log4j.logger.org.apache.hadoop.mapred.JobTracker=DEBUG\n#log4j.logger.org.apache.hadoop.mapred.TaskTracker=DEBUG\n#log4j.logger.org.apache.hadoop.fs.FSNamesystem=DEBUG\nlog4j.logger.org.apache.hadoop.metrics2=${hadoop.metrics.log.level}\n\n# Jets3t library\nlog4j.logger.org.jets3t.service.impl.rest.httpclient.RestS3Service=ERROR\n\n#\n# Null Appender\n# Trap security logger on the hadoop client side\n#\nlog4j.appender.NullAppender=org.apache.log4j.varia.NullAppender\n\n#\n# Event Counter Appender\n# Sends counts of logging messages at different severity levels to Hadoop Metrics.\n#\nlog4j.appender.EventCounter=org.apache.hadoop.log.metrics.EventCounter\n\n# Removes \\\"deprecated\\\" messages\nlog4j.logger.org.apache.hadoop.conf.Configuration.deprecation=WARN\n\n#\n# HDFS block state change log from block manager\n#\n# Uncomment the following to suppress normal block state change\n# messages from BlockManager in NameNode.\n#log4j.logger.BlockStateChange=WARN\n\n# Adding logging for 3rd party library\nlog4j.logger.org.apache.commons.beanutils=WARN',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1596,'SDP-1.0','HDFS','NULL','viewfs-mount-table','content',' ',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1597,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.accessible-node-labels','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1598,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.capacity','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1599,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.maximum-am-resource-percent','0.2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1600,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.maximum-applications','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1601,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.user-limit-factor','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1602,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.node-locality-delay','40',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1603,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.acl_submit_applications','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1604,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.acl_submit_applications','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1605,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.state','RUNNING',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1606,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.capacity','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1607,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.acl_administer_queue','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1608,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.maximum-capacity','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1609,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.queues','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1610,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.maximum-threads','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1611,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.root.default.acl_administer_jobs','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1612,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.schedule-asynchronously.scheduling-interval-ms','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1613,'SDP-1.0','YARN','NULL','capacity-scheduler','yarn.scheduler.capacity.resource-calculator','org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1614,'SDP-1.0','YARN','NULL','container-executor','cgroup_root','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1615,'SDP-1.0','YARN','NULL','container-executor','content','{#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#}\n\n#/*\n# * Licensed to the Apache Software Foundation (ASF) under one\n# * or more contributor license agreements.  See the NOTICE file\n# * distributed with this work for additional information\n# * regarding copyright ownership.  The ASF licenses this file\n# * to you under the Apache License, Version 2.0 (the\n# * \"License\"); you may not use this file except in compliance\n# * with the License.  You may obtain a copy of the License at\n# *\n# *     http://www.apache.org/licenses/LICENSE-2.0\n# *\n# * Unless required by applicable law or agreed to in writing, software\n# * distributed under the License is distributed on an \"AS IS\" BASIS,\n# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# * See the License for the specific language governing permissions and\n# * limitations under the License.\n# */\nyarn.nodemanager.local-dirs={{nm_local_dirs}}\nyarn.nodemanager.log-dirs={{nm_log_dirs}}\nyarn.nodemanager.linux-container-executor.group={{yarn_executor_container_group}}\nbanned.users=hdfs,yarn,mapred,bin\nmin.user.id={{min_user_id}}\n\n{{ \'[docker]\' }}\n  module.enabled={{docker_module_enabled}}\n  docker.binary={{docker_binary}}\n  docker.allowed.capabilities={{docker_allowed_capabilities}}\n  docker.allowed.devices={{docker_allowed_devices}}\n  docker.allowed.networks={{docker_allowed_networks}}\n  docker.allowed.ro-mounts={{nm_local_dirs}},{{docker_allowed_ro_mounts}}\n  docker.allowed.rw-mounts={{nm_local_dirs}},{{nm_log_dirs}},{{docker_allowed_rw_mounts}}\n  docker.privileged-containers.enabled={{docker_privileged_containers_enabled}}\n  docker.trusted.registries={{docker_trusted_registries}}\n  docker.allowed.volume-drivers={{docker_allowed_volume_drivers}}\n\n{{ \'[gpu]\' }}\n  module.enabled={{gpu_module_enabled}}\n\n{{ \'[cgroups]\' }}\n  root={{cgroup_root}}\n  yarn-hierarchy={{yarn_hierarchy}}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1616,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_devices','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1617,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_ro-mounts','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1618,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_rw-mounts','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1619,'SDP-1.0','YARN','NULL','container-executor','docker_allowed_volume-drivers','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1620,'SDP-1.0','YARN','NULL','container-executor','docker_binary','/usr/bin/docker',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1621,'SDP-1.0','YARN','NULL','container-executor','docker_module_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1622,'SDP-1.0','YARN','NULL','container-executor','docker_privileged-containers_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1623,'SDP-1.0','YARN','NULL','container-executor','docker_trusted_registries','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1624,'SDP-1.0','YARN','NULL','container-executor','gpu_module_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1625,'SDP-1.0','YARN','NULL','container-executor','min_user_id','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1626,'SDP-1.0','YARN','NULL','container-executor','yarn_hierarchy','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1627,'SDP-1.0','YARN','NULL','ranger-yarn-audit','ranger.plugin.yarn.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1628,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.credential.provider.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1629,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1630,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.batch.filespool.dir','/var/log/hadoop/yarn/audit/db/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1631,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.jdbc.driver','{{jdbc_driver}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1632,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.jdbc.url','{{audit_jdbc_url}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1633,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.password','crypted',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1634,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.db.user','{{xa_audit_db_user}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1635,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1636,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hadoop/yarn/audit/hdfs/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1637,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1638,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1639,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hadoop/yarn/audit/solr/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1640,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1641,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1642,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.is.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1643,'SDP-1.0','YARN','NULL','ranger-yarn-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1644,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','REPOSITORY_CONFIG_PASSWORD','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1645,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','REPOSITORY_CONFIG_USERNAME','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1646,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','common.name.for.certificate','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1647,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1648,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1649,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_ranger_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1650,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','external_ranger_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1651,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','hadoop.rpc.protection','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1652,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','policy_user','ambari-qa',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1653,'SDP-1.0','YARN','NULL','ranger-yarn-plugin-properties','ranger-yarn-plugin-enabled','No',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1654,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1655,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1656,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1657,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1658,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1659,'SDP-1.0','YARN','NULL','ranger-yarn-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1660,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.add-yarn-authorization','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1661,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1662,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.pollIntervalMs','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1663,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.rest.ssl.config.file','/etc/hadoop/conf/ranger-policymgr-ssl-yarn.xml',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1664,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1665,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1666,'SDP-1.0','YARN','NULL','ranger-yarn-security','ranger.plugin.yarn.service.name','{{repo_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1667,'SDP-1.0','HDFS','NULL','resource-types','yarn.resource-types','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1668,'SDP-1.0','HDFS','NULL','resource-types','yarn.resource-types.yarn.io_gpu.maximum-allocation','8',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1669,'SDP-1.0','YARN','NULL','yarn-env','min_user_id','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1670,'SDP-1.0','YARN','NULL','yarn-env','apptimelineserver_heapsize','8072',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1671,'SDP-1.0','YARN','NULL','yarn-env','content','\nexport HADOOP_YARN_HOME=/usr/sdp/current/hadoop\nexport HADOOP_LOG_DIR={{yarn_log_dir}}\nexport HADOOP_SECURE_LOG_DIR={{yarn_log_dir}}\nexport HADOOP_PID_DIR={{yarn_pid_dir}}\nexport HADOOP_SECURE_PID_DIR={{yarn_pid_dir}}\nexport HADOOP_LIBEXEC_DIR=/usr/sdp/current/hadoop/libexec\nexport JAVA_HOME={{java64_home}}\nexport JAVA_LIBRARY_PATH=\"${JAVA_LIBRARY_PATH}:{{hadoop_java_io_tmpdir}}\"\n\n# We need to add the EWMA and RFA appender for the yarn daemons only;\n# however, HADOOP_ROOT_LOGGER is shared by the yarn client and the\n# daemons. This is restrict the EWMA appender to daemons only.\nexport HADOOP_LOGLEVEL=${HADOOP_LOGLEVEL:-INFO}\nexport HADOOP_ROOT_LOGGER=${HADOOP_ROOT_LOGGER:-INFO,console}\nexport HADOOP_DAEMON_ROOT_LOGGER=${HADOOP_DAEMON_ROOT_LOGGER:-${HADOOP_LOGLEVEL},EWMA,RFA}\n\n# User for YARN daemons\nexport HADOOP_YARN_USER=${HADOOP_YARN_USER:-yarn}\n\n# some Java parameters\n# export JAVA_HOME=/home/y/libexec/jdk1.6.0/\nif [ \"$JAVA_HOME\" != \"\" ]; then\n#echo \"run java in $JAVA_HOME\"\nJAVA_HOME=$JAVA_HOME\nfi\n\nif [ \"$JAVA_HOME\" = \"\" ]; then\necho \"Error: JAVA_HOME is not set.\"\nexit 1\nfi\n\nJAVA=$JAVA_HOME/bin/java\nJAVA_HEAP_MAX=-Xmx1000m\n\n# For setting YARN specific HEAP sizes please use this\n# Parameter and set appropriately\nYARN_HEAPSIZE={{yarn_heapsize}}\n\n# check envvars which might override default args\nif [ \"$YARN_HEAPSIZE\" != \"\" ]; then\nJAVA_HEAP_MAX=\"-Xmx\"\"$YARN_HEAPSIZE\"\"m\"\nfi\n\n# Resource Manager specific parameters\n\n# Specify the max Heapsize for the ResourceManager using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1000.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_RESOURCEMANAGER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_RESOURCEMANAGER_HEAPSIZE={{resourcemanager_heapsize}}\n\n# Specify the JVM options to be used when starting the ResourceManager.\n# These options will be appended to the options specified as HADOOP_OPTS\n# and therefore may override any similar flags set in HADOOP_OPTS\n{% if security_enabled %}\nexport YARN_RESOURCEMANAGER_OPTS=\"-Djava.security.auth.login.config={{yarn_jaas_file}}\"\n{% endif %}\n\n# Node Manager specific parameters\n\n# Specify the max Heapsize for the NodeManager using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1000.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_NODEMANAGER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_NODEMANAGER_HEAPSIZE={{nodemanager_heapsize}}\n\n# Specify the max Heapsize for the timeline server using a numerical value\n# in the scale of MB. For example, to specify an jvm option of -Xmx1000m, set\n# the value to 1024.\n# This value will be overridden by an Xmx setting specified in either HADOOP_OPTS\n# and/or YARN_TIMELINESERVER_OPTS.\n# If not specified, the default value will be picked from either YARN_HEAPMAX\n# or JAVA_HEAP_MAX with YARN_HEAPMAX as the preferred option of the two.\nexport YARN_TIMELINESERVER_HEAPSIZE={{apptimelineserver_heapsize}}\n\n{% if security_enabled %}\nexport YARN_TIMELINESERVER_OPTS=\"-Djava.security.auth.login.config={{yarn_ats_jaas_file}}\"\n{% endif %}\n\n{% if security_enabled %}\nexport YARN_TIMELINEREADER_OPTS=\"-Djava.security.auth.login.config={{yarn_ats_jaas_file}}\"\n{% endif %}\n\n{% if security_enabled %}\nexport YARN_REGISTRYDNS_OPTS=\"-Djava.security.auth.login.config={{yarn_registry_dns_jaas_file}}\"\n{% endif %}\n\n# Specify the JVM options to be used when starting the NodeManager.\n# These options will be appended to the options specified as HADOOP_OPTS\n# and therefore may override any similar flags set in HADOOP_OPTS\n{% if security_enabled %}\nexport YARN_NODEMANAGER_OPTS=\"-Djava.security.auth.login.config={{yarn_nm_jaas_file}} -Dsun.security.krb5.rcache=none\"\n{% endif %}\n\n# so that filenames w/ spaces are handled correctly in loops below\nIFS=\n\n\n# default log directory and file\nif [ \"$HADOOP_LOG_DIR\" = \"\" ]; then\nHADOOP_LOG_DIR=\"$HADOOP_YARN_HOME/logs\"\nfi\nif [ \"$HADOOP_LOGFILE\" = \"\" ]; then\nHADOOP_LOGFILE=\'yarn.log\'\nfi\n\n# default policy file for service-level authorization\nif [ \"$YARN_POLICYFILE\" = \"\" ]; then\nYARN_POLICYFILE=\"hadoop-policy.xml\"\nfi\n\n# restore ordinary behaviour\nunset IFS\n\n# YARN now uses specific subcommand options of the pattern (command)_(subcommand)_OPTS for every\n# component. Because of this, HADDOP_OPTS is now used as a simple way to specify common properties\n# between all YARN components.\nHADOOP_OPTS=\"$HADOOP_OPTS -Dyarn.id.str=$YARN_IDENT_STRING\"\nHADOOP_OPTS=\"$HADOOP_OPTS -Dyarn.policy.file=$YARN_POLICYFILE\"\nHADOOP_OPTS=\"$HADOOP_OPTS -Djava.io.tmpdir={{hadoop_java_io_tmpdir}}\"\n\n{% if security_enabled %}\nHADOOP_OPTS=\"$HADOOP_OPTS -Djavax.security.auth.useSubjectCredsOnly=false\"\n{% endif %}\n\n{% if rm_security_opts is defined %}\nYARN_RESOURCEMANAGER_OPTS=\"{{rm_security_opts}} $YARN_RESOURCEMANAGER_OPTS\"\n{% endif %}\n\nexport YARN_NODEMANAGER_OPTS=\"$YARN_NODEMANAGER_OPTS -Dnm.audit.logger=INFO,NMAUDIT\"\nexport YARN_RESOURCEMANAGER_OPTS=\"$YARN_RESOURCEMANAGER_OPTS -Dyarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY -Drm.audit.logger=INFO,RMAUDIT\"\n\n{% if registry_dns_needs_privileged_access %}\n# If the DNS server is configured to use the standard privileged port 53,\n# the environment variables YARN_REGISTRYDNS_SECURE_USER and\n# YARN_REGISTRYDNS_SECURE_EXTRA_OPTS must be set.\nexport YARN_REGISTRYDNS_SECURE_USER={{yarn_user}}\nexport YARN_REGISTRYDNS_SECURE_EXTRA_OPTS=\"-jvm server\"\n{% endif %}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1672,'SDP-1.0','YARN','NULL','yarn-env','is_supported_yarn_ranger','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1673,'SDP-1.0','YARN','NULL','yarn-env','nodemanager_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1674,'SDP-1.0','YARN','NULL','yarn-env','registry.dns.bind-port','53',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1675,'SDP-1.0','YARN','NULL','yarn-env','resourcemanager_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1676,'SDP-1.0','YARN','NULL','yarn-env','service_check.queue.name','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1677,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_principal_name','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1678,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_user_keytab','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1679,'SDP-1.0','YARN','NULL','yarn-env','yarn_cgroups_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1680,'SDP-1.0','YARN','NULL','yarn-env','yarn_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1681,'SDP-1.0','YARN','NULL','yarn-env','yarn_log_dir_prefix','/var/log/hadoop-yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1682,'SDP-1.0','YARN','NULL','yarn-env','yarn_pid_dir_prefix','/var/run/hadoop-yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1683,'SDP-1.0','YARN','NULL','yarn-env','yarn_user_nofile_limit','32768',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1684,'SDP-1.0','YARN','NULL','yarn-env','yarn_user_nproc_limit','65536',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1685,'SDP-1.0','YARN','NULL','yarn-env','yarn_ats_user','yarn-ats',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1686,'SDP-1.0','YARN','NULL','yarn-env','yarn_user','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1760,'SDP-1.0','YARN','NULL','yarn-log4j','content','\n#Relative to Yarn Log Dir Prefix\nyarn.log.dir=.\n#\n# Job Summary Appender\n#\n# Use following logger to send summary to separate file defined by\n# hadoop.mapreduce.jobsummary.log.file rolled daily:\n# hadoop.mapreduce.jobsummary.logger=INFO,JSA\n#\nhadoop.mapreduce.jobsummary.logger=${hadoop.root.logger}\nhadoop.mapreduce.jobsummary.log.file=hadoop-mapreduce.jobsummary.log\nlog4j.appender.JSA=org.apache.log4j.DailyRollingFileAppender\n# Set the ResourceManager summary log filename\nyarn.server.resourcemanager.appsummary.log.file=hadoop-mapreduce.jobsummary.log\n# Set the ResourceManager summary log level and appender\nyarn.server.resourcemanager.appsummary.logger=${hadoop.root.logger}\n#yarn.server.resourcemanager.appsummary.logger=INFO,RMSUMMARY\n\n# To enable AppSummaryLogging for the RM,\n# set yarn.server.resourcemanager.appsummary.logger to\n# LEVEL,RMSUMMARY in hadoop-env.sh\n\n# Appender for ResourceManager Application Summary Log\n# Requires the following properties to be set\n#    - hadoop.log.dir (Hadoop Log directory)\n#    - yarn.server.resourcemanager.appsummary.log.file (resource manager app summary log filename)\n#    - yarn.server.resourcemanager.appsummary.logger (resource manager app summary log level and appender)\nlog4j.appender.RMSUMMARY=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RMSUMMARY.File=${yarn.log.dir}/${yarn.server.resourcemanager.appsummary.log.file}\nlog4j.appender.RMSUMMARY.MaxFileSize={{yarn_rm_summary_log_max_backup_size}}MB\nlog4j.appender.RMSUMMARY.MaxBackupIndex={{yarn_rm_summary_log_number_of_backup_files}}\nlog4j.appender.RMSUMMARY.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RMSUMMARY.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.JSA.layout=org.apache.log4j.PatternLayout\nlog4j.appender.JSA.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{2}: %m%n\nlog4j.appender.JSA.DatePattern=\'.\'yyyy-MM-dd-HH\nlog4j.appender.JSA.layout=org.apache.log4j.PatternLayout\nlog4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary=${yarn.server.resourcemanager.appsummary.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary=false\n\n# Appender for viewing information for errors and warnings\nyarn.ewma.cleanupInterval=300\nyarn.ewma.messageAgeLimitSeconds=86400\nyarn.ewma.maxUniqueMessages=250\nlog4j.appender.EWMA=org.apache.hadoop.yarn.util.Log4jWarningErrorMetricsAppender\nlog4j.appender.EWMA.cleanupInterval=${yarn.ewma.cleanupInterval}\nlog4j.appender.EWMA.messageAgeLimitSeconds=${yarn.ewma.messageAgeLimitSeconds}\nlog4j.appender.EWMA.maxUniqueMessages=${yarn.ewma.maxUniqueMessages}\n\n# Audit logging for ResourceManager\nrm.audit.logger=${hadoop.root.logger}\nlog4j.logger.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger=${rm.audit.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger=false\nlog4j.appender.RMAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.RMAUDIT.File=${yarn.log.dir}/rm-audit.log\nlog4j.appender.RMAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.RMAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.RMAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH\n\n# Audit logging for NodeManager\nnm.audit.logger=${hadoop.root.logger}\nlog4j.logger.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger=${nm.audit.logger}\nlog4j.additivity.org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger=false\nlog4j.appender.NMAUDIT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.NMAUDIT.File=${yarn.log.dir}/nm-audit.log\nlog4j.appender.NMAUDIT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.NMAUDIT.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n\nlog4j.appender.NMAUDIT.DatePattern=\'.\'yyyy-MM-dd-HH',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1761,'SDP-1.0','YARN','NULL','yarn-log4j','yarn_rm_summary_log_max_backup_size','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1762,'SDP-1.0','YARN','NULL','yarn-log4j','yarn_rm_summary_log_number_of_backup_files','20',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1763,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.proxyuser.root.hosts','%HOSTGROUP::MASTER1%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1764,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.proxyuser.root.groups','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1765,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.app-cache-size','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1766,'SDP-1.0','YARN','NULL','yarn-site','hadoop.http.cross-origin.allowed-origins','{{cross_origins}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1767,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.bind-address','0.0.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1768,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.bind-port','53',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1769,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.domain-name','EXAMPLE.COM',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1770,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1771,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.zone-mask','255.255.255.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1772,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.dns.zone-subnet','172.17.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1773,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.zk.quorum','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1774,'SDP-1.0','YARN','NULL','yarn-site','manage.include.files','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1775,'SDP-1.0','YARN','NULL','yarn-site','yarn.acl.enable','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1776,'SDP-1.0','YARN','NULL','yarn-site','yarn.admin.acl','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1777,'SDP-1.0','YARN','NULL','yarn-site','yarn.application.classpath','$HADOOP_CONF_DIR,/usr/sdp/current/hadoop/*,/usr/sdp/current/hadoop/share/hadoop/client/*,/usr/sdp/current/hadoop/share/hadoop/common/*,/usr/sdp/current/hadoop/share/hadoop/common/lib/*,/usr/sdp/current/hadoop/share/hadoop/hdfs/*,/usr/sdp/current/hadoop/share/hadoop/hdfs/lib/*,,/usr/sdp/current/hadoop/share/hadoop/mapreduce/*,/usr/sdp/current/hadoop/share/hadoop/yarn/*,/usr/sdp/current/hadoop/share/hadoop/yarn/lib/*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1778,'SDP-1.0','YARN','NULL','yarn-site','yarn.client.nodemanager-connect.max-wait-ms','60000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1779,'SDP-1.0','YARN','NULL','yarn-site','yarn.client.nodemanager-connect.retry-interval-ms','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1780,'SDP-1.0','YARN','NULL','yarn-site','yarn.http.policy','HTTP_ONLY',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1781,'SDP-1.0','YARN','NULL','yarn-site','yarn.log-aggregation-enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1782,'SDP-1.0','YARN','NULL','yarn-site','yarn.log-aggregation.retain-seconds','2592000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1783,'SDP-1.0','YARN','NULL','yarn-site','yarn.log.server.url','http://%HOSTGROUP::AMBARI%:19888/jobhistory/logs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1784,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1785,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.fs-store.retry-policy-spec','2000, 500',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1786,'SDP-1.0','YARN','NULL','yarn-site','yarn.node-labels.fs-store.root-dir','/system/yarn/node-labels',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1787,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.address','0.0.0.0:45454',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1788,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.admin-env','MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1789,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services','mapreduce_shuffle,spark_shuffle,spark2_shuffle,{{timeline_collector}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1790,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.mapreduce_shuffle.class','org.apache.hadoop.mapred.ShuffleHandler',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1791,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark2_shuffle.class','org.apache.spark.network.yarn.YarnShuffleService',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1792,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark2_shuffle.classpath','/usr/sdp/current/spark/yarn/*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1793,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark_shuffle.class','org.apache.spark.network.yarn.YarnShuffleService',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1794,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.spark_shuffle.classpath','/usr/sdp/current/spark/yarn/*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1795,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.aux-services.timeline_collector.class','org.apache.hadoop.yarn.server.timelineservice.collector.PerNodeTimelineCollectorsAuxService',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1796,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.bind-host','0.0.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1797,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-executor.class','org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1798,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-metrics.unregister-delay-ms','60000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1799,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.container-monitor.interval-ms','3000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1800,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.delete.debug-delay-sec','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1801,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage','90',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1802,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1803,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.disk-health-checker.min-healthy-disks','0.25',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1804,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.health-checker.interval-ms','135000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1805,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.health-checker.script.timeout-ms','60000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1806,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1807,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.group','hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1808,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1809,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.compression-type','gz',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1810,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.debug-enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1811,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.num-log-files-per-app','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1812,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds','3600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1813,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.log.retain-seconds','604800',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1814,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.dir','{{yarn_log_dir_prefix}}/nodemanager/recovery-state',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1815,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1816,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.recovery.supervised','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1817,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.remote-app-log-dir','/app-logs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1818,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.remote-app-log-dir-suffix','logs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1819,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1820,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1821,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.docker-plugin','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1822,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidiadocker-v1.endpoint','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1823,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource-plugins.gpu.path-to-discovery-executables','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1824,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.cpu-vcores','12',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1825,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.memory-mb','77824',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1826,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resource.percentage-physical-cpu-limit','80',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1827,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.resourcemanager.connect.wait.secs','1800',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1828,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.allowed-runtimes','default,docker',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1829,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.allowed-container-networks','host,none,bridge',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1830,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.capabilities','\n      CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,\n      SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1831,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.default-container-network','host',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1832,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.privileged-containers.acl','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1833,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1834,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.vmem-check-enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1835,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.vmem-pmem-ratio','2.1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1836,'SDP-1.0','YARN','NULL','yarn-site','yarn.nodemanager.webapp.cross-origin.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1837,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.am.max-attempts','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1838,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.bind-host','0.0.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1839,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.connect.max-wait.ms','900000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1840,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.connect.retry-interval.ms','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1841,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.display.per-user-apps','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1842,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.fs.state-store.retry-policy-spec','2000, 500',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1843,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.fs.state-store.uri',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1844,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.ha.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1845,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.intra-queue-preemption.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1846,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.monitoring_interval','15000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1847,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.natural_termination_factor','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1848,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.monitor.capacity.preemption.total_preemption_per_round','0.33',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1849,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.nodes.exclude-path','/etc/hadoop/conf/yarn.exclude',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1850,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.placement-constraints.handler','scheduler',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1851,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.recovery.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1852,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.scheduler.class','org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1853,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.scheduler.monitor.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1854,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.state-store.max-completed-applications','${yarn.resourcemanager.max-completed-applications}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1855,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.store.class','org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1856,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1857,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.system-metrics-publisher.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1858,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.cross-origin.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1859,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1860,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.https.address','%HOSTGROUP::AMBARI%:8090',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1861,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.work-preserving-recovery.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1862,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1863,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-acl','world:anyone:rwcda',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1864,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-num-retries','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1865,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-retry-interval-ms','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1866,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-state-store.parent-path','/rmstore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1867,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.zk-timeout-ms','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1868,'SDP-1.0','YARN','NULL','yarn-site','yarn.rm.system-metricspublisher.emit-container-events','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1869,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.capacity.ordering-policy.priority-utilization.underutilized-preemption.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1870,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.maximum-allocation-mb','77824',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1871,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.maximum-allocation-vcores','12',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1872,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.minimum-allocation-mb','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1873,'SDP-1.0','YARN','NULL','yarn-site','yarn.scheduler.minimum-allocation-vcores','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1874,'SDP-1.0','YARN','NULL','yarn-site','yarn.service.framework.path','/sdp/apps/yarn/service-dep.tar.gz',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1875,'SDP-1.0','YARN','NULL','yarn-site','yarn.service.system-service.dir','/services',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1876,'SDP-1.0','YARN','NULL','yarn-site','yarn.system-metricspublisher.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1877,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.bind-host','0.0.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1878,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.client.max-retries','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1879,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.client.retry-interval-ms','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1880,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1881,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.active-dir','/ats/active/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1882,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds','3600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1883,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.done-dir','/ats/done/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1884,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.group-id-plugin-classes','org.apache.hadoop.yarn.applications.distributedshell.DistributedShellTimelinePlugin',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1885,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.group-id-plugin-classpath','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1886,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.retain-seconds','604800',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1887,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.scan-interval-seconds','60',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1888,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.entity-group-fs-store.summary-store','org.apache.hadoop.yarn.server.timeline.RollingLevelDBTimelineStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1889,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.generic-application-history.save-non-am-container-meta-info','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1890,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.generic-application-history.store-class','org.apache.hadoop.yarn.server.applicationhistoryservice.NullApplicationHistoryStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1891,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase-schema.prefix','prod.',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1892,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase.configuration.file','file://{{yarn_hbase_conf_dir}}/hbase-site.xml',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1893,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.hbase.coprocessor.jar.hdfs.location','{{yarn_timeline_jar_location}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1894,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.simple.anonymous.allowed','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1895,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-authentication.type','simple',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1896,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.http-cross-origin.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1897,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.read-cache-size','104857600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1898,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1899,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1900,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms','300000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1903,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.recovery.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1904,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.state-store-class','org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1905,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.store-class','org.apache.hadoop.yarn.server.timeline.EntityGroupFSTimelineStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1906,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.ttl-enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1907,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.ttl-ms','2678400000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1908,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.version','2.0f',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1909,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.versions','1.5f,2.0f',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1910,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.webapp.address','%HOSTGROUP::MASTER1%:8188',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1911,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.webapp.https.address','%HOSTGROUP::AMBARI%:8190',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1912,'SDP-1.0','YARN','NULL','yarn-site','yarn.webapp.api-service.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1913,'SDP-1.0','YARN','NULL','yarn-site','yarn.webapp.ui2.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1914,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','content','\n      # export JAVA_HOME=/home/y/libexec/jdk1.8.0/\n\n      export HADOOP_JOB_HISTORYSERVER_HEAPSIZE={{jobhistory_heapsize}}\n\n      # We need to add the RFA appender for the mr daemons only;\n      # however, HADOOP_MAPRED_LOGGER is shared by the mapred client and the\n      # daemons. This will restrict the RFA appender to daemons only.\n      export HADOOP_LOGLEVEL=${HADOOP_LOGLEVEL:-INFO}\n      export HADOOP_ROOT_LOGGER=${HADOOP_ROOT_LOGGER:-INFO,console}\n      export HADOOP_DAEMON_ROOT_LOGGER=${HADOOP_DAEMON_ROOT_LOGGER:-${HADOOP_LOGLEVEL},RFA}\n\n      {% if security_enabled %}\n      export MAPRED_HISTORYSERVER_OPTS=\"-Djava.security.auth.login.config={{mapred_jaas_file}}  -Djavax.security.auth.useSubjectCredsOnly=false\"\n      {% endif %}\n\n      #export HADOOP_JHS_LOGGER=INFO,RFA # Hadoop JobSummary logger.\n      #export HADOOP_IDENT_STRING= #A string representing this instance of hadoop. $USER by default\n      #export HADOOP_NICENESS= #The scheduling priority for daemons. Defaults to 0.\n      export HADOOP_OPTS=\"-Dsdp.version=$SDP_VERSION $HADOOP_OPTS\"\n      export HADOOP_OPTS=\"-Djava.io.tmpdir={{hadoop_java_io_tmpdir}} $HADOOP_OPTS\"\n      export JAVA_LIBRARY_PATH=\"${JAVA_LIBRARY_PATH}:{{hadoop_java_io_tmpdir}}\"\n\n      # History server logs\n      export HADOOP_LOG_DIR={{mapred_log_dir_prefix}}/$USER\n\n      # History server pid\n      export HADOOP_PID_DIR={{mapred_pid_dir_prefix}}/$USER',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1915,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','jobhistory_heapsize','900',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1916,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_log_dir_prefix','/var/log/hadoop-mapreduce',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1917,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_pid_dir_prefix','/var/run/hadoop-mapreduce',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1918,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user_nofile_limit','32768',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1919,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user_nproc_limit','65536',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1920,'SDP-1.0','MAPREDUCE2','NULL','mapred-env','mapred_user','mapred',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1921,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapred.local.dir','/data/disk0/hadoop/mapred',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1922,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.map.child.java.opts','-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1923,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.reduce.child.java.opts','-server -XX:NewRatio=8 -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1924,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.admin.user.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1925,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.am.max-attempts','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1926,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.application.classpath','$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:$PWD/mr-framework/hadoop/share/hadoop/tools/lib/*:/usr/sdp/${sdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${sdp.version}.jar:/etc/hadoop/conf/secure',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1927,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.application.framework.path','/sdp/apps/mapreduce/mapreduce.tar.gz#mr-framework',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1928,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.cluster.acls.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1929,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.cluster.administrators',' hadoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1930,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.framework.name','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1931,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.acl-modify-job',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1932,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.acl-view-job',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1933,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.counters.max','130',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1934,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.emit-timeline-data','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1935,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.queuename','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1936,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.job.reduce.slowstart.completedmaps','0.05',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1937,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.address','%HOSTGROUP::MASTER1%:10020',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1938,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.admin.acl','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1939,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.bind-host','0.0.0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1940,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.done-dir','/mr-history/done',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1941,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.http.policy','HTTP_ONLY',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1942,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.intermediate-done-dir','/mr-history/tmp',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1943,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1944,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.store.class','org.apache.hadoop.mapreduce.v2.hs.HistoryServerLeveldbStateStoreService',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1945,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.recovery.store.leveldb.path','/data/disk0/hadoop/mapreduce/jhs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1946,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.jobhistory.webapp.address','%HOSTGROUP::AMBARI%:19888',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1947,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.java.opts','-Xmx15564m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1948,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1949,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.memory.mb','19456',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1950,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.output.compress','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1951,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.sort.spill.percent','0.7',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1952,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.map.speculative','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1953,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.output.fileoutputformat.compress','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1954,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.output.fileoutputformat.compress.type','BLOCK',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1955,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.input.buffer.percent','0.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1956,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.java.opts','-Xmx31129m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1957,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1958,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.memory.mb','38912',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1959,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.enabled','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1960,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.interval-ms','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1961,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.fetch.retry.timeout-ms','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1962,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.input.buffer.percent','0.7',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1963,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.merge.percent','0.66',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1964,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.shuffle.parallelcopies','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1965,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.reduce.speculative','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1966,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.shuffle.port','13562',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1967,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.io.sort.factor','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1968,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.io.sort.mb','2047',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1969,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','mapreduce.task.timeout','300000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1970,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.admin-command-opts','-Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1971,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.command-opts','-Xmx15564m -Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1972,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1973,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.resource.mb','19456',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1974,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','yarn.app.mapreduce.am.staging-dir','/user',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1975,'SDP-1.0','TEZ','NULL','tez-env','content','\n# Tez specific configuration\nexport TEZ_CONF_DIR={{config_dir}}\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n# The java implementation to use.\nexport JAVA_HOME={{java64_home}}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1976,'SDP-1.0','TEZ','NULL','tez-env','enable_heap_dump','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1977,'SDP-1.0','TEZ','NULL','tez-env','heap_dump_location','/tmp',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1978,'SDP-1.0','TEZ','NULL','tez-env','tez_user','tez',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1979,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.service.class','org.apache.tez.dag.history.logging.proto.ProtoHistoryLoggingService',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1980,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.proto-base-dir','/warehouse/tablespace/external/hive/sys.db',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1981,'SDP-1.0','TEZ','NULL','tez-site','tez.queue.name','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1982,'SDP-1.0','TEZ','NULL','tez-site','tez.am.java.opts','-server -Xmx15564m -Djava.net.preferIPv4Stack=true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1983,'SDP-1.0','TEZ','NULL','tez-site','tez.am.am-rm.heartbeat.interval-ms.max','250',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1984,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.idle.release-timeout-max.millis','20000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1985,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.idle.release-timeout-min.millis','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1986,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1987,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.locality.delay-allocation-millis','250',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1988,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.non-local-fallback.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1989,'SDP-1.0','TEZ','NULL','tez-site','tez.am.container.reuse.rack-fallback.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1990,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.cluster-default.cmd-opts','-server -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1991,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.cmd-opts','-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB{{heap_dump_opts}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1992,'SDP-1.0','TEZ','NULL','tez-site','tez.am.launch.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1993,'SDP-1.0','TEZ','NULL','tez-site','tez.am.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1994,'SDP-1.0','TEZ','NULL','tez-site','tez.am.max.app.attempts','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1995,'SDP-1.0','TEZ','NULL','tez-site','tez.am.maxtaskfailures.per.node','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1996,'SDP-1.0','TEZ','NULL','tez-site','tez.am.resource.memory.mb','19456',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1997,'SDP-1.0','TEZ','NULL','tez-site','tez.am.tez-ui.history-url.template','__HISTORY_URL_BASE__?viewPath=%2F%23%2Ftez-app%2F__APPLICATION_ID__',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1998,'SDP-1.0','TEZ','NULL','tez-site','tez.am.view-acls','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(1999,'SDP-1.0','TEZ','NULL','tez-site','tez.cluster.additional.classpath.prefix','/usr/sdp/${sdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${sdp.version}.jar:/etc/hadoop/conf/secure',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2000,'SDP-1.0','TEZ','NULL','tez-site','tez.counters.max','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2001,'SDP-1.0','TEZ','NULL','tez-site','tez.counters.max.groups','3000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2002,'SDP-1.0','TEZ','NULL','tez-site','tez.generate.debug.artifacts','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2003,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.max-size','1073741824',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2004,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.min-size','16777216',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2005,'SDP-1.0','TEZ','NULL','tez-site','tez.grouping.split-waves','1.7',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2006,'SDP-1.0','TEZ','NULL','tez-site','tez.history.logging.timeline-cache-plugin.old-num-dags-per-group','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2007,'SDP-1.0','TEZ','NULL','tez-site','tez.lib.uris','/sdp/apps/tez/tez.tar.gz',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2008,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.compress','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2009,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.compress.codec','org.apache.hadoop.io.compress.SnappyCodec',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2010,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.convert.user-payload.to.history-text','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2011,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.io.sort.mb','5136',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2012,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.optimize.local.fetch','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2013,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.pipelined.sorter.sort.threads','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2014,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.shuffle.fetch.buffer.percent','0.6',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2015,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.shuffle.memory.limit.percent','0.25',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2016,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.sorter.class','PIPELINED',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2017,'SDP-1.0','TEZ','NULL','tez-site','tez.runtime.unordered.output.buffer.size-mb','1459',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2018,'SDP-1.0','TEZ','NULL','tez-site','tez.session.am.dag.submit.timeout.secs','600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2019,'SDP-1.0','TEZ','NULL','tez-site','tez.session.client.timeout.secs','-1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2020,'SDP-1.0','TEZ','NULL','tez-site','tez.shuffle-vertex-manager.max-src-fraction','0.4',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2021,'SDP-1.0','TEZ','NULL','tez-site','tez.shuffle-vertex-manager.min-src-fraction','0.2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2022,'SDP-1.0','TEZ','NULL','tez-site','tez.staging-dir','/tmp/${user.name}/staging',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2023,'SDP-1.0','TEZ','NULL','tez-site','tez.task.am.heartbeat.counter.interval-ms.max','4000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2024,'SDP-1.0','TEZ','NULL','tez-site','tez.task.generate.counters.per.io','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2025,'SDP-1.0','TEZ','NULL','tez-site','tez.task.get-task.sleep.interval-ms.max','200',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2026,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.cluster-default.cmd-opts','-server -Djava.net.preferIPv4Stack=true -Dsdp.version=${sdp.version}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2027,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.cmd-opts','-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB{{heap_dump_opts}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2028,'SDP-1.0','TEZ','NULL','tez-site','tez.task.launch.env','LD_LIBRARY_PATH=/usr/sdp/${sdp.version}/hadoop/lib/native:/usr/sdp/${sdp.version}/hadoop/lib/native/Linux-{{architecture}}-64',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2029,'SDP-1.0','TEZ','NULL','tez-site','tez.task.max-events-per-heartbeat','500',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2030,'SDP-1.0','TEZ','NULL','tez-site','tez.task.resource.memory.mb','19456',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2031,'SDP-1.0','TEZ','NULL','tez-site','tez.tez-ui.history-url.base','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2032,'SDP-1.0','TEZ','NULL','tez-site','tez.use.cluster.hadoop-libs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2033,'SDP-1.0','TEZ','NULL','tez-site','yarn.timeline-service.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2034,'SDP-1.0','HIVE','NULL','beeline-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = BeelineLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = console\n\n# list of all appenders\nappenders = console\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# list of all loggers\nloggers = HiveConnection\n\n# HiveConnection logs useful info for dynamic service discovery\nlogger.HiveConnection.name = org.apache.hive.jdbc.HiveConnection\nlogger.HiveConnection.level = INFO\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2035,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.keepAliveTime','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2036,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.maxThreads','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2037,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.minThreads','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2038,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.numRetries','3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2039,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.queueSize','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2040,'SDP-1.0','HIVE','NULL','hive-atlas-application.properties','atlas.hook.hive.synchronous','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2041,'SDP-1.0','HIVE','NULL','hive-env','alert_ldap_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2042,'SDP-1.0','HIVE','NULL','hive-env','alert_ldap_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2043,'SDP-1.0','HIVE','NULL','hive-env','beeline_jdbc_url_default','container',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2044,'SDP-1.0','HIVE','NULL','hive-env','content','\n# The heap size of the jvm, and jvm args stared by hive shell script can be controlled via:\nif [ \"$SERVICE\" = \"metastore\" ]; then\n\n  export HADOOP_HEAPSIZE={{hive_metastore_heapsize}} # Setting for HiveMetastore\n  export HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hivemetastore-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hms_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hivemetastore.log\"\n\nfi\n\nif [ \"$SERVICE\" = \"hiveserver2\" ]; then\n\n  export HADOOP_HEAPSIZE={{hive_heapsize}} # Setting for HiveServer2 and Client\n  export HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hiveserver2-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hs2_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hiveserver2.log\"\n\nfi\n\n{% if security_enabled %}\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}\n\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS  -Xmx${HADOOP_HEAPSIZE}m\"\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS{{heap_dump_opts}}\"\n\n# Larger heap size may be required when running queries over large number of files or partitions.\n# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be\n# appropriate for hive server (hwi etc).\n\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nHADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\nexport HIVE_HOME=${HIVE_HOME:-{{hive_home_dir}}}\n\n# Hive Configuration Directory can be controlled by:\nexport HIVE_CONF_DIR=${HIVE_CONF_DIR:-{{hive_config_dir}}}\n\n# Folder containing extra libraries required for hive compilation/execution can be controlled by:\nif [ \"${HIVE_AUX_JARS_PATH}\" != \"\" ]; then\n  if [ -f \"${HIVE_AUX_JARS_PATH}\" ]; then\n    export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}\n  elif [ -d \"/usr/sdp/current/hive-webhcat/share/hcatalog\" ]; then\n    export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar\n  fi\nelif [ -d \"/usr/sdp/current/hive-webhcat/share/hcatalog\" ]; then\n  export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar\nfi\n\nexport METASTORE_PORT={{hive_metastore_port}}\n\n{% if sqla_db_used or lib_dir_available %}\nexport LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:{{jdbc_libs_dir}}\"\nexport JAVA_LIBRARY_PATH=\"$JAVA_LIBRARY_PATH:{{jdbc_libs_dir}}\"\n{% endif %}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2045,'SDP-1.0','HIVE','NULL','hive-env','enable_heap_dump','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2046,'SDP-1.0','HIVE','NULL','hive-env','heap_dump_location','/tmp',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2047,'SDP-1.0','HIVE','NULL','hive-env','hive.atlas.hook','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2048,'SDP-1.0','HIVE','NULL','hive-env','hive.heapsize','48311',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2049,'SDP-1.0','HIVE','NULL','hive-env','hive.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2050,'SDP-1.0','HIVE','NULL','hive-env','hive.metastore.heapsize','16103',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2051,'SDP-1.0','HIVE','NULL','hive-env','hive_ambari_database','MySQL',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2052,'SDP-1.0','HIVE','NULL','hive-env','hive_database','Existing MySQL / MariaDB Database',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2053,'SDP-1.0','HIVE','NULL','hive-env','hive_database_name','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2054,'SDP-1.0','HIVE','NULL','hive-env','hive_database_type','mysql',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2055,'SDP-1.0','HIVE','NULL','hive-env','hive_log_dir','/var/log/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2056,'SDP-1.0','HIVE','NULL','hive-env','hive_pid_dir','/var/run/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2057,'SDP-1.0','HIVE','NULL','hive-env','hive_security_authorization','None',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2058,'SDP-1.0','HIVE','NULL','hive-env','hive_timeline_logging_enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2059,'SDP-1.0','HIVE','NULL','hive-env','hive_user_nofile_limit','32000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2060,'SDP-1.0','HIVE','NULL','hive-env','hive_user_nproc_limit','16000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2061,'SDP-1.0','HIVE','NULL','hive-env','test_db_connection','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2062,'SDP-1.0','HIVE','NULL','hive-env','hive_user','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2063,'SDP-1.0','HIVE','NULL','hive-exec-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = HiveExecLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = FA\nproperty.hive.query.id = hadoop\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = ${sys:hive.query.id}.log\n\n# list of all appenders\nappenders = console, FA\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# simple file appender\nappender.FA.type = File\nappender.FA.name = FA\nappender.FA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\nappender.FA.layout.type = PatternLayout\nappender.FA.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n\n\n# list of all loggers\nloggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2064,'SDP-1.0','HIVE','NULL','hive-interactive-env','content','\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Xloggc:{{hive_log_dir}}/hiveserverinteractive-gc-%t.log -XX:+UseG1GC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCCause -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=10M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath={{hive_log_dir}}/hsi_heapdump.hprof -Dhive.log.dir={{hive_log_dir}} -Dhive.log.file=hiveserver2Interactive.log\"\n\n# The heap size of the jvm stared by hive shell script can be controlled via:\nexport HADOOP_HEAPSIZE={{hive_interactive_heapsize}} # Setting for HiveServer2 and Client\n\n{% if security_enabled %}\nexport HADOOP_OPTS=\"$HADOOP_OPTS -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}\n\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS  -Xmx${HADOOP_HEAPSIZE}m\"\nexport HADOOP_CLIENT_OPTS=\"$HADOOP_CLIENT_OPTS{{heap_dump_opts}}\"\n\n# Larger heap size may be required when running queries over large number of files or partitions.\n# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be\n# appropriate for hive server (hwi etc).\n\n\n# Set HADOOP_HOME to point to a specific hadoop install directory\nHADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n# Hive Configuration Directory can be controlled by:\nexport HIVE_CONF_DIR={{hive_server_interactive_conf_dir}}\n\n# Add additional hcatalog jars\nif [ \"${HIVE_AUX_JARS_PATH}\" != \"\" ]; then\n  export HIVE_AUX_JARS_PATH=${HIVE_AUX_JARS_PATH}\nelse\n  export HIVE_AUX_JARS_PATH=/usr/sdp/current/hive-server2/lib/hive-hcatalog-core.jar\nfi\n\nexport METASTORE_PORT={{hive_metastore_port}}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2065,'SDP-1.0','HIVE','NULL','hive-interactive-env','enable_hive_interactive','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2066,'SDP-1.0','HIVE','NULL','hive-interactive-env','hive_aux_jars','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2067,'SDP-1.0','HIVE','NULL','hive-interactive-env','hive_heapsize','512',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2068,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_app_name','llap0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2069,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_headroom_space','12288',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2070,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_heap_size','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2071,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_java_opts','-XX:+AlwaysPreTouch -XX:+UseG1GC -XX:TLABSize=8m -XX:+ResizeTLAB -XX:+UseNUMA -XX:+AggressiveOpts -XX:InitiatingHeapOccupancyPercent=70 -XX:+UnlockExperimentalVMOptions -XX:G1MaxNewSizePercent=40 -XX:G1ReservePercent=20 -XX:MaxGCPauseMillis=200{{heap_dump_opts}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2072,'SDP-1.0','HIVE','NULL','hive-interactive-env','llap_log_level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2073,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_llap_nodes','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2074,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_llap_nodes_for_llap_daemons','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2075,'SDP-1.0','HIVE','NULL','hive-interactive-env','num_retries_for_checking_llap_status','20',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2076,'SDP-1.0','HIVE','NULL','hive-interactive-site','dfs.client.mmap.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2077,'SDP-1.0','HIVE','NULL','hive-interactive-site','dfs.short.circuit.shared.memory.watcher.interrupt.check.ms','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2078,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.auto.convert.join.noconditionaltask.size','1000000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2079,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.driver.parallel.compilation','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2080,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.basePersistDirectory','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2081,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.bitmap.type','roaring',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2082,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.broker.address.default','localhost:8082',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2083,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.coordinator.address.default','localhost:8082',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2084,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.http.read.timeout','PT10M',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2085,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.memory.rownum.max','75000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2086,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.partition.size.max','1000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2087,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.indexer.segments.granularity','DAY',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2088,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.maxTries','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2089,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.db.type','mysql',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2090,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.password','{{druid_metadata_password}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2091,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.uri','jdbc:mysql://localhost:3355/druid',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2092,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.metadata.username','druid',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2093,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.overlord.address.default','localhost:8090',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2094,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.passiveWaitTimeMs','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2095,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.select.distribute','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2096,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.storage.storageDirectory','{{druid_storage_dir}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2097,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.druid.working.directory','/tmp/druid-indexing',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2098,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.exec.orc.split.strategy','HYBRID',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2099,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.execution.mode','llap',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2100,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.limit.optimize.enable','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2101,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.auto.allow.uber','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2102,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.client.consistent.splits','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2103,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.am.liveness.heartbeat.interval.ms','10000ms',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2104,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.logger','query-routing',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2105,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.num.executors','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2106,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.queue.name','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2107,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.rpc.port','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2108,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.service.hosts','@llap0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2109,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.task.scheduler.enable.preemption','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2110,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.vcpus.per.instance','{hive_llap_daemon_num_executors}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2111,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.yarn.container.mb','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2112,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.daemon.yarn.shuffle.port','15551',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2113,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.enable.grace.join.in.llap','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2114,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.execution.mode','only',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2115,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.allocator.mmap','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2116,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.allocator.mmap.path','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2117,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2118,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.memory.mode','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2119,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.memory.size','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2120,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.threadpool.size','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2121,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.io.use.lrfu','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2122,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.management.rpc.port','15004',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2123,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.mapjoin.memory.oversubscribe.factor','0.3f',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2124,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.object.cache.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2125,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.task.scheduler.locality.delay','5000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2126,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.llap.zk.sm.connectionString','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2127,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.load.data.owner','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2128,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.lock.manager','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2129,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.map.aggr.hash.min.reduction','0.99',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2130,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.mapjoin.hybridgrace.hashtable','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2131,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.materializedview.rewriting.incremental','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2132,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.merge.nway.joins','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2133,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.metastore.event.listeners','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2134,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.optimize.dynamic.partition.hashjoin','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2135,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.prewarm.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2136,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.active.passive.ha.registry.namespace','hs2ActivePassiveHA',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2137,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.enable.doAs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2138,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.idle.operation.timeout','6h',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2139,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.idle.session.timeout','1d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2140,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.default.queues','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2141,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.initialize.default.sessions','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2142,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.custom.queue.allowed','ignore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2143,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.per.default.queue','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2144,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.tez.sessions.restricted.configs','hive.execution.mode,hive.execution.engine',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2145,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.thrift.http.port','10501',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2146,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.thrift.port','10500',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2147,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.cors.allowed.headers','X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2148,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.enable.cors','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2149,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.port','10502',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2150,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.webui.use.ssl','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2151,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.server2.zookeeper.namespace','hiveserver2-interactive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2152,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.strict.managed.tables','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2153,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.bucket.pruning','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2154,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.cartesian-product.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2155,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.container.size','682',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2156,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.exec.print.summary','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2157,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.tez.input.generate.consistent.splits','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2158,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.txn.strict.locking.mode','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2159,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.minmax.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2160,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.native.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2161,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2162,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.execution.reduce.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2163,'SDP-1.0','HIVE','NULL','hive-interactive-site','hive.vectorized.groupby.maxentries','1000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2164,'SDP-1.0','HIVE','NULL','hive-interactive-site','llap.shuffle.connection-keep-alive.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2165,'SDP-1.0','HIVE','NULL','hive-interactive-site','llap.shuffle.connection-keep-alive.timeout','60',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2166,'SDP-1.0','HIVE','NULL','hive-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = INFO\nname = HiveLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = {{hive_log_level}}\nproperty.hive.root.logger = DRFA\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = hive.log\n\n# list of all appenders\nappenders = console, DRFA\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} [%t]: %p %c{2}: %m%n\n\n# daily rolling file appender\nappender.DRFA.type = RollingFile\nappender.DRFA.name = DRFA\nappender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\n# Use %pid in the filePattern to append process-id@host-name to the filename if you want separate log files for different CLI session\nappender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd-HH}\nappender.DRFA.layout.type = PatternLayout\nappender.DRFA.layout.pattern = %d{ISO8601} %-5p [%t]: %c{2} (%F:%M(%L)) - %m%n\nappender.DRFA.policies.type = Policies\nappender.DRFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.DRFA.policies.time.interval = 1\nappender.DRFA.policies.time.modulate = true\nappender.DRFA.strategy.type = DefaultRolloverStrategy\nappender.DRFA.strategy.max = {{hive2_log_maxbackupindex}}\nappender.DRFA.policies.fsize.type = SizeBasedTriggeringPolicy\nappender.DRFA.policies.fsize.size = {{hive2_log_maxfilesize}}MB\n\n# list of all loggers\nloggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2167,'SDP-1.0','HIVE','NULL','hive-log4j2','hive2_log_maxbackupindex','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2168,'SDP-1.0','HIVE','NULL','hive-log4j2','hive2_log_maxfilesize','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2169,'SDP-1.0','HIVE','NULL','hive-site','ambari.hive.db.schema.name','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2170,'SDP-1.0','HIVE','NULL','hive-site','atlas.hook.hive.maxThreads','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2171,'SDP-1.0','HIVE','NULL','hive-site','atlas.hook.hive.minThreads','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2172,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.autoCreateSchema','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2173,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.cache.level2.type','none',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2174,'SDP-1.0','HIVE','NULL','hive-site','datanucleus.fixedDatastore','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2175,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2176,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join.noconditionaltask','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2177,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.join.noconditionaltask.size','20000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2178,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.sortmerge.join','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2179,'SDP-1.0','HIVE','NULL','hive-site','hive.auto.convert.sortmerge.join.to.mapjoin','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2180,'SDP-1.0','HIVE','NULL','hive-site','hive.cbo.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2181,'SDP-1.0','HIVE','NULL','hive-site','hive.cli.print.header','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2182,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.class','org.apache.hadoop.hive.thrift.ZooKeeperTokenStore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2183,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.zookeeper.connectString','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2184,'SDP-1.0','HIVE','NULL','hive-site','hive.cluster.delegation.token.store.zookeeper.znode','/hive/cluster/delegation',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2185,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.abortedtxn.threshold','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2186,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.check.interval','300',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2187,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.delta.num.threshold','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2188,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.delta.pct.threshold','0.1f',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2189,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.initiator.on','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2190,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.worker.threads','2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2191,'SDP-1.0','HIVE','NULL','hive-site','hive.compactor.worker.timeout','86400',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2192,'SDP-1.0','HIVE','NULL','hive-site','hive.compute.query.using.stats','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2193,'SDP-1.0','HIVE','NULL','hive-site','hive.convert.join.bucket.mapjoin.tez','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2194,'SDP-1.0','HIVE','NULL','hive-site','hive.create.as.insert.only','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2195,'SDP-1.0','HIVE','NULL','hive-site','hive.default.fileformat','TextFile',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2196,'SDP-1.0','HIVE','NULL','hive-site','hive.default.fileformat.managed','ORC',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2197,'SDP-1.0','HIVE','NULL','hive-site','hive.driver.parallel.compilation','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2198,'SDP-1.0','HIVE','NULL','hive-site','hive.enforce.sortmergebucketmapjoin','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2199,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.compress.intermediate','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2200,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.compress.output','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2201,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.dynamic.partition','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2202,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.dynamic.partition.mode','nonstrict',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2203,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.failure.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2204,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.created.files','100000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2205,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.dynamic.partitions','5000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2206,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.max.dynamic.partitions.pernode','2000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2207,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.orc.split.strategy','HYBRID',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2208,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.parallel','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2209,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.parallel.thread.number','8',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2210,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.post.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2211,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.pre.hooks','org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2212,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.reducers.bytes.per.reducer','67108864',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2213,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.reducers.max','1009',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2214,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.scratchdir','hdfs:///tmp/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2215,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.submit.local.task.via.child','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2216,'SDP-1.0','HIVE','NULL','hive-site','hive.exec.submitviachild','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2217,'SDP-1.0','HIVE','NULL','hive-site','hive.execution.mode','container',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2218,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.aggr','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2219,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.conversion','more',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2220,'SDP-1.0','HIVE','NULL','hive-site','hive.fetch.task.conversion.threshold','1073741824',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2221,'SDP-1.0','HIVE','NULL','hive-site','hive.heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2222,'SDP-1.0','HIVE','NULL','hive-site','hive.hook.proto.base-directory','{hive_metastore_warehouse_external_dir}/sys.db/query_data/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2223,'SDP-1.0','HIVE','NULL','hive-site','hive.limit.optimize.enable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2224,'SDP-1.0','HIVE','NULL','hive-site','hive.limit.pushdown.memory.usage','0.04',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2225,'SDP-1.0','HIVE','NULL','hive-site','hive.load.data.owner','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2226,'SDP-1.0','HIVE','NULL','hive-site','hive.lock.manager','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2227,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2228,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.force.flush.memory.threshold','0.9',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2229,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.min.reduction','0.5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2230,'SDP-1.0','HIVE','NULL','hive-site','hive.map.aggr.hash.percentmemory','0.5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2231,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.bucket.cache.size','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2232,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.hybridgrace.hashtable','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2233,'SDP-1.0','HIVE','NULL','hive-site','hive.mapjoin.optimized.hashtable','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2234,'SDP-1.0','HIVE','NULL','hive-site','hive.mapred.reduce.tasks.speculative.execution','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2235,'SDP-1.0','HIVE','NULL','hive-site','hive.materializedview.rewriting.incremental','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2236,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.mapfiles','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2237,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.mapredfiles','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2238,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.nway.joins','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2239,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.orcfile.stripe.level','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2240,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.rcfile.block.level','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2241,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.size.per.task','256000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2242,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.smallfiles.avgsize','16000000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2243,'SDP-1.0','HIVE','NULL','hive-site','hive.merge.tezfiles','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2244,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.authorization.storage.checks','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2245,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.cache.pinobjtypes','Table,Database,Type,FieldSchema,Order',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2246,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.client.connect.retry.delay','5s',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2247,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.client.socket.timeout','1800s',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2248,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.connect.retries','24',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2249,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.db.type','{{hive_metastore_db_type}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2250,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.dml.events','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2251,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.event.listeners','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2252,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.execute.setugi','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2253,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.failure.retries','24',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2254,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.kerberos.keytab.file','/etc/security/keytabs/hive.service.keytab',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2255,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.kerberos.principal','hive/_HOST@EXAMPLE.COM',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2256,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.pre.event.listeners','org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2257,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.sasl.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2258,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.server.max.threads','100000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2259,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.transactional.event.listeners','org.apache.hive.hcatalog.listener.DbNotificationListener',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2260,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.uris','thrift://%HOSTGROUP::MASTER1%:9083',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2261,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.warehouse.dir','/warehouse/tablespace/managed/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2262,'SDP-1.0','HIVE','NULL','hive-site','hive.metastore.warehouse.external.dir','/warehouse/tablespace/external/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2263,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.bucketmapjoin','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2264,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.bucketmapjoin.sortedmerge','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2265,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.constant.propagation','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2266,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.dynamic.partition.hashjoin','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2267,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.index.filter','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2268,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.metadataonly','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2269,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.null.scan','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2270,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.reducededuplication','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2271,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.reducededuplication.min.reducer','4',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2272,'SDP-1.0','HIVE','NULL','hive-site','hive.optimize.sort.dynamic.partition','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2273,'SDP-1.0','HIVE','NULL','hive-site','hive.orc.compute.splits.num.threads','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2274,'SDP-1.0','HIVE','NULL','hive-site','hive.orc.splits.include.file.footer','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2275,'SDP-1.0','HIVE','NULL','hive-site','hive.prewarm.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2276,'SDP-1.0','HIVE','NULL','hive-site','hive.prewarm.numcontainers','3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2277,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.cm.enabled','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2278,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.cmrootdir','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2279,'SDP-1.0','HIVE','NULL','hive-site','hive.repl.rootdir','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2280,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authenticator.manager','org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2281,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authorization.auth.reads','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2282,'SDP-1.0','HIVE','NULL','hive-site','hive.security.metastore.authorization.manager','org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2283,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.allow.user.substitution','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2284,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication','NONE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2285,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.ldap.baseDN','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2286,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.pam.services','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2287,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.spnego.keytab','HTTP/_HOST@EXAMPLE.COM',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2288,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.authentication.spnego.principal','/etc/security/keytabs/spnego.service.keytab',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2289,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.custom.authentication.class','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2290,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.enable.doAs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2291,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.idle.operation.timeout','6h',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2292,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.idle.session.timeout','1d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2293,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.logging.operation.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2294,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.logging.operation.log.location','/tmp/hive/operation_logs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2295,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.max.start.attempts','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2296,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.support.dynamic.service.discovery','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2297,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.table.type.mapping','CLASSIC',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2298,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.default.queues','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2299,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.initialize.default.sessions','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2300,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.tez.sessions.per.default.queue','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2301,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.http.path','cliservice',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2302,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.http.port','10001',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2303,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.max.worker.threads','500',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2304,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.port','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2305,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.thrift.sasl.qop','auth',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2306,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.transport.mode','binary',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2307,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.use.SSL','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2308,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.cors.allowed.headers','X-Requested-With,Content-Type,Accept,Origin,X-Requested-By,x-requested-by',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2309,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.enable.cors','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2310,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.port','10002',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2311,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.webui.use.ssl','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2312,'SDP-1.0','HIVE','NULL','hive-site','hive.server2.zookeeper.namespace','hiveserver2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2313,'SDP-1.0','HIVE','NULL','hive-site','hive.service.metrics.codahale.reporter.classes','org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter,org.apache.hadoop.hive.common.metrics.metrics2.Metrics2Reporter',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2314,'SDP-1.0','HIVE','NULL','hive-site','hive.smbjoin.cache.rows','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2315,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.autogather','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2316,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.dbclass','fs',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2317,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.fetch.column.stats','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2318,'SDP-1.0','HIVE','NULL','hive-site','hive.stats.fetch.partition.stats','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2319,'SDP-1.0','HIVE','NULL','hive-site','hive.strict.managed.tables','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2320,'SDP-1.0','HIVE','NULL','hive-site','hive.support.concurrency','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2321,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.auto.reducer.parallelism','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2322,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.bucket.pruning','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2323,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.cartesian-product.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2324,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.container.size','19456',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2325,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.cpu.vcores','-1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2326,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2327,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning.max.data.size','104857600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2328,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.dynamic.partition.pruning.max.event.size','1048576',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2329,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.exec.print.summary','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2330,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.input.format','org.apache.hadoop.hive.ql.io.HiveInputFormat',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2331,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.input.generate.consistent.splits','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2332,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.java.opts','-server -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseG1GC -XX:+ResizeTLAB -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2333,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.log.level','INFO',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2334,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.max.partition.factor','2.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2335,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.min.partition.factor','0.25',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2336,'SDP-1.0','HIVE','NULL','hive-site','hive.tez.smb.number.waves','0.5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2337,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.manager','org.apache.hadoop.hive.ql.lockmgr.DbTxnManager',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2338,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.max.open.batch','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2339,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.strict.locking.mode','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2340,'SDP-1.0','HIVE','NULL','hive-site','hive.txn.timeout','300',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2341,'SDP-1.0','HIVE','NULL','hive-site','hive.user.install.directory','/user/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2342,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.adaptor.usage.mode','chosen',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2343,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2344,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.minmax.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2345,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.native.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2346,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2347,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.execution.reduce.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2348,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.checkinterval','4096',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2349,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.flush.percent','0.1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2350,'SDP-1.0','HIVE','NULL','hive-site','hive.vectorized.groupby.maxentries','100000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2351,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.client.port','2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2352,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.namespace','hive_zookeeper_namespace',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2353,'SDP-1.0','HIVE','NULL','hive-site','hive.zookeeper.quorum','%HOSTGROUP::MASTER1%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2354,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionDriverName','com.mysql.jdbc.Driver',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2355,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionPassword','admin',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2356,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionURL','jdbc:mysql://%HOSTGROUP::MASTER1%:3306/hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2357,'SDP-1.0','HIVE','NULL','hive-site','javax.jdo.option.ConnectionUserName','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2358,'SDP-1.0','HIVE','NULL','hive-site','metastore.create.as.acid','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2359,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.compactor.initiator.on','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2360,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.compactor.worker.threads','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2361,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.dml.events','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2362,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.event.listeners','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2363,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2364,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.metastore.transactional.event.listeners','org.apache.hive.hcatalog.listener.DbNotificationListener',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2365,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.server2.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2366,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.service.metrics.hadoop2.component','hivemetastore',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2367,'SDP-1.0','HIVE','NULL','hivemetastore-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2368,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.async.log.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2369,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.metastore.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2370,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.server2.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2371,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.service.metrics.hadoop2.component','hiveserver2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2372,'SDP-1.0','HIVE','NULL','hiveserver2-interactive-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2373,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.metastore.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2374,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.security.authorization.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2375,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.server2.metrics.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2376,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.service.metrics.hadoop2.component','hiveserver2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2377,'SDP-1.0','HIVE','NULL','hiveserver2-site','hive.service.metrics.reporter','HADOOP2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2378,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nstatus = WARN\nname = LlapCliLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.hive.log.level = WARN\nproperty.hive.root.logger = console\nproperty.hive.log.dir = ${sys:java.io.tmpdir}/${sys:user.name}\nproperty.hive.log.file = llap-cli.log\nproperty.hive.llapstatus.consolelogger.level = INFO\n\n# list of all appenders\nappenders = console, DRFA, llapstatusconsole\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %p %c{2}: %m%n\n\n# llapstatusconsole appender\nappender.llapstatusconsole.type = Console\nappender.llapstatusconsole.name = llapstatusconsole\nappender.llapstatusconsole.target = SYSTEM_OUT\nappender.llapstatusconsole.layout.type = PatternLayout\nappender.llapstatusconsole.layout.pattern = %m%n\n\n# daily rolling file appender\nappender.DRFA.type = RollingRandomAccessFile\nappender.DRFA.name = DRFA\nappender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}\n# Use %pid in the filePattern to append process-id@host-name to the filename if you want separate log files for different CLI session\nappender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%d{yyyy-MM-dd-HH}\nappender.DRFA.layout.type = PatternLayout\nappender.DRFA.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n\nappender.DRFA.policies.type = Policies\nappender.DRFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.DRFA.policies.time.interval = 1\nappender.DRFA.policies.time.modulate = true\nappender.DRFA.strategy.type = DefaultRolloverStrategy\nappender.DRFA.strategy.max = {{llap_cli_log_maxbackupindex}}\nappender.DRFA.policies.fsize.type = SizeBasedTriggeringPolicy\nappender.DRFA.policies.fsize.size = {{llap_cli_log_maxfilesize}}MB\n\n# list of all loggers\nloggers = ZooKeeper, DataNucleus, Datastore, JPOX, HadoopConf, LlapStatusServiceDriverConsole\n\nlogger.ZooKeeper.name = org.apache.zookeeper\nlogger.ZooKeeper.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\nlogger.HadoopConf.name = org.apache.hadoop.conf.Configuration\nlogger.HadoopConf.level = ERROR\n\nlogger.LlapStatusServiceDriverConsole.name = LlapStatusServiceDriverConsole\nlogger.LlapStatusServiceDriverConsole.additivity = false\nlogger.LlapStatusServiceDriverConsole.level = ${sys:hive.llapstatus.consolelogger.level}\n\n\n# root logger\nrootLogger.level = ${sys:hive.log.level}\nrootLogger.appenderRefs = root, DRFA\nrootLogger.appenderRef.root.ref = ${sys:hive.root.logger}\nrootLogger.appenderRef.DRFA.ref = DRFA\nlogger.LlapStatusServiceDriverConsole.appenderRefs = llapstatusconsole, DRFA\nlogger.LlapStatusServiceDriverConsole.appenderRef.llapstatusconsole.ref = llapstatusconsole\nlogger.LlapStatusServiceDriverConsole.appenderRef.DRFA.ref = DRFA\n',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2379,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','llap_cli_log_maxbackupindex','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2380,'SDP-1.0','HDFS','NULL','llap-cli-log4j2','llap_cli_log_maxfilesize','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2381,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\n# This is the log4j2 properties file used by llap-daemons. There\'s several loggers defined, which\n# can be selected while configuring LLAP.\n# Based on the one selected - UI links etc need to be manipulated in the system.\n# Note: Some names and logic is common to this file and llap LogHelpers. Make sure to change that\n# as well, if changing this file.\n\nstatus = INFO\nname = LlapDaemonLog4j2\npackages = org.apache.hadoop.hive.ql.log\n\n# list of properties\nproperty.llap.daemon.log.level = {{hive_log_level}}\nproperty.llap.daemon.root.logger = console\nproperty.llap.daemon.log.dir = .\nproperty.llap.daemon.log.file = llapdaemon.log\nproperty.llap.daemon.historylog.file = llapdaemon_history.log\nproperty.llap.daemon.log.maxfilesize = {{hive_llap_log_maxfilesize}}MB\nproperty.llap.daemon.log.maxbackupindex = {{hive_llap_log_maxbackupindex}}\n\n# list of all appenders\nappenders = console, RFA, HISTORYAPPENDER, query-routing\n\n# console appender\nappender.console.type = Console\nappender.console.name = console\nappender.console.target = SYSTEM_ERR\nappender.console.layout.type = PatternLayout\nappender.console.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n\n\n# rolling file appender\nappender.RFA.type = RollingRandomAccessFile\nappender.RFA.name = RFA\nappender.RFA.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}\nappender.RFA.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.log.file}_%d{yyyy-MM-dd-HH}_%i.done\nappender.RFA.layout.type = PatternLayout\nappender.RFA.layout.pattern = %d{ISO8601} %-5p [%t (%X{fragmentId})] %c: %m%n\nappender.RFA.policies.type = Policies\nappender.RFA.policies.time.type = TimeBasedTriggeringPolicy\nappender.RFA.policies.time.interval = 1\nappender.RFA.policies.time.modulate = true\nappender.RFA.policies.size.type = SizeBasedTriggeringPolicy\nappender.RFA.policies.size.size = ${sys:llap.daemon.log.maxfilesize}\nappender.RFA.strategy.type = DefaultRolloverStrategy\nappender.RFA.strategy.max = ${sys:llap.daemon.log.maxbackupindex}\n\n# history file appender\nappender.HISTORYAPPENDER.type = RollingRandomAccessFile\nappender.HISTORYAPPENDER.name = HISTORYAPPENDER\nappender.HISTORYAPPENDER.fileName = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}\nappender.HISTORYAPPENDER.filePattern = ${sys:llap.daemon.log.dir}/${sys:llap.daemon.historylog.file}_%d{yyyy-MM-dd-HH}_%i.done\nappender.HISTORYAPPENDER.layout.type = PatternLayout\nappender.HISTORYAPPENDER.layout.pattern = %m%n\nappender.HISTORYAPPENDER.policies.type = Policies\nappender.HISTORYAPPENDER.policies.size.type = SizeBasedTriggeringPolicy\nappender.HISTORYAPPENDER.policies.size.size = ${sys:llap.daemon.log.maxfilesize}\nappender.HISTORYAPPENDER.policies.time.type = TimeBasedTriggeringPolicy\nappender.HISTORYAPPENDER.policies.time.interval = 1\nappender.HISTORYAPPENDER.policies.time.modulate = true\nappender.HISTORYAPPENDER.strategy.type = DefaultRolloverStrategy\nappender.HISTORYAPPENDER.strategy.max = ${sys:llap.daemon.log.maxbackupindex}\n\n# queryId based routing file appender\nappender.query-routing.type = Routing\nappender.query-routing.name = query-routing\nappender.query-routing.routes.type = Routes\nappender.query-routing.routes.pattern = $${ctx:queryId}\n#Purge polciy for query-based Routing Appender\nappender.query-routing.purgePolicy.type = LlapRoutingAppenderPurgePolicy\n# Note: Do not change this name without changing the corresponding entry in LlapConstants\nappender.query-routing.purgePolicy.name = llapLogPurgerQueryRouting\n# default route\nappender.query-routing.routes.route-default.type = Route\nappender.query-routing.routes.route-default.key = $${ctx:queryId}\nappender.query-routing.routes.route-default.ref = RFA\n# queryId based route\nappender.query-routing.routes.route-mdc.type = Route\nappender.query-routing.routes.route-mdc.file-mdc.type = LlapWrappedAppender\nappender.query-routing.routes.route-mdc.file-mdc.name = IrrelevantName-query-routing\nappender.query-routing.routes.route-mdc.file-mdc.app.type = RandomAccessFile\nappender.query-routing.routes.route-mdc.file-mdc.app.name = file-mdc\nappender.query-routing.routes.route-mdc.file-mdc.app.fileName = ${sys:llap.daemon.log.dir}/${ctx:queryId}-${ctx:dagId}.log\nappender.query-routing.routes.route-mdc.file-mdc.app.layout.type = PatternLayout\nappender.query-routing.routes.route-mdc.file-mdc.app.layout.pattern = %d{ISO8601} %5p [%t (%X{fragmentId})] %c{2}: %m%n\n\n# list of all loggers\nloggers = PerfLogger, EncodedReader, NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, HistoryLogger, LlapIoImpl, LlapIoOrc, LlapIoCache, LlapIoLocking, TezSM, TezSS, TezHC\n\nlogger.TezSM.name = org.apache.tez.runtime.library.common.shuffle.impl.ShuffleManager.fetch\nlogger.TezSM.level = WARN\nlogger.TezSS.name = org.apache.tez.runtime.library.common.shuffle.orderedgrouped.ShuffleScheduler.fetch\nlogger.TezSS.level = WARN\nlogger.TezHC.name = org.apache.tez.http.HttpConnection.url\nlogger.TezHC.level = WARN\n\nlogger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger\nlogger.PerfLogger.level = DEBUG\n\nlogger.EncodedReader.name = org.apache.hadoop.hive.ql.io.orc.encoded.EncodedReaderImpl\nlogger.EncodedReader.level = INFO\n\nlogger.LlapIoImpl.name = LlapIoImpl\nlogger.LlapIoImpl.level = INFO\n\nlogger.LlapIoOrc.name = LlapIoOrc\nlogger.LlapIoOrc.level = WARN\n\nlogger.LlapIoCache.name = LlapIoCache\nlogger.LlapIoCache.level = WARN\n\nlogger.LlapIoLocking.name = LlapIoLocking\nlogger.LlapIoLocking.level = WARN\n\nlogger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn\nlogger.NIOServerCnxn.level = WARN\n\nlogger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO\nlogger.ClientCnxnSocketNIO.level = WARN\n\nlogger.DataNucleus.name = DataNucleus\nlogger.DataNucleus.level = ERROR\n\nlogger.Datastore.name = Datastore\nlogger.Datastore.level = ERROR\n\nlogger.JPOX.name = JPOX\nlogger.JPOX.level = ERROR\n\nlogger.HistoryLogger.name = org.apache.hadoop.hive.llap.daemon.HistoryLogger\nlogger.HistoryLogger.level = INFO\nlogger.HistoryLogger.additivity = false\nlogger.HistoryLogger.appenderRefs = HistoryAppender\nlogger.HistoryLogger.appenderRef.HistoryAppender.ref = HISTORYAPPENDER\n\n# root logger\nrootLogger.level = ${sys:llap.daemon.log.level}\nrootLogger.appenderRefs = root\nrootLogger.appenderRef.root.ref = ${sys:llap.daemon.root.logger}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2382,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','hive_llap_log_maxbackupindex','240',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2383,'SDP-1.0','HDFS','NULL','llap-daemon-log4j','hive_llap_log_maxfilesize','256',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2384,'SDP-1.0','HIVE','NULL','parquet-logging','content','\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Properties file which configures the operation of the JDK\n# logging facility.\n\n# The system will look for this config file, first using\n# a System property specified at startup:\n#\n# >java -Djava.util.logging.config.file=myLoggingConfigFilePath\n#\n# If this property is not specified, then the config file is\n# retrieved from its default location at:\n#\n# JDK_HOME/jre/lib/logging.properties\n\n# Global logging properties.\n# ------------------------------------------\n# The set of handlers to be loaded upon startup.\n# Comma-separated list of class names.\n# (? LogManager docs say no comma here, but JDK example has comma.)\n# handlers=java.util.logging.ConsoleHandler\norg.apache.parquet.handlers= java.util.logging.FileHandler\n\n# Default global logging level.\n# Loggers and Handlers may override this level\n.level=INFO\n\n# Handlers\n# -----------------------------------------\n\n# --- ConsoleHandler ---\n# Override of global logging level\njava.util.logging.ConsoleHandler.level=INFO\njava.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter\njava.util.logging.SimpleFormatter.format=[%1$tc] %4$s: %2$s - %5$s %6$s%n\n\n# --- FileHandler ---\n# Override of global logging level\njava.util.logging.FileHandler.level=ALL\n\n# Naming style for the output file:\n# (The output file is placed in the system temporary directory.\n# %u is used to provide unique identifier for the file.\n# For more information refer\n# https://docs.oracle.com/javase/7/docs/api/java/util/logging/FileHandler.html)\njava.util.logging.FileHandler.pattern=%t/parquet-%u.log\n\n# Limiting size of output file in bytes:\njava.util.logging.FileHandler.limit=50000000\n\n# Number of output files to cycle through, by appending an\n# integer to the base file name:\njava.util.logging.FileHandler.count=1\n\n# Style of output (Simple or XML):\njava.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2385,'SDP-1.0','HIVE','NULL','ranger-hive-audit','ranger.plugin.hive.ambari.cluster.name','{{cluster_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2386,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2387,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs.batch.filespool.dir','/var/log/hive/audit/hdfs/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2388,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.hdfs.dir','hdfs://NAMENODE_HOSTNAME:8020/ranger/audit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2389,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2390,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.batch.filespool.dir','/var/log/hive/audit/solr/spool',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2391,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.urls','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2392,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.destination.solr.zookeepers','NONE',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2393,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.is.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2394,'SDP-1.0','HIVE','NULL','ranger-hive-audit','xasecure.audit.provider.summary.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2395,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','REPOSITORY_CONFIG_PASSWORD','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2396,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','REPOSITORY_CONFIG_USERNAME','hive',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2397,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','common.name.for.certificate','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2398,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2399,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2400,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_ranger_admin_password','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2401,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','external_ranger_admin_username','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2402,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','jdbc.driverClassName','org.apache.hive.jdbc.HiveDriver',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2403,'SDP-1.0','HIVE','NULL','ranger-hive-plugin-properties','policy_user','ambari-qa',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2404,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2405,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2406,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.keystore.password','myKeyFilePassword',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2407,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2408,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore.credential.file','jceks://file{{credential_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2409,'SDP-1.0','HIVE','NULL','ranger-hive-policymgr-ssl','xasecure.policymgr.clientssl.truststore.password','changeit',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2410,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.cache.dir','/etc/ranger/{{repo_name}}/policycache',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2411,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.pollIntervalMs','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2412,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.rest.ssl.config.file','{{ranger_hive_ssl_config_file}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2413,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.rest.url','{{policymgr_mgr_url}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2414,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.policy.source.impl','org.apache.ranger.admin.client.RangerAdminRESTClient',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2415,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.service.name','{{repo_name}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2416,'SDP-1.0','HIVE','NULL','ranger-hive-security','ranger.plugin.hive.urlauth.filesystem.schemes','hdfs:,file:,wasb:,adl:',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2417,'SDP-1.0','HIVE','NULL','ranger-hive-security','xasecure.hive.update.xapolicies.on.grant.revoke','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2418,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.am-rm.heartbeat.interval-ms.max','10000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2419,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.client.heartbeat.poll.interval.millis','6000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2420,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.client.heartbeat.timeout.secs','90',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2421,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.node-blacklisting.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2422,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.resource.memory.mb','1536',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2423,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.task.listener.thread-count','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2424,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.am.task.reschedule.higher.priority','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2425,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.container.max.java.heap.fraction','-1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2426,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.dag.recovery.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2427,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.grouping.node.local.only','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2428,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.log.level','TASK_ATTEMPT',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2429,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.taskattempt-filters','SERVICE_BUSY,EXTERNAL_PREEMPTION',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2430,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.history.logging.timeline.num-dags-per-group','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2431,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.lib.uris','/sdp/apps/tez/tez.tar.gz',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2432,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.enable.final-merge.in.output','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2433,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.io.sort.mb','512',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2434,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.pipelined-shuffle.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2435,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.pipelined.sorter.lazy-allocate.memory','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2436,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.report.partition.stats','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2437,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.connect.timeout','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2438,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.fetch.buffer.percent','0.6',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2439,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.fetch.verify-disk-checksum','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2440,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.keep-alive.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2441,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.memory.limit.percent','0.25',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2442,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.parallel.copies','8',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2443,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.read.timeout','30000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2444,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.shuffle.ssl.enable','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2445,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.unordered.output.buffer.size-mb','100',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2446,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.runtime.unordered.output.max-per-buffer.size-bytes','134217728',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2447,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.session.am.dag.submit.timeout.secs','1209600',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2448,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.task.heartbeat.timeout.check-ms','15000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2449,'SDP-1.0','TEZ','NULL','tez-interactive-site','tez.task.timeout-ms','90000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2567,'SDP-1.0','SQOOP','NULL','sqoop-atlas-application.properties','atlas.jaas.KafkaClient.option.renewTicket','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2568,'SDP-1.0','SQOOP','NULL','sqoop-atlas-application.properties','atlas.jaas.KafkaClient.option.useTicketCache','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2569,'SDP-1.0','SQOOP','NULL','sqoop-env','content','\n# Set Hadoop-specific environment variables here.\n\n#Set path to where bin/hadoop is available\n#Set path to where bin/hadoop is available\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\n\n#set the path to where bin/hbase is available\nexport HBASE_HOME=${HBASE_HOME:-{{hbase_home}}}\n\n#Set the path to where bin/hive is available\nexport HIVE_HOME=${HIVE_HOME:-{{hive_home}}}\n\n#Set the path for where zookeper config dir is\nexport ZOOCFGDIR=${ZOOCFGDIR:-/etc/zookeeper/conf}\n\n# add libthrift in hive to sqoop class path first so hive imports work\nexport SQOOP_USER_CLASSPATH=\"`ls ${HIVE_HOME}/lib/libthrift-*.jar 2> /dev/null`:${SQOOP_USER_CLASSPATH}\"',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2570,'SDP-1.0','SQOOP','NULL','sqoop-env','jdbc_drivers',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2571,'SDP-1.0','SQOOP','NULL','sqoop-env','sqoop.atlas.hook','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2572,'SDP-1.0','SQOOP','NULL','sqoop-env','sqoop_user','sqoop',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2573,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','autopurge.purgeInterval','24',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2574,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','autopurge.snapRetainCount','30',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2575,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','clientPort','2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2576,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','dataDir','/hadoop/zookeeper',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2577,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','initLimit','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2578,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','quorum.auth.enableSasl','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2579,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','quorum.cnxn.threads.size','20',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2580,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','syncLimit','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2581,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','tickTime','3000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2582,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','content','\nexport JAVA_HOME={{java64_home}}\nexport ZOOKEEPER_HOME={{zk_home}}\nexport ZOO_LOG_DIR={{zk_log_dir}}\nexport ZOOPIDFILE={{zk_pid_file}}\nexport SERVER_JVMFLAGS={{zk_server_heapsize}}\nexport JAVA=$JAVA_HOME/bin/java\nexport CLASSPATH=$CLASSPATH:/usr/share/zookeeper/*\n\n{% if security_enabled %}\nexport SERVER_JVMFLAGS=\"$SERVER_JVMFLAGS -Djava.security.auth.login.config={{zk_server_jaas_file}}\"\nexport CLIENT_JVMFLAGS=\"$CLIENT_JVMFLAGS -Djava.security.auth.login.config={{zk_client_jaas_file}} -Dzookeeper.sasl.client.username={{zk_principal_user}}\"\n{% endif %}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2583,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_log_dir','/var/log/zookeeper',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2584,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_pid_dir','/var/run/zookeeper',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2585,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_server_heapsize','1024',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2586,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zookeeper_keytab_path','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2587,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zookeeper_principal_name','null',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2588,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-env','zk_user','zookeeper',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2589,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','content','   \n#\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \\\"License\\\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n#\n#\n\n#\n# ZooKeeper Logging Configuration\n#\n\n# DEFAULT: console appender only\nlog4j.rootLogger=INFO, CONSOLE, ROLLINGFILE\n\n# Example with rolling log file\n#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE\n\n# Example with rolling log file and tracing\n#log4j.rootLogger=TRACE, CONSOLE, ROLLINGFILE, TRACEFILE\n\n#\n# Log INFO level and above messages to the console\n#\nlog4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\nlog4j.appender.CONSOLE.Threshold=INFO\nlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\n\n#\n# Add ROLLINGFILE to rootLogger to get log file output\n#    Log DEBUG level and above messages to a log file\nlog4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.ROLLINGFILE.Threshold=DEBUG\nlog4j.appender.ROLLINGFILE.File={{zk_log_dir}}/zookeeper.log\nlog4j.appender.ROLLINGFILE.DatePattern=\'.\'yyyy-MM-dd-HH\n# Max log file size of 10MB\nlog4j.appender.ROLLINGFILE.MaxFileSize={{zookeeper_log_max_backup_size}}MB\n# uncomment the next line to limit number of backup files\n#log4j.appender.ROLLINGFILE.MaxBackupIndex={{zookeeper_log_number_of_backup_files}}\n\nlog4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayout\nlog4j.appender.ROLLINGFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\n\n\n#\n# Add TRACEFILE to rootLogger to get log file output\n#    Log DEBUG level and above messages to a log file\nlog4j.appender.TRACEFILE=org.apache.log4j.FileAppender\nlog4j.appender.TRACEFILE.Threshold=TRACE\nlog4j.appender.TRACEFILE.File=zookeeper_trace.log\n\nlog4j.appender.TRACEFILE.layout=org.apache.log4j.PatternLayout\n### Notice we are including log4j\'s NDC here (%x)\nlog4j.appender.TRACEFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L][%x] - %m%n\n',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2590,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','zookeeper_log_max_backup_size','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2591,'SDP-1.0','ZOOKEEPER','NULL','zookeeper-log4j','zookeeper_log_number_of_backup_files','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2592,'SDP-1.0','SPARK3','NULL','livy3-client-conf','livy.rsc.launcher.address',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2593,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.environment','production',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2594,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.impersonation.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2595,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.repl.enableHiveContext','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2596,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.access-control.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2597,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.csrf_protection.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2598,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.port','8999',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2599,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.mode','recovery',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2600,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.state-store','filesystem',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2601,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.recovery.state-store.url','/livy2-recovery',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2602,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.server.session.timeout','3600000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2603,'SDP-1.0','SPARK3','NULL','livy3-conf','livy.spark.master','yarn-cluster',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2604,'SDP-1.0','SPARK3','NULL','livy3-env','content','\n            #!/usr/bin/env bash\n\n            # - SPARK_HOME      Spark which you would like to use in livy\n            # - SPARK_CONF_DIR  Directory containing the Spark configuration to use.\n            # - HADOOP_CONF_DIR Directory containing the Hadoop / YARN configuration to use.\n            # - LIVY_LOG_DIR    Where log files are stored.  (Default: ${LIVY_HOME}/logs)\n            # - LIVY_PID_DIR    Where the pid file is stored. (Default: /tmp)\n            # - LIVY_SERVER_JAVA_OPTS  Java Opts for running livy server (You can set jvm related setting here, like jvm memory/gc algorithm and etc.)\n            export SPARK_HOME=/usr/sdp/current/spark3-client\n            export SPARK_CONF_DIR=/etc/spark3/conf\n            export JAVA_HOME={{java_home}}\n            export HADOOP_CONF_DIR=/etc/hadoop/conf\n            export LIVY_LOG_DIR={{livy2_log_dir}}\n            export LIVY_PID_DIR={{livy2_pid_dir}}\n            export LIVY_SERVER_JAVA_OPTS=\"-Xmx2g\"',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2605,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_log_dir','/var/log/livy2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2606,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_pid_dir','/var/run/livy2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2607,'SDP-1.0','SPARK3','NULL','livy3-env','spark_home','/usr/sdp/current/spark3-client',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2608,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_group','livy',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2609,'SDP-1.0','SPARK3','NULL','livy3-env','livy2_user','livy',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2610,'SDP-1.0','SPARK3','NULL','livy3-log4j-properties','content','\n            # Set everything to be logged to the console\n            log4j.rootCategory=INFO, console\n            log4j.appender.console=org.apache.log4j.ConsoleAppender\n            log4j.appender.console.target=System.err\n            log4j.appender.console.layout=org.apache.log4j.PatternLayout\n            log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\n\n            log4j.logger.org.eclipse.jetty=WARN',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2611,'SDP-1.0','SPARK3','NULL','livy3-spark-blacklist','content','\n            #\n            # Configuration override / blacklist. Defines a list of properties that users are not allowed\n            # to override when starting Spark sessions.\n            #\n            # This file takes a list of property names (one per line). Empty lines and lines starting with \"#\"\n            # are ignored.\n            #\n\n            # Disallow overriding the master and the deploy mode.\n            spark.master\n            spark.submit.deployMode\n\n            # Disallow overriding the location of Spark cached jars.\n            spark.yarn.jar\n            spark.yarn.jars\n            spark.yarn.archive\n\n            # Don\'t allow users to override the RSC timeout.\n            livy.rsc.server.idle_timeout',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2612,'SDP-1.0','SPARK3','NULL','spark3-atlas-application-properties-override','atlas.spark.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2613,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.driver.extraClassPath',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2614,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.driver.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2615,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.eventLog.dir','hdfs:///spark3-history/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2616,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.eventLog.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2617,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.executor.extraJavaOptions','-XX:+UseNUMA',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2618,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.executor.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2619,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.extraListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2620,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2621,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.interval','7d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2622,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.cleaner.maxAge','90d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2623,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.fs.logDirectory','hdfs:///spark3-history/',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2624,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.kerberos.keytab','none',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2625,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.kerberos.principal','none',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2626,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.provider','org.apache.spark.deploy.history.FsHistoryProvider',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2627,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.store.path','/var/lib/spark3/shs_db',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2628,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.history.ui.port','18081',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2629,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.io.compression.lz4.blockSize','128kb',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2630,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.master','yarn',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2631,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.file.buffer','1m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2632,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.io.backLog','8192',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2633,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.io.serverThreads','128',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2634,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.shuffle.unsafe.file.output.buffer','5m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2635,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.autoBroadcastJoinThreshold','26214400',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2636,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.convertMetastoreOrc','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2637,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.metastore.jars','/usr/sdp/current/spark/standalone-metastore/*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2638,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.hive.metastore.version','3.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2639,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.orc.filterPushdown','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2640,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.orc.impl','native',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2641,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.queryExecutionListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2642,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.statistics.fallBackToHdfs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2643,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.streaming.streamingQueryListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2644,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.sql.warehouse.dir','/apps/spark/warehouse',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2645,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.unsafe.sorter.spill.reader.buffer.size','1m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2646,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.dist.files',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2647,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.historyServer.address','{{spark_history_server_host}}:{{spark_history_ui_port}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2648,'SDP-1.0','SPARK3','NULL','spark3-defaults','spark.yarn.queue','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2649,'SDP-1.0','SPARK3','NULL','spark3-env','content','\n#!/usr/bin/env bash\n\n# This file is sourced when running various Spark programs.\n# Copy it as spark-env.sh and edit that to configure Spark for your site.\n\n# Options read in YARN client mode\n#SPARK_EXECUTOR_INSTANCES=\"2\" #Number of workers to start (Default: 2)\n#SPARK_EXECUTOR_CORES=\"1\" #Number of cores for the workers (Default: 1).\n#SPARK_EXECUTOR_MEMORY=\"1G\" #Memory per Worker (e.g. 1000M, 2G) (Default: 1G)\n#SPARK_DRIVER_MEMORY=\"512M\" #Memory for Master (e.g. 1000M, 2G) (Default: 512 Mb)\n#SPARK_YARN_APP_NAME=\"spark\" #The name of your application (Default: Spark)\n#SPARK_YARN_QUEUE=\"default\" #The hadoop queue to use for allocation requests (Default: default)\n#SPARK_YARN_DIST_FILES=\"\" #Comma separated list of files to be distributed with the job.\n#SPARK_YARN_DIST_ARCHIVES=\"\" #Comma separated list of archives to be distributed with the job.\n\n{% if security_enabled %}\nexport SPARK_HISTORY_OPTS=\'-Dspark.ui.filters=org.apache.hadoop.security.authentication.server.AuthenticationFilter -Dspark.org.apache.hadoop.security.authentication.server.AuthenticationFilter.params=\"type=kerberos,kerberos.principal={{spnego_principal}},kerberos.keytab={{spnego_keytab}}\"\'\n{% endif %}\n\n\n# Generic options for the daemons used in the standalone deploy mode\n\n# Alternate conf dir. (Default: ${SPARK_HOME}/conf)\nexport SPARK_CONF_DIR=${SPARK_CONF_DIR:-{{spark_home}}/conf}\n\n# Where log files are stored.(Default:${SPARK_HOME}/logs)\n#export SPARK_LOG_DIR=${SPARK_HOME:-{{spark_home}}}/logs\nexport SPARK_LOG_DIR={{spark_log_dir}}\n\n# Where the pid file is stored. (Default: /tmp)\nexport SPARK_PID_DIR={{spark_pid_dir}}\n\n#Memory for Master, Worker and history server (default: 1024MB)\nexport SPARK_DAEMON_MEMORY={{spark_daemon_memory}}m\n\n# A string representing this instance of spark.(Default: $USER)\nSPARK_IDENT_STRING=$USER\n\n# The scheduling priority for daemons. (Default: 0)\nSPARK_NICENESS=0\n\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\nexport HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-{{hadoop_conf_dir}}}\n\n# The java implementation to use.\nexport JAVA_HOME={{java_home}}',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2650,'SDP-1.0','SPARK3','NULL','spark3-env','hive_kerberos_keytab','{{hive_kerberos_keytab}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2651,'SDP-1.0','SPARK3','NULL','spark3-env','hive_kerberos_principal','{{hive_kerberos_principal}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2652,'SDP-1.0','SPARK3','NULL','spark3-env','spark_daemon_memory','2048',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2653,'SDP-1.0','SPARK3','NULL','spark3-env','spark_log_dir','/var/log/spark3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2654,'SDP-1.0','SPARK3','NULL','spark3-env','spark_pid_dir','/var/run/spark3',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2655,'SDP-1.0','SPARK3','NULL','spark3-env','spark_thrift_cmd_opts','',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2656,'SDP-1.0','SPARK3','NULL','spark3-env','spark_group','spark',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2657,'SDP-1.0','SPARK3','NULL','spark3-env','spark_user','spark',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2658,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.exec.scratchdir','/tmp/spark',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2659,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.metastore.client.connect.retry.delay','5',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2660,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.metastore.client.socket.timeout','1800',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2661,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.enable.doAs','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2662,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.thrift.http.port','10002',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2663,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.thrift.port','10016',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2664,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','hive.server2.transport.mode','binary',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2665,'SDP-1.0','SPARK3','NULL','spark3-hive-site-override','metastore.catalog.default','spark',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2666,'SDP-1.0','SPARK3','NULL','spark3-log4j-properties','content','log4j.rootLogger=INFO, ROOT\nlog4j.appender.ROOT=org.apache.log4j.DailyRollingFileAppender\nlog4j.appender.ROOT.DatePattern=\'.\'yyyy-MM-dd-HH\nlog4j.appender.ROOT.layout=org.apache.log4j.PatternLayout\nlog4j.appender.ROOT.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\nlog4j.appender.ROOT.file=/var/log/spark3/spark.log\nlog4j.logger.org.apache.spark.repl.Main=WARN\nlog4j.logger.org.sparkproject.jetty=WARN\nlog4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle=ERROR\nlog4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO\nlog4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO\nlog4j.logger.org.apache.parquet=ERROR\nlog4j.logger.parquet=ERROR\nlog4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL\nlog4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR\nlog4j.appender.console.filter.1=org.apache.log4j.varia.StringMatchFilter\nlog4j.appender.console.filter.1.AcceptOnMatch=false',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2667,'SDP-1.0','SPARK3','NULL','spark3-metrics-properties','content','\n# syntax: [instance].sink|source.[name].[options]=[value]\n\n# This file configures Spark\'s internal metrics system. The metrics system is\n# divided into instances which correspond to internal components.\n# Each instance can be configured to report its metrics to one or more sinks.\n# Accepted values for [instance] are \"master\", \"worker\", \"executor\", \"driver\",\n# and \"applications\". A wild card \"*\" can be used as an instance name, in\n# which case all instances will inherit the supplied property.\n#\n# Within an instance, a \"source\" specifies a particular set of grouped metrics.\n# there are two kinds of sources:\n# 1. Spark internal sources, like MasterSource, WorkerSource, etc, which will\n# collect a Spark component\'s internal state. Each instance is paired with a\n# Spark source that is added automatically.\n# 2. Common sources, like JvmSource, which will collect low level state.\n# These can be added through configuration options and are then loaded\n# using reflection.\n#\n# A \"sink\" specifies where metrics are delivered to. Each instance can be\n# assigned one or more sinks.\n#\n# The sink|source field specifies whether the property relates to a sink or\n# source.\n#\n# The [name] field specifies the name of source or sink.\n#\n# The [options] field is the specific property of this source or sink. The\n# source or sink is responsible for parsing this property.\n#\n# Notes:\n# 1. To add a new sink, set the \"class\" option to a fully qualified class\n# name (see examples below).\n# 2. Some sinks involve a polling period. The minimum allowed polling period\n# is 1 second.\n# 3. Wild card properties can be overridden by more specific properties.\n# For example, master.sink.console.period takes precedence over\n# *.sink.console.period.\n# 4. A metrics specific configuration\n# \"spark.metrics.conf=${SPARK_HOME}/conf/metrics.properties\" should be\n# added to Java properties using -Dspark.metrics.conf=xxx if you want to\n# customize metrics system. You can also put the file in ${SPARK_HOME}/conf\n# and it will be loaded automatically.\n# 5. MetricsServlet is added by default as a sink in master, worker and client\n# driver, you can send http request \"/metrics/json\" to get a snapshot of all the\n# registered metrics in json format. For master, requests \"/metrics/master/json\" and\n# \"/metrics/applications/json\" can be sent seperately to get metrics snapshot of\n# instance master and applications. MetricsServlet may not be configured by self.\n#\n\n## List of available sinks and their properties.\n\n# org.apache.spark.metrics.sink.ConsoleSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n\n# org.apache.spark.metrics.sink.CSVSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n# directory /tmp Where to store CSV files\n\n# org.apache.spark.metrics.sink.GangliaSink\n# Name: Default: Description:\n# host NONE Hostname or multicast group of Ganglia server\n# port NONE Port of Ganglia server(s)\n# period 10 Poll period\n# unit seconds Units of poll period\n# ttl 1 TTL of messages sent by Ganglia\n# mode multicast Ganglia network mode (\'unicast\' or \'multicast\')\n\n# org.apache.spark.metrics.sink.JmxSink\n\n# org.apache.spark.metrics.sink.MetricsServlet\n# Name: Default: Description:\n# path VARIES* Path prefix from the web server root\n# sample false Whether to show entire set of samples for histograms (\'false\' or \'true\')\n#\n# * Default path is /metrics/json for all instances except the master. The master has two paths:\n# /metrics/aplications/json # App information\n# /metrics/master/json # Master information\n\n# org.apache.spark.metrics.sink.GraphiteSink\n# Name: Default: Description:\n# host NONE Hostname of Graphite server\n# port NONE Port of Graphite server\n# period 10 Poll period\n# unit seconds Units of poll period\n# prefix EMPTY STRING Prefix to prepend to metric name\n\n## Examples\n# Enable JmxSink for all instances by class name\n#*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink\n\n# Enable ConsoleSink for all instances by class name\n#*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink\n\n# Polling period for ConsoleSink\n#*.sink.console.period=10\n\n#*.sink.console.unit=seconds\n\n# Master instance overlap polling period\n#master.sink.console.period=15\n\n#master.sink.console.unit=seconds\n\n# Enable CsvSink for all instances\n#*.sink.csv.class=org.apache.spark.metrics.sink.CsvSink\n\n# Polling period for CsvSink\n#*.sink.csv.period=1\n\n#*.sink.csv.unit=minutes\n\n# Polling directory for CsvSink\n#*.sink.csv.directory=/tmp/\n\n# Worker instance overlap polling period\n#worker.sink.csv.period=10\n\n#worker.sink.csv.unit=minutes\n\n# Enable jvm source for instance master, worker, driver and executor\n#master.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource',1,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2668,'SDP-1.0','SPARK3','NULL','spark3-thrift-fairscheduler','fairscheduler_content','<?xml version=\"1.0\"?>\n            <allocations>\n            <pool name=\"default\">\n            <schedulingMode>FAIR</schedulingMode>\n            <weight>1</weight>\n            <minShare>2</minShare>\n            </pool>\n            </allocations>',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2669,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.driver.extraClassPath',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2670,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.driver.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2671,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2672,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.initialExecutors','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2673,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.maxExecutors','10',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2674,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.dynamicAllocation.minExecutors','0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2675,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.eventLog.dir','{{spark_history_dir}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2676,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.eventLog.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2677,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.executor.extraJavaOptions','-XX:+UseNUMA',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2678,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.executor.extraLibraryPath','{{spark_hadoop_lib_native}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2679,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.extraListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2680,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.hadoop.cacheConf','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2681,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2682,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.interval','7d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2683,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.cleaner.maxAge','90d',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2684,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.fs.logDirectory','{{spark_history_dir}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2685,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.history.provider','org.apache.spark.deploy.history.FsHistoryProvider',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2686,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.io.compression.lz4.blockSize','128kb',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2687,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.master','{{spark_thrift_master}}',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2688,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.scheduler.allocation.file','{{spark_conf}}/spark-thrift-fairscheduler.xml',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2689,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.scheduler.mode','FAIR',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2690,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.file.buffer','1m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2691,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.io.backLog','8192',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2692,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.io.serverThreads','128',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2693,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.service.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2694,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.shuffle.unsafe.file.output.buffer','5m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2695,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.autoBroadcastJoinThreshold','26214400',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2696,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.convertMetastoreOrc','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2697,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.metastore.jars','/usr/sdp/current/spark/standalone-metastore/*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2698,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.hive.metastore.version','3.0',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2699,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.orc.filterPushdown','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2700,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.orc.impl','native',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2701,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.queryExecutionListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2702,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.statistics.fallBackToHdfs','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2703,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.streaming.streamingQueryListeners',' ',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2704,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.sql.warehouse.dir','/apps/spark/warehouse',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2705,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.unsafe.sorter.spill.reader.buffer.size','1m',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2706,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.executor.failuresValidityInterval','2h',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2707,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.maxAppAttempts','1',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(2708,'SDP-1.0','SPARK3','NULL','spark3-thrift-sparkconf','spark.yarn.queue','default',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3406,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','admin.serverPort','38080',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3407,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','admin.serverPort','38080',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3408,'SDP-1.0','HDFS','NULL','hadoop-env','dfs_ha_initial_namenode_active','%HOSTGROUP::MASTER1%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3409,'SDP-1.0','HDFS','NULL','hadoop-env','dfs_ha_initial_namenode_standby','%HOSTGROUP::MASTER2%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3410,'SDP-1.0','HDFS','NULL','core-site','ha.zookeeper.quorum','%HOSTGROUP::MASTER1%:2181,%HOSTGROUP::MASTER2%:2181,%HOSTGROUP::AMBARI%:2181',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3411,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.client.failover.proxy.provider.sunboxcluster','org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3412,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.ha.automatic-failover.enabled','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3413,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.ha.fencing.methods','shell(/bin/true)',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3414,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.ha.namenodes.sunboxcluster','nn1,nn2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3415,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.http-address.sunboxcluster.nn1','%HOSTGROUP::MASTER1%:50070',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3416,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.http-address.sunboxcluster.nn2','%HOSTGROUP::MASTER2%:50070',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3417,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.https-address.sunboxcluster.nn1','%HOSTGROUP::MASTER1%:50470',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3418,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.https-address.sunboxcluster.nn2','%HOSTGROUP::MASTER2%:50470',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3419,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.rpc-address.sunboxcluster.nn1','%HOSTGROUP::MASTER1%:8020',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3420,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.rpc-address.sunboxcluster.nn2','%HOSTGROUP::MASTER2%:8020',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3421,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.namenode.shared.edits.dir','qjournal://%HOSTGROUP::MASTER1%:8485;%HOSTGROUP::MASTER2%:8485;%HOSTGROUP::AMBARI%:8485/sunboxcluster',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3422,'SDP-1.0','HDFS','NULL','hdfs-site','dfs.nameservices','sunboxcluster',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3423,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','4lw.commands.whitelist','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3424,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','4lw.commands.whitelist','*',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3425,'SDP-1.0','YARN','NULL','yarn-site','hadoop.registry.rm.enabled','false',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3427,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.cluster-id','yarn-cluster',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3428,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.ha.automatic-failover.zk-base-path','/yarn-leader-election',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3429,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.ha.rm-ids','rm1,rm2',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3430,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.hostname.rm1','%HOSTGROUP::MASTER1%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3431,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.hostname.rm2','%HOSTGROUP::MASTER2%',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3432,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.address.rm2','%HOSTGROUP::MASTER2%:8088',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3433,'SDP-1.0','YARN','NULL','yarn-site','yarn.resourcemanager.webapp.address.rm1','%HOSTGROUP::MASTER1%:8088',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3434,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.yarn.hosts','*',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3435,'SDP-1.0','HDFS','NULL','core-site','hadoop.proxyuser.yarn.hosts','*',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3436,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','maxClientCnxns','1000',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3437,'SDP-1.0','ZOOKEEPER','NULL','zoo.cfg','maxClientCnxns','1000',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3448,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.reader.webapp.address','%HOSTGROUP::MASTER1%:8198',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3449,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.reader.webapp.https.address','%HOSTGROUP::MASTER1%:8199',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3450,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.reader.webapp.address','%HOSTGROUP::MASTER1%:8198',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3451,'SDP-1.0','YARN','NULL','yarn-site','yarn.timeline-service.reader.webapp.https.address','%HOSTGROUP::MASTER1%:8199',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3456,'SDP-1.0','HIVE','NULL','hive-site','hive.use.scratchdir.for.staging','true',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3457,'SDP-1.0','HIVE','NULL','hive-site','hive.use.scratchdir.for.staging','true',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3458,'SDP-1.0','HIVE','NULL','hive-site','hive.blobstore.supported.schemes','s3,s3a,s3n,abfs,wasbs,wasb',0,0,NULL,'HA','VALID',NULL,NULL,NULL,NULL),(3459,'SDP-1.0','HIVE','NULL','hive-site','hive.blobstore.supported.schemes','s3,s3a,s3n,abfs,wasbs,wasb',0,0,NULL,'NON_HA','VALID',NULL,NULL,NULL,NULL),(3460,'SDP-1.0','HDFS','NULL','core-site','fs.azure.enable.check.access','false',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3461,'SDP-1.0','HDFS','NULL','core-site','fs.azure.user.agent.prefix','User-Agent: APN/1.0 Hortonworks/1.0 SDP/{{version}}',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3467,'SDP-1.0','HDFS','NULL','core-site','fs.azure.enable.check.access','false',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3468,'SDP-1.0','HDFS','NULL','core-site','fs.azure.user.agent.prefix','User-Agent: APN/1.0 Hortonworks/1.0 SDP/{{version}}',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3476,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.auth.type','OAuth',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3477,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth.provider.type','org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3478,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.msi.tenant','',0,1,'MI_ABFS','HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3479,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.msi.endpoint','http://169.254.169.254/metadata/identity/oauth2/token',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3480,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.client.id','',0,1,'MI_ABFS','HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3481,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.auth.type','OAuth',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3482,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth.provider.type','org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3483,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.msi.tenant','',0,1,'MI_ABFS','NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3484,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.msi.endpoint','http://169.254.169.254/metadata/identity/oauth2/token',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3485,'SDP-1.0','HDFS','NULL','core-site','fs.azure.account.oauth2.client.id','',0,1,'MI_ABFS','NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3486,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','sdp.version','1.0',0,0,NULL,'HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00'),(3487,'SDP-1.0','MAPREDUCE2','NULL','mapred-site','sdp.version','1.0',0,0,NULL,'NON_HA','VALID','system','2023-01-10 17:54:00','system','2023-01-10 17:54:00');


insert  into `ambari_config_item_attr`(`id`,`stack_code`,`service_code`,`component_code`,`config_type_code`,`tag_name`,`key`,`value`,`state`,`created_by`,`created_time`,`updated_by`,`updated_time`) values (4,'SDP-1.0','HDFS','NAMENODE','core-site','final','fs.defaultFS','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(5,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.client.datanode-restart.timeout','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(6,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.webhdfs.enabled','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(7,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.namenode.http-address','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(8,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.namenode.name.dir','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(9,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.datanode.failed.volumes.tolerated','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(10,'SDP-1.0','HDFS','NAMENODE','hdfs-site','final','dfs.datanode.data.dir','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(11,'SDP-1.0','TEZ','TEZ_CLIENT','tez-interactive-site','final','tez.runtime.shuffle.ssl.enable','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(12,'SDP-1.0','YARN','RESOURCEMANAGER','yarn-site','hidden','hadoop.registry.dns.bind-port','true','VALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46'),(13,'SDP-1.0','HIVE','HIVE_METASTORE','hive-site','hidden','javax.jdo.option.ConnectionPassword','HIVE_CLIENT,CONFIG_DOWNLOAD','INVALID','system','2022-12-10 03:07:46','system','2022-12-10 03:07:46');


insert  into `base_cluster_operation_template`(`template_id`,`release_version`,`operation_name`,`operation_description`,`is_delete`,`createdby`,`created_time`) values ('034f75e9-7227-11ed-85b7-6045bdc7fdca','SDP-1.0','create','',0,'',NULL),('134f75e9-7227-11ed-85b7-6045bdc7fdcb','SDP-1.0','delete','',0,'',NULL),('90f52443-838b-11ed-8607-6045bdc792d8','SDP-1.0','runuserscript','',0,'',NULL);


insert  into `base_cluster_operation_template_activity`(`activity_id`,`template_id`,`activity_type`,`activity_cnname`,`activity_name`,`sort_no`,`timeout`,`createdby`,`created_time`) values ('02546cf9-783d-11ed-85b7-6045bdc7fdca','134f75e9-7227-11ed-85b7-6045bdc7fdcb','azureVMService','','queryDeleteVms',1,0,'system',NULL),('05be6f4e-797a-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','','sleep',10,0,'system',NULL),('09d70ff1-78a4-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','queryPlayJobStatus',7,0,'system',NULL),('1b680f8e-7862-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','Ambari-Server','queryPlayJobStatus',3,0,'system',NULL),('330df4ed-7ac1-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','','sleep',1,0,'system',NULL),('34cfec84-74ae-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','azureVMService','','queryVmsCreateJob',0,0,'system',NULL),('5b2528cf-789c-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','Ambari-Agent','installAgent',4,0,'system',NULL),('5c4dbe92-78d0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','SDP','createSDPCluster',8,0,'system',NULL),('5c4dc157-78d0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','SDP','querySDPClusterInstallProcess',9,3600,'system',NULL),('5c4dc1dc-78d0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','','startSDPClusterApps',13,0,'system',NULL),('876f4dbf-79f0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','beforeClusterStartScript',11,0,'system',NULL),('876f527d-79f0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','queryPlayJobStatus',12,0,'system',NULL),('876f5319-79f0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','clusterservice','','querySDPClusterInstallProcess',14,3600,'system',NULL),('876f5379-79f0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','afterClusterCompletedScript',15,0,'system',NULL),('876f53c9-79f0-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','queryPlayJobStatus',16,0,'system',NULL),('935f8f37-789c-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','Ambari-Agent','queryPlayJobStatus',5,0,'system',NULL),('d69c473b-74ad-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','azureVMService','','createVms',-1,0,'system',NULL),('dc050236-838b-11ed-8607-6045bdc792d8','90f52443-838b-11ed-8607-6045bdc792d8','InstallSDP','','queryPlayJobStatus',1,0,'system',NULL),('dc0506c0-838b-11ed-8607-6045bdc792d8','90f52443-838b-11ed-8607-6045bdc792d8','InstallSDP','','runUserCusterScript',0,0,'system',NULL),('e91af09a-78a3-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','','initScript',6,0,'system',NULL),('f02cb4bc-7861-11ed-85b7-6045bdc7fdca','034f75e9-7227-11ed-85b7-6045bdc7fdca','InstallSDP','Ambari-Server','installAmbari',2,0,'system',NULL),('f8f625f4-783c-11ed-85b7-6045bdc7fdca','134f75e9-7227-11ed-85b7-6045bdc7fdcb','azureVMService','','deleteVms',0,0,'system',NULL);


insert  into `base_cluster_script`(`conf_script_id`,`release_version`,`script_name`,`run_timing`,`playbook_uri`,`script_file_uri`,`extra_vars`,`sort_no`,`createdby`,`created_time`) values ('d9a6564b-7853-11ed-85b7-6045bdc7fdca','SDP-1.0','AmbariServer','install_ambari_server','https://{wgetpath}/sunbox3/shell/ambari.yaml','https://{wgetpath}/sunbox3/shell/ambari-agent.sh,https://{wgetpath}/sunbox3/shell/ambari-server.sh,https://{wgetpath}/sunbox3/shell/initialize.sh,https://{wgetpath}/sunbox3/shell/mountnew.sh','-e \"type=server host={ambarihost} dburl={ambaridb} dbport={ambaridbport} dbname={ambaridbname} dbuser={dbuser} dbpass={dbpassword} domain={domain} wgetpath={wgetpath} clustername={clustername} logblob={logblob} username={username}\"\n',0,'','2022-12-10 06:28:24'),('f9a6564b-7853-11ed-85b7-6045bdc7fdca','SDP-1.0','AmbariAgent','install_ambari_agent','https://{wgetpath}/sunbox3/shell/ambari.yaml','https://{wgetpath}/sunbox3/shell/ambari-agent.sh,https://{wgetpath}/sunbox3/shell/ambari-server.sh,https://{wgetpath}/sunbox3/shell/initialize.sh,https://{wgetpath}/sunbox3/shell/mountnew.sh','-e \"type=agent host={ambarihost} dburl={ambaridb} dbport={ambaridbport} dbname={ambaridbname} dbuser={dbuser} dbpass={dbpassword} domain={domain} wgetpath={wgetpath} clustername={clustername} logblob={logblob} username={username}\"\n',0,'','2022-12-10 06:28:24');


insert  into `base_dictionary`(`dict_id`,`pdict_id`,`dict_name`,`dict_value`,`alias_name`,`is_delete`,`sortno`,`createdby`,`created_time`,`modifiedby`,`modified_time`) values (10,NULL,'',NULL,'NetWork','0',NULL,NULL,NULL,NULL,NULL),(11,'10','Default-VPC','Default-VPC',NULL,'0','1',NULL,NULL,NULL,NULL);


insert  into `base_release_apps`(`release_version`,`app_name`,`app_verison`,`required`,`sort_no`,`created_by`,`created_time`) values ('SDP-1.0','HBase','2.4.4',0,8,'sysadmin','2022-12-01 16:43:13'),('SDP-1.0','HDFS','3.3.2',1,2,'sysadmin','2022-12-01 16:43:13'),('SDP-1.0','Hive','3.1.2',0,3,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','MapReduce2','3.3.2',1,2,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','Spark3','3.1.2',0,5,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','Sqoop','1.4.7',0,7,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','Tez','0.10.2',0,4,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','Yarn','3.3.2',1,2,'sysadmin','2022-12-01 16:43:42'),('SDP-1.0','ZooKeeper','3.5.7',1,1,'sysadmin','2022-12-01 16:43:42');


insert  into `base_release_apps_config`(`release_version`,`app_name`,`app_config_classification`,`app_config_file`,`sort_no`,`is_delete`,`createdby`,`created_time`) values ('SDP-1.0','Yarn','capacity-scheduler','capacity-scheduler.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','HDFS','core-site','core-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','HDFS','hadoop-env','hadoop-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','HBase','hbase-env','hbase-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','HBase','hbase-site','hbase-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','HDFS','hdfs-site','hdfs-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Hive','hive-env','hive-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Hive','hive-site','hive-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','MapReduce2','mapred-env','mapred-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','MapReduce2','mapred-site','mapred-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Spark3','spark-defaults','spark-defaults.conf',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Spark3','spark-env','spark-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Tez','tez-env','tez-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Tez','tez-site','tez-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Yarn','yarn-env','yarn-env.sh',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','Yarn','yarn-site','yarn-site.xml',NULL,0,'sysadmin','2022-12-03 17:02:21'),('SDP-1.0','ZooKeeper','zoo.cfg','zoo.cfg',NULL,0,'sysadmin','2022-12-03 17:02:21');


insert  into `base_release_version`(`release_version`,`release_description`,`create_by`,`create_time`) values ('SDP-1.0','SDP-1.0','sysadmin','2022-12-03 16:55:34');


insert  into `base_release_vm_img`(`release_version`,`vm_role`,`os_imageid`,`os_image_type`,`os_version`,`createdby`,`created_time`) values ('SDP-1.0','ambari','/subscriptions/9b88bd64-d315-48de-96bc-83051ed25fdc/resourceGroups/rg-sdp-dev-test/providers/Microsoft.Compute/galleries/sig_sdp_images/images/sunbox-ubuntu/versions/1.10.1','CustomImage','ubuntu 18.04','sysadmin','2022-12-06 15:44:34'),('SDP-1.0','core','/subscriptions/9b88bd64-d315-48de-96bc-83051ed25fdc/resourceGroups/rg-sdp-dev-test/providers/Microsoft.Compute/galleries/sig_sdp_images/images/sunbox-ubuntu/versions/1.10.1','CustomImage','ubuntu 18.04','sysadmin','2022-12-06 15:44:37'),('SDP-1.0','master','/subscriptions/9b88bd64-d315-48de-96bc-83051ed25fdc/resourceGroups/rg-sdp-dev-test/providers/Microsoft.Compute/galleries/sig_sdp_images/images/sunbox-ubuntu/versions/1.10.1','CustomImage','ubuntu 18.04','sysadmin','2022-12-06 15:44:40'),('SDP-1.0','task','/subscriptions/9b88bd64-d315-48de-96bc-83051ed25fdc/resourceGroups/rg-sdp-dev-test/providers/Microsoft.Compute/galleries/sig_sdp_images/images/sunbox-ubuntu/versions/1.10.1','CustomImage','ubuntu 18.04','sysadmin','2022-12-06 15:44:43');


insert  into `base_scene`(`scene_id`,`cluster_release_ver`,`scene_name`,`scene_desc`,`created_time`,`createdby`) values ('692fc42a-5251-1eb8-f1de-6dbbd3e47529','SDP-1.0','HBASE','HBASE','2022-12-21 22:34:00','system'),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','SDP-1.0','DEFAULT','','2022-12-21 22:34:00','system');


insert  into `base_scene_apps`(`scene_id`,`app_name`,`app_version`,`required`,`sort_no`) values ('692fc42a-5251-1eb8-f1de-6dbbd3e47529','HBase','2.4.4',1,5),('692fc42a-5251-1eb8-f1de-6dbbd3e47529','HDFS','3.3.2',1,2),('692fc42a-5251-1eb8-f1de-6dbbd3e47529','MapReduce2','3.3.2',1,3),('692fc42a-5251-1eb8-f1de-6dbbd3e47529','Yarn','3.3.2',1,4),('692fc42a-5251-1eb8-f1de-6dbbd3e47529','ZooKeeper','3.5.7',1,1),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','HDFS','3.3.2',1,2),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','Hive','3.1.2',0,5),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','MapReduce2','3.3.2',1,3),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','Spark3','3.1.2',0,6),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','Sqoop','1.4.7',0,7),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','Tez','0.10.2',0,8),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','Yarn','3.3.2',1,4),('6dee2ab7-6e64-80d2-ca67-2a433db39daa','ZooKeeper','3.5.7',1,1);



INSERT INTO base_user_info (user_id,user_name,real_name,dept_id,dept_name,password,created_time,createdby,modified_time,modifiedby) VALUES
    ('5772a355-ce6d-4d91-9331-e3bce19c52d6','sdpadmin','sdpadmin','sdpadmin','sdpadmin','9b6daa66b84dc456f31011a6e44b5b97','2022-12-26 08:19:15',NULL,NULL,NULL);


insert  into `config_core`(`id`,`akey`,`avalue`,`application`,`profile`,`label`,`mwtype`) values (1421,'spring.datasource.driver-class-name','com.mysql.cj.jdbc.Driver','core','test','master','db'),(1422,'spring.datasource.type','com.alibaba.druid.pool.DruidDataSource','core','test','master','db'),(1423,'spring.datasource.initialization-mode','always','core','test','master','db'),(1424,'spring.datasource.initial-size','5','core','test','master','db'),(1425,'spring.datasource.max-active','200','core','test','master','db'),(1426,'spring.datasource.min-idle','5','core','test','master','db'),(1427,'spring.datasource.max-wait','6000','core','test','master','db'),(1428,'spring.datasource.connectionProperties','config.decrypt=true;config.decrypt.key=${spring.datasource.publicKey}','core','test','master','db'),(1429,'spring.datasource.druid.config.enabled','true','core','test','master','db'),(1430,'mybatis.mapper-locations','classpath:mapper/*Mapper.xml','core','test','master','db'),(1431,'logconfig.root','./logs','core','test','master','db'),(1432,'logconfig.level','INFO','core','test','master','db'),(1433,'logconfig.days','7','core','test','master','db'),(1434,'logging.config','classpath:log/logback-custom.xml','core','test','master','db'),(1435,'org.slf4j.simpleLogger.log.com.zaxxer.hikari','error','core','test','master','db');
